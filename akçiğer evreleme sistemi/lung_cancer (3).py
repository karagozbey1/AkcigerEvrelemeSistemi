# -*- coding: utf-8 -*-
"""Lung Cancer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u9pB3fT3ytI9Vfc7m1CxZq1YbhFXvuSP

# GÃ¶rÃ¼ntÃ¼ Ä°ÅŸleme
"""

from google.colab import drive
drive.mount('/content/drive')



from google.colab import drive
drive.mount('/content/drive')

import os

root_path = '/content/drive/MyDrive'
dataset_path = os.path.join(root_path, 'dataset_lung')

# dataset_lung iÃ§eriÄŸini yazdÄ±r
print("dataset_lung iÃ§eriÄŸi:")
print(os.listdir(dataset_path))

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from collections import defaultdict

dataset_path = '/content/drive/MyDrive/dataset_lung'

# Otomatik sÄ±nÄ±f isimleri
class_names = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
image_counts = defaultdict(int)
sample_images = {}

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    image_counts[class_name] = len(image_files)
    if image_files:
        sample_images[class_name] = os.path.join(class_dir, image_files[0])

print("ğŸ“¦ SÄ±nÄ±f baÅŸÄ±na gÃ¶rÃ¼ntÃ¼ sayÄ±sÄ±:")
for class_name, count in image_counts.items():
    print(f"â€¢ {class_name}: {count} gÃ¶rÃ¼ntÃ¼")

print("\nğŸ¨ Ã–rnek gÃ¶rÃ¼ntÃ¼ler:")
plt.figure(figsize=(12, 4))
for i, (class_name, image_path) in enumerate(sample_images.items()):
    img = mpimg.imread(image_path)
    plt.subplot(1, len(sample_images), i + 1)
    plt.imshow(img, cmap='gray')
    plt.title(class_name)
    plt.axis('off')
plt.tight_layout()
plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""*** ğŸ§© I. VERÄ° Ã–NÄ°ZLEME & KEÅÄ°F (EXPLORATORY DATA ANALYSIS) ***

1	KlasÃ¶r YapÄ±sÄ±, GÃ¶rsel SayÄ±sÄ±, Format KontrolÃ¼
"""

import os
import matplotlib.pyplot as plt
from collections import defaultdict

# Dataset path
dataset_path = "/content/drive/MyDrive/dataset_lung"
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

# KlasÃ¶rleri al
class_names = sorted(os.listdir(dataset_path))
image_counts = defaultdict(int)
invalid_files = []

# GÃ¶rsel format kontrolÃ¼ ve sayÄ±mÄ±
for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    if not os.path.isdir(class_dir):
        continue
    for f in os.listdir(class_dir):
        file_path = os.path.join(class_dir, f)
        if f.lower().endswith(valid_extensions):
            image_counts[class_name] += 1
        else:
            invalid_files.append(file_path)

# 1ï¸âƒ£ GÃ¶rsel SayÄ±sÄ± GrafiÄŸi
plt.figure(figsize=(8, 5))
plt.bar(image_counts.keys(), image_counts.values(), color='skyblue')
plt.title("SÄ±nÄ±f BazÄ±nda GÃ¶rsel SayÄ±sÄ±")
plt.ylabel("GÃ¶rsel SayÄ±sÄ±")
plt.xlabel("SÄ±nÄ±f")
for i, count in enumerate(image_counts.values()):
    plt.text(i, count + 5, str(count), ha='center')
plt.tight_layout()
plt.savefig("image_counts_by_class.png")
plt.show()

# 2ï¸âƒ£ GeÃ§ersiz DosyalarÄ± Listele
print("\nâŒ GeÃ§ersiz FormatlÄ± Dosyalar:")
if invalid_files:
    for path in invalid_files:
        print("-", path)
else:
    print("TÃ¼m dosyalar geÃ§erli formatta.")

# 3ï¸âƒ£ Ã–zet
print("\nğŸ“¦ SÄ±nÄ±f BaÅŸÄ±na GÃ¶rsel SayÄ±sÄ±:")
for class_name, count in image_counts.items():
    print(f"â€¢ {class_name.capitalize()}: {count} gÃ¶rÃ¼ntÃ¼")

# 4ï¸âƒ£ Toplam gÃ¶rsel sayÄ±sÄ±
print(f"\nğŸ“Š Toplam geÃ§erli gÃ¶rsel sayÄ±sÄ±: {sum(image_counts.values())}")
print(f"ğŸ” GeÃ§ersiz dosya sayÄ±sÄ±: {len(invalid_files)}")

"""#	2	Her SÄ±nÄ±ftan Ã–rnek GÃ¶rsel PanolarÄ± (3x3 Grid)

Bu adÄ±mda, her sÄ±nÄ±ftan (benign, normal, malignant) rastgele 9 gÃ¶rsel seÃ§erek birer 3x3 grid oluÅŸturuldu . BÃ¶ylece sÄ±nÄ±flar arasÄ± gÃ¶rsel farklarÄ± ilk aÅŸamada sezgisel olarak gÃ¶zlemleyebiliriz.

AmaÃ§:
GÃ¶rsellerdeki yapÄ±sal ve doku farklÄ±lÄ±klarÄ±nÄ± ilk aÅŸamada gÃ¶zlemleme

Verinin niteliÄŸi hakkÄ±nda sezgisel iÃ§gÃ¶rÃ¼ elde etme

"""

import matplotlib.pyplot as plt
import os
import random
import cv2

# KlasÃ¶r yolu
dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

def plot_sample_images(class_name, img_size=(100, 100)):
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    selected_images = random.sample(image_files, 9)

    plt.figure(figsize=(8, 8))
    plt.suptitle(f"{class_name.capitalize()} SÄ±nÄ±fÄ±ndan 9 Ã–rnek GÃ¶rsel", fontsize=16)

    for idx, image_name in enumerate(selected_images):
        image_path = os.path.join(class_dir, image_name)
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)

        plt.subplot(3, 3, idx + 1)
        plt.imshow(img)
        plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.savefig(f"{class_name}_samples_grid.png")
    plt.show()

# Her sÄ±nÄ±f iÃ§in ayrÄ± grid
for cls in class_names:
    plot_sample_images(cls)

"""#	3	GÃ¶rsel Boyut & Kanal Ä°ncelemesi (RGB vs. Grayscale)
Bu adÄ±mda amacÄ±mÄ±z, tÃ¼m veri setindeki gÃ¶rÃ¼ntÃ¼lerin:

ğŸ“ Boyut (yÃ¼kseklik x geniÅŸlik) daÄŸÄ±lÄ±mÄ±nÄ±

ğŸ¨ Kanal sayÄ±sÄ±nÄ± (Grayscale mi, RGB mi?)

ğŸ” Anormal Ã§Ã¶zÃ¼nÃ¼rlÃ¼kleri ve standart dÄ±ÅŸÄ± formatlarÄ±

tespit etmektir.

ğŸ“Š 1. GÃ¶rsel Boyut DaÄŸÄ±lÄ±mÄ± (Histogram)
Grafikte Ã§oÄŸu gÃ¶rselin boyutu yaklaÅŸÄ±k 224x224 ve 512x512 gibi gÃ¶rÃ¼nÃ¼yor.

Ufak sayÄ±da 600+ ve 800+ piksel geniÅŸliÄŸe sahip outlier gÃ¶rseller mevcut.

Standardizasyon iÃ§in tÃ¼m gÃ¶rselleri ortak bir boyuta getirmek mantÄ±klÄ± (Ã¶rn: 224x224 veya 256x256).

ğŸ¨ 2. Kanal SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±
TÃ¼m gÃ¶rÃ¼ntÃ¼ler 3-kanallÄ± (RGB) Ã§Ä±ktÄ±.

Bu durum harika: Model eÄŸitimine doÄŸrudan uygun.

Grayscale â†’ RGB dÃ¶nÃ¼ÅŸÃ¼mÃ¼ne gerek kalmadÄ±.

âœ… Teknik SonuÃ§:
GÃ¶zlem	SonuÃ§
Kanal tÃ¼rÃ¼	Hepsi RGB (3-kanallÄ±)
Boyutlar	2 farklÄ± boyut kÃ¼mesi hÃ¢kim
Tavsiye	EÄŸitim Ã¶ncesi tÃ¼m gÃ¶rseller cv2.resize(..., (224,224)) gibi normalize edilmeli

"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from tqdm import tqdm

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

image_shapes = []
channel_counts = []

print("ğŸ” GÃ¶rseller analiz ediliyor...\n")

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

    for image_name in tqdm(image_files, desc=class_name):
        img_path = os.path.join(class_dir, image_name)
        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

        if img is None:
            continue  # bozuk gÃ¶rsel

        h, w = img.shape[:2]
        c = 1 if len(img.shape) == 2 else img.shape[2]
        image_shapes.append((w, h))
        channel_counts.append(c)

# ğŸ¯ Boyut DaÄŸÄ±lÄ±mÄ±
shape_counts = Counter(image_shapes)
most_common_shape, most_common_count = shape_counts.most_common(1)[0]

# ğŸ“Š Kanal DaÄŸÄ±lÄ±mÄ±
channel_counts_freq = Counter(channel_counts)

# ğŸ“ˆ Boyut HistogramÄ±
widths = [s[0] for s in image_shapes]
heights = [s[1] for s in image_shapes]

plt.figure(figsize=(10, 4))
plt.hist(widths, bins=30, alpha=0.7, label='GeniÅŸlik', color='skyblue')
plt.hist(heights, bins=30, alpha=0.7, label='YÃ¼kseklik', color='salmon')
plt.title("ğŸ“ GÃ¶rsel Boyut DaÄŸÄ±lÄ±mÄ± (GeniÅŸlik & YÃ¼kseklik)")
plt.xlabel("Piksel SayÄ±sÄ±")
plt.ylabel("Frekans")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("image_size_distribution.png")
plt.show()

# ğŸ¨ Kanal DaÄŸÄ±lÄ±mÄ± GrafiÄŸi
plt.figure(figsize=(5, 4))
plt.bar(channel_counts_freq.keys(), channel_counts_freq.values(), color='orchid')
plt.title("ğŸ¨ Kanal SayÄ±sÄ± DaÄŸÄ±lÄ±mÄ±")
plt.xticks([1, 3], ["Grayscale", "RGB"])
plt.xlabel("Kanal SayÄ±sÄ±")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.tight_layout()
plt.savefig("channel_count_distribution.png")
plt.show()

# ğŸ§¾ Metinsel Ã–zet
print("\nğŸ“‹ GÃ¶rsel Kanal DaÄŸÄ±lÄ±mÄ±:")
for ch, count in channel_counts_freq.items():
    print(f"â€¢ {ch} kanal ({'Grayscale' if ch == 1 else 'RGB'}): {count} gÃ¶rÃ¼ntÃ¼")

print(f"\nğŸ“‹ En yaygÄ±n boyut: {most_common_shape[0]}x{most_common_shape[1]} ({most_common_count} gÃ¶rsel)")
print(f"ğŸ” FarklÄ± boyut sayÄ±sÄ±: {len(shape_counts)}")

"""#	4	Bozuk, Eksik, AÃ§Ä±lmayan GÃ¶rsellerin LoglanmasÄ±



"""

import os
import cv2
from tqdm import tqdm

# KlasÃ¶r yolu
dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

# Bozuk dosya listesi
corrupted_images = []

print("ğŸ” GÃ¶rseller taranÄ±yor...\n")

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

    for img_file in tqdm(image_files, desc=f"TaranÄ±yor: {class_name}"):
        img_path = os.path.join(class_dir, img_file)

        # BoÅŸ dosya veya okunamayan gÃ¶rsel
        if os.path.getsize(img_path) == 0:
            corrupted_images.append((class_name, img_file, "Dosya boyutu 0"))
            continue

        img = cv2.imread(img_path)
        if img is None:
            corrupted_images.append((class_name, img_file, "cv2.imread baÅŸarÄ±sÄ±z"))

# ğŸ§¾ SonuÃ§larÄ± kaydet
log_path = "/content/corrupted_image_log.txt"
with open(log_path, "w") as f:
    for item in corrupted_images:
        f.write(f"{item[0]}/{item[1]} => {item[2]}\n")

# ğŸ§® Ã–zet
print("\nğŸ§¾ Taranan toplam bozuk/eksik gÃ¶rsel sayÄ±sÄ±:", len(corrupted_images))
if corrupted_images:
    print(f"ğŸ“ Log dosyasÄ±: {log_path}")
    print("ğŸ” Ä°lk 5 bozuk dosya:")
    for item in corrupted_images[:5]:
        print(f" - {item[0]}/{item[1]} â†’ {item[2]}")
else:
    print("ğŸ‰ TÃ¼m gÃ¶rseller okunabilir ve saÄŸlam!")

"""#	5	Her sÄ±nÄ±fa ait Ortalama GÃ¶rsel (Mean Image Map)


Her sÄ±nÄ±f iÃ§in tÃ¼m gÃ¶rÃ¼ntÃ¼lerin piksel bazÄ±nda ortalamasÄ±nÄ± alarak:

GÃ¶rsel Ã¶rÃ¼ntÃ¼ farklarÄ±nÄ± daha net gÃ¶rmek

EÄŸitim setindeki baskÄ±n yapÄ±larÄ± sezgisel olarak gÃ¶rmek

Noise var mÄ±, veri standardÄ± ne durumda anlayabilmek

ğŸ“ HazÄ±rlÄ±k:
TÃ¼m gÃ¶rseller aynÄ± boyutta (Ã¶rn: 224Ã—224) olmalÄ±

TÃ¼m gÃ¶rseller RGB (3-kanal) olmalÄ±

Ortalama, float32 tÃ¼rÃ¼nde hesaplanmalÄ±

ğŸ“Š Ne Elde Ediyoruz?
SÄ±nÄ±f	GÃ¶rsel
benign	mean_image_benign.png
normal	mean_image_normal.png
malignant	mean_image_malignant.png

Bu gÃ¶rseller, o sÄ±nÄ±ftaki tÃ¼m verilerin â€œortalama yapÄ±sÄ±nÄ±â€ temsil eder. Genellikle daha soluk ve yayvan dokular Ã§Ä±kar.

ğŸ’¬ Yorumlama Ã–nerisi:
GÃ¶zlem	Yorum
Daha parlak ortalamalar	Genel yoÄŸunluk fazla
Belirgin yapÄ±lar	SÄ±nÄ±f iÃ§i benzerlik yÃ¼ksek
Belirsiz / daÄŸÄ±nÄ±k	Veri gÃ¼rÃ¼ltÃ¼lÃ¼ olabilir
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]
img_size = (224, 224)  # Ortak boyut

def compute_class_mean_image(class_name):
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

    mean_image = np.zeros((img_size[1], img_size[0], 3), dtype=np.float32)
    count = 0

    for img_file in image_files:
        img_path = os.path.join(class_dir, img_file)
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, img_size)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mean_image += img.astype(np.float32)
        count += 1

    if count > 0:
        mean_image /= count
        mean_image = mean_image.astype(np.uint8)

    return mean_image, count

# ğŸ” Her sÄ±nÄ±f iÃ§in ortalama hesapla ve gÃ¶ster
for class_name in class_names:
    mean_img, total = compute_class_mean_image(class_name)

    plt.figure(figsize=(4, 4))
    plt.imshow(mean_img)
    plt.title(f"ğŸ§  Ortalama GÃ¶rsel: {class_name.capitalize()} ({total} adet)")
    plt.axis("off")
    plt.tight_layout()
    save_path = f"mean_image_{class_name}.png"
    plt.savefig(save_path)
    plt.show()

"""#	6	GÃ¶rÃ¼ntÃ¼ Entropisi ile Bilgi YoÄŸunluÄŸu Ã–lÃ§Ã¼mÃ¼

AmaÃ§:
Her bir sÄ±nÄ±ftaki gÃ¶rÃ¼ntÃ¼lerin bilgi miktarÄ±nÄ± (entropi) Ã¶lÃ§erek:

GÃ¶rsel iÃ§erik ne kadar karmaÅŸÄ±k?

Detay/farklÄ±lÄ±k ne dÃ¼zeyde?

Veri kalitesi & ayÄ±rt edicilik potansiyeli nedir?

bunu sayÄ±sal ve grafiksel olarak deÄŸerlendirmek.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from scipy.stats import entropy

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

def calculate_entropy(image):
    """Tek kanallÄ± (grayscale) gÃ¶rÃ¼ntÃ¼nÃ¼n entropisini hesaplar"""
    histogram, _ = np.histogram(image.flatten(), bins=256, range=[0, 256], density=True)
    return entropy(histogram, base=2)

entropies = {}

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    entropy_list = []
    for file in tqdm(files, desc=f"{class_name} sÄ±nÄ±fÄ± entropi hesaplanÄ±yor"):
        img_path = os.path.join(class_dir, file)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (224, 224))
        e = calculate_entropy(img)
        entropy_list.append(e)

    entropies[class_name] = entropy_list

# ğŸ“Š Boxplot ile GÃ¶rsel Entropi DaÄŸÄ±lÄ±mÄ±
plt.figure(figsize=(10, 6))
plt.boxplot([entropies[c] for c in class_names], labels=class_names)
plt.title("ğŸ“‰ GÃ¶rÃ¼ntÃ¼ Entropisi DaÄŸÄ±lÄ±mÄ± (Bilgi YoÄŸunluÄŸu)")
plt.ylabel("Entropi (bit)")
plt.grid(True)
plt.tight_layout()
plt.savefig("entropi_dagilimi.png")
plt.show()

# ğŸ§¾ Ortalama entropiler
print("ğŸ“˜ Ortalama Entropi DeÄŸerleri:")
for c in class_names:
    avg_entropy = np.mean(entropies[c])
    std_entropy = np.std(entropies[c])
    print(f"â€¢ {c.capitalize()}: {avg_entropy:.3f} Â± {std_entropy:.3f} bit")

"""#	7	Dosya Boyutu DaÄŸÄ±lÄ±mÄ± â€“ Ä°maj Kalitesi KontrolÃ¼

**AmaÃ§:**

 GÃ¶rsel boyutlarÄ±nÄ± normalize ederek (Ã¶rneÄŸin 224Ã—224):

Model mimarileriyle (CNN tabanlÄ± ResNet, VGG vs.) uyum saÄŸlanÄ±r.

AykÄ±rÄ± Ã§Ã¶zÃ¼nÃ¼rlÃ¼k farklarÄ± ve Ã¶ÄŸrenme bozukluklarÄ± ortadan kaldÄ±rÄ±lÄ±r.

EÄŸitim sÃ¼resi kÄ±salÄ±r, GPU belleÄŸi dengelenir.

**Ne GÃ¶zlemlemeliyiz?** :
------------------------
Outlier dosyalar var mÄ±? Ã‡ok kÃ¼Ã§Ã¼k veya Ã§ok bÃ¼yÃ¼k dosyalar tespit edilirse loglayabiliriz.

SÄ±nÄ±flar arasÄ± kalite farkÄ± var mÄ±? Ã–rneÄŸin, malignant dosyalarÄ± belirgin ÅŸekilde bÃ¼yÃ¼kse veri dengesizliÄŸi olabilir.

Dilersen:

df_sizes[df_sizes['size_kb'] < 5] gibi filtreyle Ã§ok kÃ¼Ã§Ã¼k dosyalarÄ± listeleyebilirim.

AykÄ±rÄ± deÄŸerleri .boxplot(showfliers=True) ile gÃ¶sterebiliriz.
"""

import os
import matplotlib.pyplot as plt
import seaborn as sns

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ['benign', 'normal', 'malignant']
file_sizes = []

# Her sÄ±nÄ±ftan dosya boyutlarÄ±nÄ± topla
for cls in class_names:
    class_dir = os.path.join(dataset_path, cls)
    for file_name in os.listdir(class_dir):
        if file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            file_path = os.path.join(class_dir, file_name)
            size_kb = os.path.getsize(file_path) / 1024  # KB
            file_sizes.append({'class': cls, 'size_kb': size_kb})

# GÃ¶rsel olarak analiz et
df_sizes = pd.DataFrame(file_sizes)

plt.figure(figsize=(12, 6))
sns.boxplot(data=df_sizes, x='class', y='size_kb')
plt.title('ğŸ“¦ Dosya Boyutu DaÄŸÄ±lÄ±mÄ± (KB)')
plt.ylabel('Dosya Boyutu (KB)')
plt.xlabel('SÄ±nÄ±f')
plt.grid(True)
plt.show()

# Ä°statistikleri yazdÄ±r
print("ğŸ“Š Dosya Boyutu Ä°statistikleri (KB):")
print(df_sizes.groupby("class")["size_kb"].describe().round(2))

"""# 8 GÃ¶rsel BoyutlarÄ±nÄ± Dengeleme

GÃ¶rsel boyutlarÄ±nÄ± normalize ederek (Ã¶rneÄŸin 224Ã—224):

Model mimarileriyle (CNN tabanlÄ± ResNet, VGG vs.) uyum saÄŸlanÄ±r.

AykÄ±rÄ± Ã§Ã¶zÃ¼nÃ¼rlÃ¼k farklarÄ± ve Ã¶ÄŸrenme bozukluklarÄ± ortadan kaldÄ±rÄ±lÄ±r.

EÄŸitim sÃ¼resi kÄ±salÄ±r, GPU belleÄŸi dengelenir.
"""

import os
from PIL import Image
from tqdm import tqdm

# Kaynak ve hedef klasÃ¶r
input_root = '/content/drive/MyDrive/dataset_lung'
output_root = '/content/drive/MyDrive/dataset_lung_resized'
target_size = (224, 224)

os.makedirs(output_root, exist_ok=True)

# SÄ±nÄ±f klasÃ¶rleri Ã¼zerinden dÃ¶n
for class_name in os.listdir(input_root):
    input_class_dir = os.path.join(input_root, class_name)
    output_class_dir = os.path.join(output_root, class_name)
    os.makedirs(output_class_dir, exist_ok=True)

    for filename in tqdm(os.listdir(input_class_dir), desc=f"Resizing {class_name}"):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            img_path = os.path.join(input_class_dir, filename)
            save_path = os.path.join(output_class_dir, filename)

            try:
                img = Image.open(img_path)
                img = img.convert('RGB')  # RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r (uyumluluk iÃ§in)
                img = img.resize(target_size, Image.BILINEAR)
                img.save(save_path)
            except Exception as e:
                print(f"HATA: {img_path} - {e}")



import os
from PIL import Image
import matplotlib.pyplot as plt
from collections import Counter

resized_path = "/content/drive/MyDrive/dataset_lung_resized"
class_names = os.listdir(resized_path)

widths, heights, sizes = [], [], []

# Boyut bilgilerini topla
for cls in class_names:
    cls_dir = os.path.join(resized_path, cls)
    for fname in os.listdir(cls_dir):
        if fname.lower().endswith(('.jpg', '.png', '.jpeg')):
            try:
                img = Image.open(os.path.join(cls_dir, fname))
                w, h = img.size
                widths.append(w)
                heights.append(h)
                sizes.append((w, h))
            except:
                print(f"âš ï¸ HatalÄ± gÃ¶rsel: {cls}/{fname}")

# Histogram Ã§izimi
plt.figure(figsize=(10,4))
plt.hist(widths, bins=10, alpha=0.6, label="GeniÅŸlik", color="skyblue", edgecolor='black')
plt.hist(heights, bins=10, alpha=0.6, label="YÃ¼kseklik", color="salmon", edgecolor='black')
plt.title("ğŸ¯ Resize SonrasÄ± GÃ¶rsel Boyut DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Piksel SayÄ±sÄ±")
plt.ylabel("Frekans")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Boyut frekans analizi
size_counter = Counter(sizes)
print("\nğŸ§¾ GÃ¶rsel Boyutu FrekansÄ±:")
for size, count in size_counter.most_common():
    print(f"ğŸ”¹ {size}: {count} adet")

# Yorum
total = sum(size_counter.values())
correct = size_counter.get((224, 224), 0)
if correct == total:
    print(f"\nâœ… TÃ¼m {total} gÃ¶rsel baÅŸarÄ±yla 224x224 olarak resize edildi.")
else:
    print(f"\nâš ï¸ Toplam {total} gÃ¶rselden yalnÄ±zca {correct} tanesi 224x224. DiÄŸerlerinde farklÄ±lÄ±k var!")

"""#	9	Histogram KarÅŸÄ±laÅŸtÄ±rmalarÄ± (Her sÄ±nÄ±fa Ã¶zel)

Her sÄ±nÄ±ftaki Ã¶rnek gÃ¶rsellerin piksel yoÄŸunluÄŸu daÄŸÄ±lÄ±mÄ±nÄ± histogramlarla gÃ¶rselleÅŸtirildi . Bu, sÄ±nÄ±flar arasÄ±ndaki gÃ¶rsel parlaklÄ±k, kontrast ve bilgi yoÄŸunluÄŸu farklarÄ±nÄ± gÃ¶zlemlemek iÃ§in Ã¶nemli bir adÄ±mdÄ±r.

**AmaÃ§:**

Her sÄ±nÄ±f iÃ§in birkaÃ§ rastgele gÃ¶rselin grayscale histogramÄ±nÄ± Ã§izmek

GÃ¶rsel iÃ§erikler hakkÄ±nda bilgi edinmek (aÅŸÄ±rÄ± karanlÄ±k, kontrast eksikliÄŸi vs.)

EÄŸitim Ã¶ncesi normalize ihtiyacÄ±nÄ± daha iyi anlamak

**sonuÃ§:**

 cv2.IMREAD_GRAYSCALE ile grayscale dÃ¶nÃ¼ÅŸÃ¼mÃ¼ yapÄ±lÄ±yor (Renk kanallarÄ±nÄ± karÅŸÄ±laÅŸtÄ±rmak istiyorsan RGB histogramlarÄ± da Ã§izilebilir).

Histogram EÄŸrisi â†’ Piksel deÄŸerine gÃ¶re gÃ¶rselin ne kadar karanlÄ±k/aÃ§Ä±k yoÄŸunlukta olduÄŸunu gÃ¶sterir.

Bu Ã§Ä±ktÄ±lar, gÃ¶rsellerin normalize edilmesi gerektiÄŸini daha iyi anlamanÄ± saÄŸlar.

"""

import os
import cv2
import matplotlib.pyplot as plt
import random

def plot_class_histograms(dataset_path, class_names, img_size=(224, 224), samples_per_class=3):
    for cls in class_names:
        cls_path = os.path.join(dataset_path, cls)
        all_images = [img for img in os.listdir(cls_path) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]
        selected_imgs = random.sample(all_images, samples_per_class)

        plt.figure(figsize=(15, 3))
        for i, img_name in enumerate(selected_imgs):
            img_path = os.path.join(cls_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, img_size)
            hist = cv2.calcHist([img], [0], None, [256], [0, 256])

            plt.subplot(1, samples_per_class, i + 1)
            plt.plot(hist, color='black')
            plt.title(f"{cls} - {img_name}")
            plt.xlabel("Piksel DeÄŸeri")
            plt.ylabel("Frekans")
            plt.tight_layout()
            plt.suptitle(f"ğŸ“Š {cls} SÄ±nÄ±fÄ± HistogramlarÄ±", fontsize=16)
        plt.subplots_adjust(top=0.75)
        plt.show()


# KullanÄ±m
dataset_path = "/content/drive/MyDrive/dataset_lung_resized"
class_names = ["benign", "malignant", "normal"]
plot_class_histograms(dataset_path, class_names)

"""#	10	Renk KanalÄ± DÃ¶nÃ¼ÅŸÃ¼mÃ¼ (Grayscale â†’ RGB)

Her resmi RGBâ€™ye Ã§evirir

Bu adÄ±m, Ã¶zellikle bazÄ± modeller (Ã¶rneÄŸin: pretrained CNN modelleri â€“ ResNet, VGG, EfficientNet vs.) RGB giriÅŸ beklediÄŸi iÃ§in zorunlu hale gelir.

Grayscale (tek kanal) olan gÃ¶rselleri 3 kanallÄ± RGB (aynÄ± gÃ¶rÃ¼ntÃ¼yÃ¼ 3 kez kopyalayarak) haline getirmek.


CNN tabanlÄ± birÃ§ok model input_shape=(224, 224, 3) ister.

GÃ¶rsellerimiz ÅŸu anda 224x224x1 ÅŸeklinde olabilir.

Grayscale â†’ RGB dÃ¶nÃ¼ÅŸÃ¼m: cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)

Bu iÅŸlem bilgiyi deÄŸiÅŸtirmez, yalnÄ±zca kanallarÄ± geniÅŸletir.



"""

import os
import cv2
from tqdm import tqdm

# GiriÅŸ (grayscale) klasÃ¶rÃ¼ ve Ã§Ä±kÄ±ÅŸ (RGB) klasÃ¶rÃ¼
input_dir = "/content/drive/MyDrive/dataset_lung_resized"
output_dir = "/content/drive/MyDrive/dataset_lung_rgb"
os.makedirs(output_dir, exist_ok=True)

# Her sÄ±nÄ±fÄ± gez
for class_name in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, class_name)
    class_output_path = os.path.join(output_dir, class_name)
    os.makedirs(class_output_path, exist_ok=True)

    for file_name in tqdm(os.listdir(class_input_path), desc=f"{class_name} dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼yor"):
        input_path = os.path.join(class_input_path, file_name)
        output_path = os.path.join(class_output_path, file_name)

        try:
            img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            rgb_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            cv2.imwrite(output_path, rgb_img)
        except Exception as e:
            print(f"Hata: {file_name} - {e}")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict

# Sen klasÃ¶r yolunu buraya yaz
dataset_path = "/content/drive/MyDrive/dataset_lung_rgb"
class_names = os.listdir(dataset_path)

channel_counts = defaultdict(list)

for cls in class_names:
    class_dir = os.path.join(dataset_path, cls)
    for img_name in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path)
        if img is None:
            continue
        channels = img.shape[-1]
        channel_counts[cls].append(channels)

# Grafik: SÄ±nÄ±flara gÃ¶re kanal sayÄ±sÄ± daÄŸÄ±lÄ±mÄ±
plt.figure(figsize=(8, 5))
for cls in class_names:
    plt.hist(channel_counts[cls], bins=np.arange(1, 5)-0.5, alpha=0.6, label=cls)
plt.xticks([1, 2, 3])
plt.xlabel("Kanal SayÄ±sÄ± (1=Grayscale, 3=RGB)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.title("ğŸ” SÄ±nÄ±flara GÃ¶re GÃ¶rsel Renk Kanal DaÄŸÄ±lÄ±mÄ±")
plt.legend()
plt.grid(True)
plt.show()

# Metinsel analiz (ZeroDivisionError kontrolÃ¼ ile)
for cls in class_names:
    total = len(channel_counts[cls])
    rgb = sum(1 for c in channel_counts[cls] if c == 3)
    gray = sum(1 for c in channel_counts[cls] if c == 1)

    if total > 0:
        print(f"ğŸ“ {cls}: {rgb}/{total} (%{round(100 * rgb / total, 2)}) RGB, {gray}/{total} (%{round(100 * gray / total, 2)}) Grayscale")
    else:
        print(f"ğŸ“ {cls}: âš ï¸ UyarÄ±: Bu sÄ±nÄ±fta analiz edilecek gÃ¶rÃ¼ntÃ¼ bulunamadÄ±.")

"""#	11	Piksel DeÄŸer Normalizasyonu (0â€“1 veya -1â€“1)

Bu adÄ±m, gÃ¶rsellerin her piksel deÄŸerini aynÄ± Ã¶lÃ§eÄŸe indirerek modelin daha hÄ±zlÄ± ve kararlÄ± Ã¶ÄŸrenmesini saÄŸlar.

AmaÃ§:

Piksel deÄŸerlerini 0â€“255 aralÄ±ÄŸÄ±ndan 0â€“1 aralÄ±ÄŸÄ±na dÃ¶nÃ¼ÅŸtÃ¼rmek

GÃ¶rselleri normalize ederek model eÄŸitimine uygun hale getirmek

"""

import os
import cv2
import numpy as np
from tqdm import tqdm
from matplotlib import pyplot as plt

input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_rgb"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_normalized"
os.makedirs(output_dir, exist_ok=True)

class_names = [cls for cls in os.listdir(input_dir) if not cls.startswith(".")]
summary = {}

for cls in class_names:
    class_input_path = os.path.join(input_dir, cls)
    class_output_path = os.path.join(output_dir, cls)
    os.makedirs(class_output_path, exist_ok=True)

    pixel_means = []
    for fname in tqdm(os.listdir(class_input_path), desc=f"{cls}"):
        img_path = os.path.join(class_input_path, fname)
        try:
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = img.astype(np.float32) / 255.0  # ğŸ”½ Normalization

            pixel_means.append(np.mean(img))

            save_path = os.path.join(class_output_path, fname)
            img_uint8 = (img * 255).astype(np.uint8)  # Kaydetmek iÃ§in tekrar uint8'e Ã§evir
            cv2.imwrite(save_path, cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR))
        except Exception as e:
            print(f"âš ï¸ Hata: {img_path} â€“ {e}")

    summary[cls] = {
        "count": len(pixel_means),
        "mean": round(np.mean(pixel_means), 4),
        "std": round(np.std(pixel_means), 4)
    }

# ğŸ¯ Ã–zet Tablosu
print("\nğŸ“˜ Piksel Ortalama DeÄŸerleri (0â€“1 aralÄ±ÄŸÄ±nda):")
for cls, stat in summary.items():
    print(f"â€¢ {cls}: {stat['mean']} Â± {stat['std']} (n={stat['count']})")

# ğŸ“Š DaÄŸÄ±lÄ±m GrafiÄŸi
plt.figure(figsize=(8, 4))
for cls, stat in summary.items():
    plt.bar(cls, stat['mean'], yerr=stat['std'], capsize=6)
plt.title("ğŸ“Š SÄ±nÄ±f BazÄ±nda Ortalama Piksel DeÄŸerleri (Normalize EdilmiÅŸ)")
plt.ylabel("Ortalama Piksel DeÄŸeri (0â€“1)")
plt.tight_layout()
plt.show()

"""# 12 Histogram EÅŸitleme + Kontrast DaÄŸÄ±lÄ±m Analizi

Her gÃ¶rseli griye Ã§evirip histogram eÅŸitleme uygular.

Geri RGB formatÄ±nda 3 kanallÄ± olarak kaydeder.

GÃ¶rsellerin kontrastÄ±nÄ± (piksel std. sapmasÄ±) Ã¶lÃ§er.

Her sÄ±nÄ±f iÃ§in kontrast istatistiklerini ve histogram grafiÄŸini Ã¼retir.




"""

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image

# GiriÅŸ ve Ã§Ä±kÄ±ÅŸ klasÃ¶rleri
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_normalized"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_hist_equalized"
os.makedirs(output_dir, exist_ok=True)

# Kontrast Ã¶lÃ§Ã¼m fonksiyonu (standard deviation)
def calculate_contrast(image):
    return np.std(image)

# Her sÄ±nÄ±f iÃ§in iÅŸlemleri yapalÄ±m
contrast_stats = {}

for cls in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, cls)
    class_output_path = os.path.join(output_dir, cls)
    os.makedirs(class_output_path, exist_ok=True)

    contrast_values = []

    for filename in tqdm(os.listdir(class_input_path), desc=f"Ä°ÅŸleniyor: {cls}"):
        img_path = os.path.join(class_input_path, filename)
        try:
            # RGB gÃ¶rseli yÃ¼kle ve Grayscale'e Ã§evir
            img_rgb = cv2.imread(img_path)
            gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)

            # Histogram eÅŸitleme
            equalized = cv2.equalizeHist(gray)

            # Tekrar RGB'ye Ã§evirerek kaydet (3 kanal)
            equalized_rgb = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)
            save_path = os.path.join(class_output_path, filename)
            cv2.imwrite(save_path, equalized_rgb)

            # Kontrast Ã¶lÃ§
            contrast = calculate_contrast(equalized)
            contrast_values.append(contrast)

        except Exception as e:
            print(f"HATA: {filename} dosyasÄ±nda sorun var â†’ {e}")

    # Ä°statistikleri kaydet
    contrast_stats[cls] = {
        'mean': np.mean(contrast_values),
        'std': np.std(contrast_values),
        'min': np.min(contrast_values),
        'max': np.max(contrast_values),
        'n': len(contrast_values),
        'values': contrast_values
    }

# ğŸ” Kontrast istatistiklerini yazdÄ±r
for cls, stats in contrast_stats.items():
    print(f"\nğŸ“Š {cls} SÄ±nÄ±fÄ± Kontrast DaÄŸÄ±lÄ±mÄ±:")
    print(f"â€¢ Ortalama: {stats['mean']:.2f}")
    print(f"â€¢ Standart Sapma: {stats['std']:.2f}")
    print(f"â€¢ Min: {stats['min']:.2f}")
    print(f"â€¢ Max: {stats['max']:.2f}")
    print(f"â€¢ GÃ¶rsel SayÄ±sÄ±: {stats['n']}")

# ğŸ¨ Kontrast HistogramlarÄ±nÄ± Ã§iz
plt.figure(figsize=(12, 6))
for cls, stats in contrast_stats.items():
    plt.hist(stats['values'], bins=50, alpha=0.6, label=cls)
plt.title("ğŸ“ˆ Histogram EÅŸitleme SonrasÄ± GÃ¶rsel Kontrast DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Kontrast (Std. Dev.)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""# 13 Gaussian Blur


TÃ¼m sÄ±nÄ±flar iÃ§in kontrastÄ±n normalize edilmesi ve dar bir aralÄ±ÄŸa oturmasÄ±, modelin kontrasta baÄŸlÄ± aÅŸÄ±rÄ± Ã¶ÄŸrenme yapmasÄ±nÄ± engeller.

SonuÃ§:
Kontrast aralÄ±klarÄ± dengelendi ve Gaussian Blur ile gÃ¼rÃ¼ltÃ¼ler azaltÄ±ldÄ±.

Kontrast uÃ§larÄ± yok, bu da modelin aÅŸÄ±rÄ±ya kaÃ§masÄ±nÄ± engelleyecek.

TÃ¼m sÄ±nÄ±flar iÃ§in ortalamalar birbirine yakÄ±n (Â±1.75 aralÄ±ÄŸÄ±nda), bu Ã§ok iyi bir Ã¶n iÅŸleme sonucu!


"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from torchvision import transforms
from PIL import Image

# GiriÅŸ ve Ã§Ä±kÄ±ÅŸ yollarÄ±
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_hist_equalized"
blurred_augmented_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_blur_augmented"
os.makedirs(blurred_augmented_dir, exist_ok=True)

# Veri artÄ±rma transformlarÄ±
augmentations = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(degrees=15),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
])

# Gaussian blur parametresi
kernel_size = (3, 3)

# Ä°ÅŸlenmiÅŸ Ã¶rneklerden kontrast Ã¶lÃ§mek iÃ§in
contrast_map = {'malignant': [], 'benign': [], 'normal': []}

# Ä°ÅŸleme
for cls in os.listdir(input_dir):
    class_path = os.path.join(input_dir, cls)
    out_path = os.path.join(blurred_augmented_dir, cls)
    os.makedirs(out_path, exist_ok=True)

    for img_file in tqdm(os.listdir(class_path), desc=f"{cls} iÅŸleniyor"):
        img_path = os.path.join(class_path, img_file)

        # OpenCV ile oku ve Gaussian Blur uygula
        image = cv2.imread(img_path)
        blurred = cv2.GaussianBlur(image, kernel_size, 0)

        # RGB iÃ§in yeniden PIL'e Ã§evirip augment et
        pil_img = Image.fromarray(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))
        augmented_img = augmentations(pil_img)

        # Sonucu kaydet
        save_path = os.path.join(out_path, img_file)
        augmented_img.save(save_path)

        # Kontrast analizi iÃ§in: std (grayscale)
        gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)
        contrast_map[cls].append(np.std(gray))

# ğŸ¨ Kontrast DaÄŸÄ±lÄ±m GrafiÄŸi
plt.figure(figsize=(12, 6))
for cls in contrast_map:
    sns.histplot(contrast_map[cls], label=cls, kde=True, bins=30, alpha=0.5)
plt.title("ğŸ¯ Gaussian Blur + Augmentasyon SonrasÄ± GÃ¶rsel Kontrast DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Kontrast (Std. Dev.)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.legend()
plt.tight_layout()
plt.savefig("blur_augmented_contrast.png")
plt.show()

# ğŸ”¢ Ä°statistiksel Ã–zet
for cls, values in contrast_map.items():
    print(f"ğŸ“Š {cls.capitalize()} sÄ±nÄ±fÄ± (Gaussian Blur + Augmentation):")
    print(f"â€¢ Ortalama: {np.mean(values):.2f}")
    print(f"â€¢ Std. Sapma: {np.std(values):.2f}")
    print(f"â€¢ Min: {np.min(values):.2f}")
    print(f"â€¢ Max: {np.max(values):.2f}")
    print(f"â€¢ GÃ¶rsel SayÄ±sÄ±: {len(values)}\n")

"""TÃ¼m sÄ±nÄ±flar iÃ§in ortalamalar birbirine yakÄ±n (Â±1.75 aralÄ±ÄŸÄ±nda), bu Ã§ok iyi bir Ã¶n iÅŸleme sonucu!

# 14 Gaussian Blur + Augmentation

Yani gÃ¶rsellerin etrafÄ±ndaki boÅŸluklarÄ± temizleme veya gÃ¶rseli orantÄ±lÄ± bir ÅŸekilde geniÅŸleterek kare hale getirme iÅŸlemini gerÃ§ekleÅŸtireceÄŸiz.

 Bu AdÄ±mda AmaÃ§:
GÃ¶rseller farklÄ± oranlarda (en-boy oranÄ± â‰  1) olabilir.

Model iÃ§in giriÅŸ boyutlarÄ±nÄ± eÅŸitlemek gerekir.

Padding iÅŸlemiyle resimler kare formatta ve ortalanmÄ±ÅŸ olur.
"""

import os
from PIL import Image, ImageOps
import matplotlib.pyplot as plt

input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_blur_augmented"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_padded"
os.makedirs(output_dir, exist_ok=True)

# Her sÄ±nÄ±fÄ± iÅŸle
for class_name in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, class_name)
    class_output_path = os.path.join(output_dir, class_name)
    os.makedirs(class_output_path, exist_ok=True)

    for file_name in os.listdir(class_input_path):
        if not file_name.lower().endswith(('.png', '.jpg', '.jpeg')): continue

        img_path = os.path.join(class_input_path, file_name)
        img = Image.open(img_path)

        # Otomatik padding iÃ§in kareye merkezle
        padded_img = ImageOps.pad(img, size=(224, 224), color=(0, 0, 0))  # Siyah boÅŸluk eklenir

        padded_img.save(os.path.join(class_output_path, file_name))

"""DoÄŸrulama: Ã–rnek GÃ¶rsellerden Ã–nce/Sonra GÃ¶sterimi"""

import random

def show_before_after(sample_class):
    input_folder = os.path.join(input_dir, sample_class)
    output_folder = os.path.join(output_dir, sample_class)

    img_name = random.choice(os.listdir(input_folder))
    orig = Image.open(os.path.join(input_folder, img_name))
    padded = Image.open(os.path.join(output_folder, img_name))

    fig, axs = plt.subplots(1, 2, figsize=(8, 4))
    axs[0].imshow(orig)
    axs[0].set_title("ğŸ”¹ Orijinal")
    axs[1].imshow(padded)
    axs[1].set_title("ğŸ“ Padded (224x224)")
    for ax in axs: ax.axis("off")
    plt.suptitle(f"{sample_class} sÄ±nÄ±fÄ±ndan: {img_name}")
    plt.tight_layout()
    plt.show()

# Ã–rnek olarak bir sÄ±nÄ±f gÃ¶ster
show_before_after("malignant")

"""# 15 GÃ¶rÃ¼ntÃ¼ Åiddet Normalizasyonu / Sharpening (KeskinleÅŸtirme)

CT gÃ¶rÃ¼ntÃ¼lerindeki kenarlarÄ± ve detaylarÄ± daha belirgin hale getirerek modelin odaklanmasÄ±nÄ± kolaylaÅŸtÄ±rmak.

KullanÄ±lan YÃ¶ntem:

OpenCV cv2.filter2D() ile klasik sharpening filtresi

Her gÃ¶rÃ¼ntÃ¼ye keskinleÅŸtirme.


Ortalama kontrast ve keskinlik histogramÄ± .
"""

import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from PIL import Image

# GiriÅŸ ve Ã§Ä±kÄ±ÅŸ yollarÄ±
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_padded"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_sharpened"
os.makedirs(output_dir, exist_ok=True)

# KeskinleÅŸtirme filtresi
sharpen_kernel = np.array([[0, -1, 0],
                           [-1, 5, -1],
                           [0, -1, 0]])

# Kontrast deÄŸerlerini tut
contrast_dict = {}

# GÃ¶rselleÅŸtirme iÃ§in Ã¶rnek seÃ§elim
example_images = {}

# Her sÄ±nÄ±f iÃ§in iÅŸle
for cls in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, cls)
    class_output_path = os.path.join(output_dir, cls)
    os.makedirs(class_output_path, exist_ok=True)

    contrasts = []
    image_list = sorted(os.listdir(class_input_path))[:3]  # Ä°lk 3 gÃ¶rsel Ã¶rnek
    example_images[cls] = []

    for img_name in os.listdir(class_input_path):
        img_path = os.path.join(class_input_path, img_name)
        img = cv2.imread(img_path)

        # Apply sharpening
        sharpened = cv2.filter2D(img, -1, sharpen_kernel)

        # Save sharpened image
        cv2.imwrite(os.path.join(class_output_path, img_name), sharpened)

        # Kontrast (std dev)
        gray = cv2.cvtColor(sharpened, cv2.COLOR_BGR2GRAY)
        contrast = np.std(gray)
        contrasts.append(contrast)

        # Ã–rnek gÃ¶rsel topla
        if img_name in image_list:
            example_images[cls].append((img, sharpened, img_name))

    contrast_dict[cls] = contrasts

# ğŸ¨ Ã–rnek Ã¶nce-sonra karÅŸÄ±laÅŸtÄ±rmasÄ±
fig, axs = plt.subplots(len(example_images), 3, figsize=(12, 4*len(example_images)))
for i, cls in enumerate(example_images):
    for j, (original, sharpened, name) in enumerate(example_images[cls]):
        axs[i, j].imshow(np.hstack((original, sharpened)))
        axs[i, j].axis("off")
        axs[i, j].set_title(f"{cls}: {name}")
plt.suptitle("ğŸ” KeskinleÅŸtirme UygulamasÄ± (Ã–nce - Sonra)", fontsize=16)
plt.tight_layout()
plt.show()

# ğŸ“Š Kontrast histogramÄ±
plt.figure(figsize=(10, 5))
for cls, values in contrast_dict.items():
    plt.hist(values, bins=50, alpha=0.5, label=cls)
plt.xlabel("Kontrast (Std. Dev.)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.title("ğŸ“Š KeskinleÅŸtirme SonrasÄ± Kontrast DaÄŸÄ±lÄ±mÄ±")
plt.legend()
plt.grid(True)
plt.show()

# ğŸ“˜ Ortalama kontrastlar
for cls in contrast_dict:
    print(f"{cls} sÄ±nÄ±fÄ± kontrast ortalamasÄ±: {np.mean(contrast_dict[cls]):.2f} Â± {np.std(contrast_dict[cls]):.2f}")

"""# 16 Augmentasyon

Veri artÄ±rÄ±mÄ±, elimizdeki verileri Ã§eÅŸitlendirmek iÃ§in gÃ¶rseller Ã¼zerinde yapay Ã§eÅŸitlilik oluÅŸturur.
"""

import os
from PIL import Image, ImageOps
import random
from tqdm import tqdm
import matplotlib.pyplot as plt

input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_sharpened"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_augmented"
os.makedirs(output_dir, exist_ok=True)

def augment_image(image):
    transforms = [
        lambda x: x.transpose(Image.FLIP_LEFT_RIGHT),
        lambda x: x.transpose(Image.FLIP_TOP_BOTTOM),
        lambda x: x.rotate(15),
        lambda x: x.rotate(-15)
    ]
    return [t(image) for t in transforms]

# GÃ¶rselleri Ã§oÄŸalt ve kaydet
for class_name in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, class_name)
    class_output_path = os.path.join(output_dir, class_name)
    os.makedirs(class_output_path, exist_ok=True)

    for img_name in tqdm(os.listdir(class_input_path), desc=f"{class_name}"):
        if not img_name.endswith(".jpg"):
            continue
        img_path = os.path.join(class_input_path, img_name)
        image = Image.open(img_path).convert("RGB")
        image.save(os.path.join(class_output_path, img_name))  # Orijinali

        for i, aug in enumerate(augment_image(image)):
            aug_name = f"{os.path.splitext(img_name)[0]}_aug{i}.jpg"
            aug.save(os.path.join(class_output_path, aug_name))

# GÃ¶rsel Ã¶rnekleri gÃ¶ster
def show_augmented_examples(class_name, n=3):
    path = os.path.join(output_dir, class_name)
    sample_files = sorted([f for f in os.listdir(path) if f.endswith(".jpg")])[:n * 4]

    fig, axes = plt.subplots(n, 4, figsize=(12, 3 * n))
    for i in range(n):
        for j in range(4):
            idx = i * 4 + j
            img = Image.open(os.path.join(path, sample_files[idx]))
            axes[i, j].imshow(img)
            axes[i, j].axis("off")
            axes[i, j].set_title(sample_files[idx])
    plt.tight_layout()
    plt.suptitle(f"ğŸ“ˆ Augmentasyon SonrasÄ± Ã–rnek GÃ¶rseller ({class_name})", fontsize=16, y=1.02)
    plt.show()

show_augmented_examples("malignant")

"""Orijinal gÃ¶rselin Ã§eÅŸitli varyasyonlarÄ± (Ã§evirme, dÃ¶ndÃ¼rme) oluÅŸturuldu.

GÃ¶rÃ¼ntÃ¼ kalitesi ve medikal iÃ§erik korunarak veri Ã§eÅŸitliliÄŸi saÄŸlandÄ±.

Bu, overfitting riskini azaltÄ±r, modelin genel performansÄ±nÄ± artÄ±rÄ±r.
"""

import os
import matplotlib.pyplot as plt

# Augment edilmiÅŸ veri seti yolu
augmented_dataset_path = "/content/drive/MyDrive/processed_dataset/dataset_lung_augmented"

# Her sÄ±nÄ±ftaki gÃ¶rsel sayÄ±sÄ±nÄ± say
class_counts = {}
for cls in os.listdir(augmented_dataset_path):
    cls_path = os.path.join(augmented_dataset_path, cls)
    if os.path.isdir(cls_path):
        image_count = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        class_counts[cls] = image_count

# GÃ¶rselleÅŸtirme
plt.figure(figsize=(6, 4))
plt.bar(class_counts.keys(), class_counts.values(), color=["#FF9999", "#99CCFF", "#99FF99"])
plt.title("ğŸ“Š Augmentasyon SonrasÄ± SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("SÄ±nÄ±flar")
plt.ylabel("GÃ¶rsel SayÄ±sÄ±")
plt.grid(axis='y')
plt.show()

# YazÄ±lÄ± Ã§Ä±ktÄ±
print("ğŸ“¦ SÄ±nÄ±f DaÄŸÄ±lÄ±mlarÄ±:")
for cls, count in class_counts.items():
    print(f"â€¢ {cls}: {count} gÃ¶rÃ¼ntÃ¼")

# Dengesizlik deÄŸerlendirmesi
min_class = min(class_counts, key=class_counts.get)
max_class = max(class_counts, key=class_counts.get)
imbalance_ratio = class_counts[max_class] / class_counts[min_class]

print(f"\nğŸ” Dengesizlik OranÄ±: {imbalance_ratio:.2f}")
if imbalance_ratio > 1.2:
    print("âš ï¸ SÄ±nÄ±flar arasÄ±nda belirgin bir dengesizlik var. Oversampling Ã¶nerilir.")
else:
    print("âœ… SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± dengeli. Ek dengeleme gerekmez.")

"""#	**17	SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (Train/Val/Test iÃ§in ayrÄ±)**

"""

import os
import shutil
from sklearn.model_selection import train_test_split
from collections import defaultdict

# ğŸ”§ GiriÅŸ ve Ã§Ä±kÄ±ÅŸ klasÃ¶r yollarÄ±
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_augmented"
output_base = "/content/drive/MyDrive/processed_dataset/split_dataset"
os.makedirs(output_base, exist_ok=True)

# ğŸ“ Train, Val, Test oranlarÄ±
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# ğŸ“¦ GÃ¶rselleri sÄ±nÄ±fa gÃ¶re ayÄ±r
class_files = defaultdict(list)
for class_name in os.listdir(input_dir):
    class_path = os.path.join(input_dir, class_name)
    if not os.path.isdir(class_path):
        continue
    for file in os.listdir(class_path):
        if file.lower().endswith((".jpg", ".png", ".jpeg")):
            class_files[class_name].append(os.path.join(class_path, file))

# âœ‚ï¸ Train/Val/Test ayrÄ±mÄ± ve kopyalama
for class_name, file_list in class_files.items():
    train_files, temp_files = train_test_split(file_list, train_size=train_ratio, random_state=42)
    val_files, test_files = train_test_split(temp_files, test_size=test_ratio / (val_ratio + test_ratio), random_state=42)

    for split, files in zip(["train", "val", "test"], [train_files, val_files, test_files]):
        split_dir = os.path.join(output_base, split, class_name)
        os.makedirs(split_dir, exist_ok=True)
        for f in files:
            shutil.copy(f, os.path.join(split_dir, os.path.basename(f)))

print("âœ… Veriler Train/Val/Test olarak ayrÄ±ldÄ± ve kopyalandÄ±.")

# ğŸ”¢ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± raporu
import pandas as pd

distribution = {}
for split in ["train", "val", "test"]:
    for class_name in class_files.keys():
        path = os.path.join(output_base, split, class_name)
        count = len(os.listdir(path)) if os.path.exists(path) else 0
        distribution[(split, class_name)] = count

df = pd.DataFrame(distribution.items(), columns=["Split/Class", "Count"])
df = df.pivot(index="Split/Class", columns=None, values="Count")
print("\nğŸ“Š SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (Train/Val/Test):")
print(df)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# ğŸ”§ SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± tabloya dÃ¶nÃ¼ÅŸtÃ¼r
distribution_df = pd.DataFrame([
    {"split": split, "class": class_name, "count": count}
    for (split, class_name), count in distribution.items()
])

# ğŸ“Š Tablo olarak yazdÄ±r
pivot_df = distribution_df.pivot(index="class", columns="split", values="count")
print("ğŸ“Š SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± Tablosu (Train / Val / Test):")
print(pivot_df)

# ğŸ“ˆ Grafikle gÃ¶ster
plt.figure(figsize=(8, 5))
sns.barplot(data=distribution_df, x="class", y="count", hue="split")
plt.title("ğŸ“Š Train / Val / Test SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("SÄ±nÄ±f")
plt.ylabel("GÃ¶rsel SayÄ±sÄ±")
plt.tight_layout()
plt.show()

"""# **18 Entropi HesabÄ±**

Bu adÄ±mda, her bir sÄ±nÄ±fÄ±n entropi deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± histogram Ã¼zerinde gÃ¶stereceÄŸiz. Bu, bilgi yoÄŸunluÄŸunun sÄ±nÄ±flar arasÄ±nda nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶rsel olarak analiz etmemizi saÄŸlar.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# EÄŸitim setinde entropi analizi
data_dir = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
class_names = sorted(os.listdir(data_dir))

# Entropi hesaplama fonksiyonu
def calculate_entropy(img):
    hist = cv2.calcHist([img], [0], None, [256], [0, 256])
    hist_norm = hist.ravel() / hist.sum()
    entropy = -np.sum([p * np.log2(p) for p in hist_norm if p != 0])
    return entropy

# TÃ¼m sÄ±nÄ±flar iÃ§in entropileri topla
entropy_dict = {}

for cls in class_names:
    entropies = []
    class_dir = os.path.join(data_dir, cls)
    for fname in tqdm(os.listdir(class_dir), desc=f"{cls}"):
        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
            img_path = os.path.join(class_dir, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                entropies.append(calculate_entropy(img))
    entropy_dict[cls] = entropies

# ğŸ“Š HistogramlarÄ± Ã§iz
plt.figure(figsize=(12, 6))
for cls, values in entropy_dict.items():
    plt.hist(values, bins=50, alpha=0.6, label=f"{cls} (mean={np.mean(values):.2f})")

plt.title("ğŸ“Š Entropi DaÄŸÄ±lÄ±mÄ± HistogramÄ± (TÃ¼m SÄ±nÄ±flar)")
plt.xlabel("Entropi (bit)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **19**

# **Ortalama GÃ¶rÃ¼ntÃ¼ YoÄŸunluÄŸu KarÅŸÄ±laÅŸtÄ±rmasÄ±**

# **GÃ¶rsel Frekans Spektrumu Analizi (FFT)**

# **GÃ¶rÃ¼ntÃ¼ ZÄ±tlÄ±k (Seviye FarkÄ±) Analizi**

-

Kod, her sÄ±nÄ±f iÃ§in:

GÃ¶rÃ¼ntÃ¼ ortalamasÄ±nÄ±,

Frekans spektrum enerjisini (log-FFT),

Piksel seviyesinde kontrastÄ± (max-min farkÄ±) Ã§Ä±karÄ±r.

KDE eÄŸrileri ile karÅŸÄ±laÅŸtÄ±rmalÄ± analiz saÄŸlar.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import seaborn as sns

# ğŸ”§ GiriÅŸ dizini (gerekirse deÄŸiÅŸtir)
input_dir = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
classes = ["malignant", "benign", "normal"]

# ğŸ“Š Verileri saklayacak sÃ¶zlÃ¼k
mean_intensities = {}
fft_energies = {}
contrast_levels = {}

# ğŸ§ª Her sÄ±nÄ±f iÃ§in hesapla
for cls in classes:
    mean_vals, fft_vals, contrast_vals = [], [], []
    class_dir = os.path.join(input_dir, cls)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    for img_name in tqdm(image_files, desc=f"{cls}"):
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

        # Ortalama yoÄŸunluk
        mean_vals.append(np.mean(img))

        # FFT spektrumu
        f = np.fft.fft2(img)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = np.abs(fshift)
        energy = np.mean(np.log1p(magnitude_spectrum))  # log(1 + x) for stability
        fft_vals.append(energy)

        # Kontrast (Seviye farkÄ±)
        contrast = img.max() - img.min()
        contrast_vals.append(contrast)

    mean_intensities[cls] = mean_vals
    fft_energies[cls] = fft_vals
    contrast_levels[cls] = contrast_vals

# ğŸ“Š Ortalama YoÄŸunluk
plt.figure(figsize=(10, 5))
for cls in classes:
    sns.kdeplot(mean_intensities[cls], label=f"{cls} (mean={np.mean(mean_intensities[cls]):.2f})")
plt.title("ğŸ“Œ Ortalama GÃ¶rÃ¼ntÃ¼ YoÄŸunluÄŸu DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("YoÄŸunluk (0â€“255)")
plt.ylabel("YoÄŸunluk")
plt.legend()
plt.grid(True)
plt.show()

# âš¡ FFT Frekans Enerjisi
plt.figure(figsize=(10, 5))
for cls in classes:
    sns.kdeplot(fft_energies[cls], label=f"{cls} (mean={np.mean(fft_energies[cls]):.2f})")
plt.title("ğŸ“Š FFT TabanlÄ± Frekans Spektrumu Enerji DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("Log-Frekans Enerjisi")
plt.ylabel("YoÄŸunluk")
plt.legend()
plt.grid(True)
plt.show()

# ğŸ¯ Kontrast (Seviye FarkÄ±)
plt.figure(figsize=(10, 5))
for cls in classes:
    sns.kdeplot(contrast_levels[cls], label=f"{cls} (mean={np.mean(contrast_levels[cls]):.2f})")
plt.title("ğŸŒ“ GÃ¶rÃ¼ntÃ¼ ZÄ±tlÄ±ÄŸÄ± DaÄŸÄ±lÄ±mÄ± (Seviye FarkÄ±)")
plt.xlabel("Kontrast (max - min)")
plt.ylabel("YoÄŸunluk")
plt.legend()
plt.grid(True)
plt.show()

"""#*** 20 PCA + t-SNE ***
 Bu adÄ±mda gÃ¶rsellerin yÃ¼ksek boyutlu temsilini 2 boyuta indirerek sÄ±nÄ±flar arasÄ± ayrÄ±labilirliÄŸi gÃ¶rselleÅŸtiriyoruz. Bu iÅŸlem, veri setindeki Ã¶rneklerin benzerliklerini sezgisel olarak gÃ¶zlemlememizi saÄŸlar.

 sonuÃ§: PCA (Principal Component Analysis):
Avantaj: HÄ±zlÄ±dÄ±r ve bÃ¼yÃ¼k veri setleri iÃ§in uygundur.

SonuÃ§: PCA grafiÄŸinde sÄ±nÄ±flar (malignant, benign, normal) bÃ¼yÃ¼k Ã¶lÃ§Ã¼de Ã¼st Ã¼ste binmiÅŸ. Bu durum, sÄ±nÄ±flarÄ±n doÄŸrudan PCA dÃ¼zleminde Ã§ok ayrÄ±ÅŸmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor.

Yorum: GÃ¶rsellerin temel bileÅŸenleri (renk tonu, doku vb.) sÄ±nÄ±flar arasÄ±nda Ã§ok belirgin farklar Ã¼retmemiÅŸ olabilir.

 t-SNE (t-Distributed Stochastic Neighbor Embedding):
Avantaj: Daha karmaÅŸÄ±k, non-lineer iliÅŸkileri aÃ§Ä±ÄŸa Ã§Ä±karabilir.

SonuÃ§: t-SNE sonucunda kÄ±smi kÃ¼melenmeler gÃ¶rÃ¼lebiliyor ama yine Ã§ok belirgin bir ayrÄ±m gÃ¶zlenmiyor.

Yorum: GÃ¶rsel temsiller daha fazla iyileÅŸtirme veya farklÄ± Ã¶zellik mÃ¼hendisliÄŸi gerektirebilir. CNN tabanlÄ± feature extractorâ€™lar (Ã¶rneÄŸin VGG veya ResNet) ile Ã¶znitelik Ã§Ä±karÄ±mÄ± yapÄ±lÄ±rsa ayrÄ±m daha net olabilir.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from PIL import Image

# ğŸ“‚ Yol
data_dir = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
classes = ["malignant", "benign", "normal"]

# ğŸ”„ GÃ¶rselleri yÃ¼kle ve flatten et
image_vectors = []
labels = []

for cls in classes:
    class_dir = os.path.join(data_dir, cls)
    for fname in os.listdir(class_dir):
        if fname.lower().endswith(('.jpg', '.png', '.jpeg')):
            img_path = os.path.join(class_dir, fname)
            img = Image.open(img_path).convert("L").resize((64, 64))  # Daha kÃ¼Ã§Ã¼k boyut hÄ±z iÃ§in
            img_array = np.array(img).flatten()
            image_vectors.append(img_array)
            labels.append(cls)

X = np.array(image_vectors)
y = np.array(labels)

# ğŸ”„ StandartlaÅŸtÄ±rma
X_scaled = StandardScaler().fit_transform(X)

# ğŸ”¬ PCA (Ã¶nce kaba ayrÄ±m)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# ğŸŒ€ t-SNE (daha detaylÄ± gÃ¶rsel ayrÄ±m)
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_tsne = tsne.fit_transform(X_scaled)

# ğŸ¨ GÃ¶rselleÅŸtir (PCA)
plt.figure(figsize=(10, 5))
for cls in classes:
    plt.scatter(X_pca[y == cls, 0], X_pca[y == cls, 1], label=cls, alpha=0.5)
plt.title("ğŸ§¬ PCA ile GÃ¶rsel Temsil")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.legend()
plt.grid(True)
plt.show()

# ğŸ¨ GÃ¶rselleÅŸtir (t-SNE)
plt.figure(figsize=(10, 5))
for cls in classes:
    plt.scatter(X_tsne[y == cls, 0], X_tsne[y == cls, 1], label=cls, alpha=0.5)
plt.title("ğŸŒ€ t-SNE ile GÃ¶rsel Temsil")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.legend()
plt.grid(True)
plt.show()

"""# 21 Veri Seti Ä°statistikleri (Ortalama, Std, Min, Max)

sonuÃ§:

âœ… TÃ¼m sÄ±nÄ±flarÄ±n ortalama parlaklÄ±ÄŸÄ± oldukÃ§a yakÄ±n ve dengeli.
âœ… TÃ¼m sÄ±nÄ±flarda min/max deÄŸerleri 0â€“255 aralÄ±ÄŸÄ±nda. Bu, gÃ¶rsellerin tÃ¼m ton aralÄ±ÄŸÄ±nÄ± kapsadÄ±ÄŸÄ±nÄ± gÃ¶steriyor.
âœ… Standart sapma deÄŸerleri de benzer seviyelerde, bu da kontrast Ã§eÅŸitliliÄŸinin dengeli olduÄŸunu gÃ¶steriyor.
"""

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt

# ğŸ“ KlasÃ¶r yolu
dataset_path = "/content/drive/MyDrive/processed_dataset/split_dataset/train"

# ğŸ” SÄ±nÄ±flar
class_names = ["malignant", "benign", "normal"]

# ğŸ“Š Ä°statistikleri tutmak iÃ§in liste
statistics = []

# ğŸ” Her sÄ±nÄ±f iÃ§in tÃ¼m gÃ¶rsellerin istatistiklerini hesapla
for cls in class_names:
    cls_dir = os.path.join(dataset_path, cls)
    pixel_values = []

    for img_name in tqdm(os.listdir(cls_dir), desc=f"{cls}"):
        img_path = os.path.join(cls_dir, img_name)
        try:
            img = cv2.imread(img_path)
            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            pixel_values.extend(img_gray.flatten())
        except:
            continue

    pixel_values = np.array(pixel_values)
    stats = {
        "SÄ±nÄ±f": cls,
        "GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±": len(os.listdir(cls_dir)),
        "Ortalama Piksel": np.mean(pixel_values).round(2),
        "Std Sapma": np.std(pixel_values).round(2),
        "Min": np.min(pixel_values),
        "Max": np.max(pixel_values)
    }
    statistics.append(stats)

# ğŸ“‹ Tabloyu oluÅŸtur
df_stats = pd.DataFrame(statistics)
print(df_stats)

# ğŸ“ˆ GÃ¶rselleÅŸtirme (Opsiyonel)
df_stats_plot = df_stats.set_index("SÄ±nÄ±f")[["Ortalama Piksel", "Std Sapma"]]
df_stats_plot.plot(kind='bar', figsize=(10, 5), title="ğŸ“Š Ortalama ve Std Piksel DeÄŸerleri", colormap='viridis')
plt.ylabel("DeÄŸer (0-255)")
plt.xticks(rotation=0)
plt.grid(axis="y")
plt.tight_layout()
plt.show()

"""# 22 BoÅŸ GÃ¶rsel Tespiti ve Temizlenmesi ve GÃ¶rÃ¼ntÃ¼deki AÃ§Ä±k-KaranlÄ±k OranÄ± Ã–lÃ§Ã¼mÃ¼ (Mean Brightness)


Train/Val/Test iÃ§in ayrÄ±k ÅŸekilde parlaklÄ±k ortalamalarÄ± oldukÃ§a tutarlÄ±:

malignant: 122.68â€“122.80

benign: 121.21â€“121.42

normal: 122.12â€“122.60

DaÄŸÄ±lÄ±mlar dengeli ve sÄ±nÄ±flar arasÄ± bÃ¼yÃ¼k uÃ§urumlar yok â†’ Bu, modelin aydÄ±nlÄ±k/karanlÄ±k farklarÄ±ndan etkilenme riskini azaltÄ±r.

âœ… HiÃ§bir sÄ±nÄ±fta ciddi bir outlier parlaklÄ±k sapmasÄ± yok.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from collections import defaultdict

# ğŸ“ Ana veri dizini
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
brightness_data = defaultdict(list)
empty_images = []

# ğŸ” Train/Val/Test her biri iÃ§in gez
for split in ['train', 'val', 'test']:
    split_path = os.path.join(root_dir, split)
    for cls in os.listdir(split_path):
        class_dir = os.path.join(split_path, cls)
        if not os.path.isdir(class_dir):
            continue
        for fname in tqdm(os.listdir(class_dir), desc=f"ğŸ“‚ {split}/{cls}"):
            fpath = os.path.join(class_dir, fname)
            try:
                img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)
                if img is None or np.all(img == 0):
                    empty_images.append(fpath)
                    continue
                mean_brightness = np.mean(img)
                brightness_data[f"{split}/{cls}"].append(mean_brightness)
            except Exception:
                empty_images.append(fpath)

# ğŸ§¹ BoÅŸ/bozuk gÃ¶rsellerin silinmesi
for fpath in empty_images:
    if os.path.exists(fpath):
        os.remove(fpath)

# ğŸ“Š Ortalama parlaklÄ±k analizi
plt.figure(figsize=(12, 6))
for key, values in brightness_data.items():
    plt.hist(values, bins=40, alpha=0.6, label=f"{key} (mean={np.mean(values):.2f})")
plt.title("ğŸ’¡ Train/Val/Test AyrÄ±k Ortalama ParlaklÄ±k DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("ParlaklÄ±k (0â€“255)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# ğŸ“ Log
print("ğŸ§¹ Silinen boÅŸ/bozuk gÃ¶rsel sayÄ±sÄ±:", len(empty_images))

"""# 23 GÃ¶rÃ¼ntÃ¼lerde Kenar (Edge) Bilgisi YoÄŸunluÄŸu (Canny Edge)

sonuÃ§:

Malignant (kÃ¶tÃ¼ huylu) sÄ±nÄ±fÄ±ndaki edge yoÄŸunluÄŸu daha dÃ¼ÅŸÃ¼k. Bu, kenarlarÄ±n daha az belirgin veya daha yumuÅŸak yapÄ±da olduÄŸunu gÃ¶sterebilir.

Benign ve normal sÄ±nÄ±flar daha yÃ¼ksek edge oranÄ±na sahip, bu da daha fazla yapÄ±sal detay veya kenar geÃ§iÅŸi barÄ±ndÄ±rdÄ±klarÄ±nÄ± gÃ¶steriyor.

Bu fark, sÄ±nÄ±flandÄ±rma modelleri aÃ§Ä±sÄ±ndan ayÄ±rt edici bir sinyal olabilir.
"""

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
from tqdm import tqdm

# Dataset yolu
base_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]
classes = ["malignant", "benign", "normal"]

edge_densities = defaultdict(list)

# Her klasÃ¶r iÃ§in gezip Canny edge analizi yapalÄ±m
for split in splits:
    for cls in classes:
        class_path = os.path.join(base_dir, split, cls)
        for fname in tqdm(os.listdir(class_path), desc=f"{split}/{cls}"):
            fpath = os.path.join(class_path, fname)
            try:
                img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)
                if img is None: continue

                edges = cv2.Canny(img, 100, 200)
                edge_density = np.sum(edges > 0) / edges.size
                edge_densities[f"{split}/{cls}"].append(edge_density)
            except:
                continue

# ğŸ” Histogram grafiÄŸi
plt.figure(figsize=(12, 6))
for key, values in edge_densities.items():
    plt.hist(values, bins=50, alpha=0.5, label=f"{key} (mean={np.mean(values):.3f})")
plt.title("ğŸ§  Canny Edge YoÄŸunluÄŸu DaÄŸÄ±lÄ±mÄ± (Train/Val/Test + SÄ±nÄ±f BazlÄ±)")
plt.xlabel("Kenar YoÄŸunluÄŸu (Oran)")
plt.ylabel("GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±")
plt.legend()
plt.grid(True)
plt.show()

"""# 24 Etiketli CSV OluÅŸturma (filename, label, path, size, set) , Etiket Uyumu KontrolÃ¼ â€“ SÄ±nÄ±f Ä°smi ve Path UyuÅŸmazlÄ±klarÄ± , Ã‡oklu Etiket veya Evre Bilgisi Varsa AyrÄ±ÅŸtÄ±rma (Multi-Label) , Etiket TutarlÄ±lÄ±k Testi â€“ AynÄ± GÃ¶rselin Ä°ki FarklÄ± Etiketi Var mÄ±? ,Class Weights Hesaplama â€“ Model EÄŸitimi Ä°Ã§in.


**Ã–zellikler:**

Her sÄ±nÄ±f ve split iÃ§in gÃ¶rsel sayÄ±sÄ± Ã§ubuÄŸu Ã§izilir.

Label uyuÅŸmazlÄ±klarÄ± varsa tablo olarak gÃ¶sterilir.

Ã‡oklu etiket durumu tespit edilir.

AynÄ± dosya adÄ±na sahip ancak farklÄ± etiket almÄ±ÅŸ gÃ¶rseller varsa listelenir.

Class weights tablo formatÄ±nda sunulur.
"""

import os
import pandas as pd
from PIL import Image
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

# Ana dizin
base_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]
classes = ["malignant", "benign", "normal"]

# 1. Etiketli CSV oluÅŸturma
data = []
for split in splits:
    for cls in classes:
        class_dir = os.path.join(base_dir, split, cls)
        if not os.path.exists(class_dir):
            continue
        for fname in os.listdir(class_dir):
            fpath = os.path.join(class_dir, fname)
            try:
                with Image.open(fpath) as img:
                    width, height = img.size
            except:
                width, height = None, None
            data.append({
                "filename": fname,
                "label": cls,
                "full_path": fpath,
                "size": f"{width}x{height}",
                "set": split
            })

df = pd.DataFrame(data)

# 2. Etiket Uyumu KontrolÃ¼
df["path_match_label"] = df.apply(lambda row: row["label"] in row["full_path"], axis=1)
label_mismatches = df[~df["path_match_label"]]

# 3. Ã‡oklu Etiket KontrolÃ¼
df["multi_label"] = df["label"].apply(lambda x: "," in x)

# 4. AynÄ± gÃ¶rsele farklÄ± etiket atanmÄ±ÅŸ mÄ±?
conflicts_df = df.groupby("filename")["label"].nunique().reset_index()
conflicts_df = conflicts_df[conflicts_df["label"] > 1]

# 5. Class weights
label_counts = df["label"].value_counts().to_dict()
total = sum(label_counts.values())
class_weights = {cls: round(total / (len(label_counts) * count), 3) for cls, count in label_counts.items()}

# ğŸ” GÃ¶rselleÅŸtirme ve Ã§Ä±ktÄ±
print("âœ… Etiketli CSV oluÅŸturuldu. GÃ¶rsel tutarsÄ±zlÄ±klar ve istatistiksel analiz aÅŸaÄŸÄ±dadÄ±r:")

# ğŸ¯ 1. SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± gÃ¶rselleÅŸtirme
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="label", hue="set", palette="viridis")
plt.title("ğŸ“Š GÃ¶rsel SayÄ±sÄ± - SÄ±nÄ±f ve Set DaÄŸÄ±lÄ±mÄ±")
plt.xlabel("SÄ±nÄ±f")
plt.ylabel("Adet")
plt.tight_layout()
plt.show()

# ğŸ¯ 2. Label uyumsuzluklarÄ±
if not label_mismatches.empty:
    print(f"âš ï¸ Etiket uyuÅŸmazlÄ±ÄŸÄ± bulunan {len(label_mismatches)} gÃ¶rsel tespit edildi.")
    display(label_mismatches.head())
else:
    print("âœ… Etiket ve path uyumu tam.")

# ğŸ¯ 3. Multi-label kontrol
multi_count = df["multi_label"].sum()
print(f"ğŸ§© Multi-label etiketli gÃ¶rsel sayÄ±sÄ±: {multi_count}")

# ğŸ¯ 4. Etiket Ã§akÄ±ÅŸmasÄ± kontrolÃ¼
if not conflicts_df.empty:
    print(f"âš ï¸ FarklÄ± etiket atanmÄ±ÅŸ {len(conflicts_df)} gÃ¶rsel bulundu.")
    display(conflicts_df.head())
else:
    print("âœ… AynÄ± gÃ¶rsele birden fazla etiket atanmasÄ± durumu yok.")

# ğŸ¯ 5. Class weights
cw_df = pd.DataFrame.from_dict(class_weights, orient="index", columns=["Class Weight"]).reset_index()
cw_df.rename(columns={"index": "Class"}, inplace=True)
print("\nğŸ¯ Class Weights (Model iÃ§in Ã¶nerilen):")
display(cw_df)

# ğŸ”š Ã–zet
print("ğŸ” Analiz tamamlandÄ±. EÄŸitimde bu veriler Ä±ÅŸÄ±ÄŸÄ±nda dengeleme uygulanabilir.")

import os
import pandas as pd

# Split klasÃ¶r yolu
split_root = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]

# HatalÄ± etiketlenenleri tutmak iÃ§in liste
mismatch_entries = []

# Her split iÃ§in kontrol et
for split in splits:
    split_path = os.path.join(split_root, split)
    for class_name in os.listdir(split_path):
        class_dir = os.path.join(split_path, class_name)
        if not os.path.isdir(class_dir):
            continue
        for file in os.listdir(class_dir):
            if file.lower().endswith((".jpg", ".jpeg", ".png")):
                actual_path = os.path.join(class_dir, file)
                expected_label = class_name.lower()

                # Dosya adÄ±ndan label Ã§Ä±karmaya Ã§alÄ±ÅŸ
                # Ã–rn: "malignant - XYZ.jpg" â†’ "malignant"
                try:
                    file_label = file.split()[0].lower()
                except:
                    file_label = "unknown"

                if expected_label != file_label:
                    mismatch_entries.append({
                        "split": split,
                        "expected_label": expected_label,
                        "inferred_from_filename": file_label,
                        "file": file,
                        "path": actual_path
                    })

# SonuÃ§larÄ± DataFrame'e aktar
mismatch_df = pd.DataFrame(mismatch_entries)

# Durumu bildir
if mismatch_df.empty:
    print("âœ… TÃ¼m train/val/test dosyalarÄ±nÄ±n etiketleri dosya isimleriyle uyumlu.")
else:
    print(f"âŒ {len(mismatch_df)} etiket uyuÅŸmazlÄ±ÄŸÄ± bulundu:")
    display(mismatch_df.head())

"""# 25
# Kenar AlgÄ±lama (Edge Detection) â€“ Sobel, Prewitt, Canny gibi yÃ¶ntemlerle yapÄ± farklarÄ±nÄ± gÃ¶rselleÅŸtirme

ğŸ” AmaÃ§: GÃ¶rsellerdeki kenar bilgisi oranlarÄ±nÄ± Ã¶lÃ§mek
ğŸ“Š GÃ¶zlem:

malignant sÄ±nÄ±fÄ±nda kenar yoÄŸunluÄŸu genellikle daha az (%40â€“50 civarÄ±).

benign ve normal sÄ±nÄ±flarda daha yÃ¼ksek, geniÅŸ bir daÄŸÄ±lÄ±ma sahip.

â¡ Bu farklÄ±lÄ±k, kenar netliÄŸi Ã¼zerinden ayrÄ±m yapacak bir modelde kullanÄ±labilir.

# HOG (Histogram of Oriented Gradients) GÃ¶rselleÅŸtirme â€“ SÄ±nÄ±flar arasÄ± yapÄ±sal yÃ¶n bilgisini karÅŸÄ±laÅŸtÄ±rma

AmaÃ§: Kenar yÃ¶nelimlerini (gradient) gÃ¶rselleÅŸtirmek
ğŸ“· GÃ¶zlem: FFT gÃ¶rselleri:

Malignant gÃ¶rÃ¼ntÃ¼lerde daha yoÄŸun merkez bÃ¶lgesi (daha fazla dÃ¼ÅŸÃ¼k frekanslÄ± detay).

Normal ve benign sÄ±nÄ±flarda daha homojen yapÄ±lar gÃ¶rÃ¼lÃ¼yor.

â¡ YapÄ±sal yoÄŸunluk farklarÄ± tespit edilmiÅŸ, bu HOG gibi kenara duyarlÄ± CNN tabanlÄ± modeller iÃ§in Ã¶nemlidir.

# Fourier Transform GÃ¶rsel Analizi â€“ Frekans spektrumu ile doku ve dÃ¼zen tespiti

ğŸ” AmaÃ§: GÃ¶rsellerdeki frekans bileÅŸenlerinin enerji daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶rmek
ğŸ“· GÃ¶zlem:

FFT Ã§Ä±ktÄ±larÄ± tÃ¼m sÄ±nÄ±flarda benzer gÃ¶rÃ¼nÃ¼yor ama malignant daha belirgin dÃ¼ÅŸey frekans Ã§izgileri taÅŸÄ±yor.

Bu, bazÄ± radyolojik paternlerin frekans uzayÄ±nda daha belirgin olduÄŸunu gÃ¶steriyor olabilir.

â¡ Frekans domain'i kullanÄ±larak Ã¶zellik Ã§Ä±karÄ±mÄ± yapÄ±labilir.

# Gabor Filter ile TekstÃ¼r Ã–zellikleri â€“ Doku analizi iÃ§in Gabor filtre haritalarÄ±

ğŸ” AmaÃ§: GÃ¶rÃ¼ntÃ¼deki yÃ¼zey ve doku farklÄ±lÄ±klarÄ±nÄ± (tekstÃ¼r) yakalamak
ğŸ“· GÃ¶zlem:

malignant doku haritalarÄ± daha yoÄŸun ve ayrÄ±k.

normal daha dÃ¼zgÃ¼n ve tekstÃ¼rel detaylarÄ± daha az.

â¡ Gabor filtreleri, CNN Ã¶ncesi Ã¶zellik Ã§Ä±karÄ±mÄ± iÃ§in etkili olabilir.

# VGG/ResNet ile Feature Embedding Ã‡Ä±karÄ±mÄ± â€“ Modelden vektÃ¶r temsili alÄ±p PCA/t-SNE ile gÃ¶rselleÅŸtirme

ğŸ” AmaÃ§: Derin bir modelden gÃ¶rÃ¼ntÃ¼ temsillerini alarak sÄ±nÄ±flar arasÄ± ayrÄ±mÄ± test etmek
ğŸ“Š GÃ¶zlem:

VGG16â€™dan alÄ±nan Ã¶zelliklerin daÄŸÄ±lÄ±mÄ± normal sÄ±nÄ±fta daha dÃ¼ÅŸÃ¼k yoÄŸunluklu.

malignant ve benign daha zengin ve farklÄ± bir daÄŸÄ±lÄ±m sergiliyor.

â¡ Bu adÄ±m modelin sÄ±nÄ±flarÄ± ayÄ±rt edebilirliÄŸini gÃ¶steren gÃ¼Ã§lÃ¼ bir adÄ±mdÄ±.


"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage.filters import gabor
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model
from tqdm import tqdm
from scipy.fft import fft2, fftshift
import seaborn as sns
import pandas as pd

base_path = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]
classes = ["malignant", "benign", "normal"]

edge_means = []

for split in splits:
    for cls in classes:
        folder = os.path.join(base_path, split, cls)
        for img_file in tqdm(sorted(os.listdir(folder))[:50], desc=f"Canny: {split}/{cls}"):
            img_path = os.path.join(folder, img_file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            edges = cv2.Canny(img, 100, 200)
            edge_mean = np.mean(edges)
            edge_means.append({"split": split, "class": cls, "mean_edge": edge_mean})

df_edge = pd.DataFrame(edge_means)
plt.figure(figsize=(8, 4))
sns.boxplot(data=df_edge, x="class", y="mean_edge", hue="split")
plt.title("ğŸ” Canny Edge YoÄŸunluÄŸu")
plt.show()

plt.figure(figsize=(12, 6))
i = 1
for cls in classes:
    path = os.path.join(base_path, "train", cls)
    img_path = os.path.join(path, sorted(os.listdir(path))[0])
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    f = fftshift(fft2(img))
    magnitude_spectrum = 20 * np.log(np.abs(f) + 1)
    plt.subplot(1, 3, i)
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.title(f"FFT - {cls}")
    plt.axis('off')
    i += 1
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
i = 1
for cls in classes:
    path = os.path.join(base_path, "train", cls)
    img_path = os.path.join(path, sorted(os.listdir(path))[0])
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    filt_real, _ = gabor(img, frequency=0.6)
    plt.subplot(1, 3, i)
    plt.imshow(filt_real, cmap='gray')
    plt.title(f"Gabor - {cls}")
    plt.axis('off')
    i += 1
plt.tight_layout()
plt.show()

model = VGG16(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
feat_model = Model(inputs=model.input, outputs=model.output)

features = []
for cls in classes:
    folder = os.path.join(base_path, "train", cls)
    for img_file in tqdm(sorted(os.listdir(folder))[:5], desc=f"VGG16 Features - {cls}"):
        img_path = os.path.join(folder, img_file)
        img = load_img(img_path, target_size=(224, 224))
        x = img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        feat = feat_model.predict(x)
        features.append({"class": cls, "flatten_feat": feat.flatten()[:50].mean()})  # Ã¶rnek

df_feat = pd.DataFrame(features)
sns.boxplot(data=df_feat, x="class", y="flatten_feat")
plt.title("ğŸ” VGG16 Ã–zellik DaÄŸÄ±lÄ±mÄ± (Ortalama Ä°lk 50 DeÄŸer)")
plt.show()

import os
import time
import cv2
import torch
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt

# Dataset sÄ±nÄ±fÄ±
class SimpleImageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.image_paths = []
        self.labels = []
        self.transform = transform

        for cls in os.listdir(root_dir):
            cls_path = os.path.join(root_dir, cls)
            if not os.path.isdir(cls_path): continue
            for fname in os.listdir(cls_path):
                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
                    self.image_paths.append(os.path.join(cls_path, fname))
                    self.labels.append(cls)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = cv2.imread(self.image_paths[idx])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx]

# 1ï¸âƒ£ Transform ve dataset
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
dataset_path = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
dataset = SimpleImageDataset(dataset_path, transform=transform)

# 2ï¸âƒ£ DataLoader test
loader = DataLoader(dataset, batch_size=32, shuffle=True)
start = time.time()
for batch in loader:
    images, labels = batch
    break
end = time.time()
print(f"â±ï¸ Ä°lk batch yÃ¼kleme sÃ¼resi: {end - start:.4f} saniye")

# 3ï¸âƒ£ Augmentasyon testi
aug_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
sample_path = dataset.image_paths[0]
orig = cv2.imread(sample_path)
orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)
aug = aug_transform(orig)

# GÃ¶rselleÅŸtir
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(orig)
plt.title("ğŸ–¼ï¸ Orijinal")
plt.axis("off")
plt.subplot(1, 2, 2)
plt.imshow(aug.permute(1, 2, 0))
plt.title("ğŸ¨ Augmented")
plt.axis("off")
plt.tight_layout()
plt.show()

"""# **MODEL EÄÄ°TÄ°MLERÄ°**
---------------------------
YAPILACAK Ä°ÅLEMLER:

KapsamlÄ± Model EÄŸitimi YapÄ±lacak Modeller:
 (hem klasik hem derin Ã¶ÄŸrenme):

ğŸ¯ Klasik Modeller (scikit-learn):
Random Forest

SVM

XGBoost

LightGBM

CatBoost

ğŸ¤– Derin Ã–ÄŸrenme Modelleri (PyTorch / Keras):
CNN (Scratch)

Transfer Learning:

VGG16

ResNet50

EfficientNetB0

MobileNetV2


**Her model iÃ§in:**

Confusion Matrix

ROC-AUC Curve

Precision-Recall Curve

Accuracy/F1 Score tablosu

Epoch bazlÄ± loss/accuracy grafik

Classification Report

Feature importance (varsa)

Grad-CAM haritalarÄ± (DL modellerde)
"""

# âœ… TÃ¼m modelleri karÅŸÄ±laÅŸtÄ±rmalÄ± eÄŸiten, A100 iÃ§in optimize edilmiÅŸ eÄŸitim pipeline'Ä±
# KullanÄ±lan modeller: ResNet50, EfficientNetB0, MobileNetV2, VGG16, SVM, XGBoost, LightGBM, CatBoost
# Ã–lÃ§Ã¼len metrikler: Accuracy, Precision, Recall, F1-Score, AUC, Confusion Matrix, Loss/EÄŸri, Grad-CAM, Feature Importance

import os
import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

# ğŸ”§ DonanÄ±m AyarÄ±
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("KullanÄ±lan cihaz:", device)

# âœ… DataLoader ayarlarÄ±
batch_size = 64
input_size = 224

data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

# ğŸ“‚ Dataset Yolu
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
datasets = {x: ImageFolder(os.path.join(root_dir, x), transform=data_transforms[x]) for x in ['train', 'val']}
dataloaders = {x: DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}
class_names = datasets['train'].classes

# ğŸ“¦ Model listesi
def get_model(name):
    if name == 'resnet50':
        model = models.resnet50(weights='IMAGENET1K_V1')
        model.fc = nn.Linear(model.fc.in_features, len(class_names))
    elif name == 'efficientnet':
        model = models.efficientnet_b0(weights='IMAGENET1K_V1')
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))
    elif name == 'mobilenetv2':
        model = models.mobilenet_v2(weights='IMAGENET1K_V1')
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))
    elif name == 'vgg16':
        model = models.vgg16(weights='IMAGENET1K_V1')
        model.classifier[6] = nn.Linear(model.classifier[6].in_features, len(class_names))
    else:
        raise ValueError("Model bilinmiyor.")
    return model.to(device)

# ğŸ¯ EÄŸitim Fonksiyonu
criterion = nn.CrossEntropyLoss()
def train_model(model, epochs=70, lr=2e-5):
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    train_loss_hist, val_loss_hist = [], []
    best_acc = 0.0

    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in tqdm(dataloaders[phase]):
                inputs, labels = inputs.to(device), labels.to(device)

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        optimizer.zero_grad()
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(datasets[phase])
            epoch_acc = running_corrects.double() / len(datasets[phase])

            if phase == 'train':
                train_loss_hist.append(epoch_loss)
                scheduler.step()
            else:
                val_loss_hist.append(epoch_loss)

            print(f"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                torch.save(model.state_dict(), f"best_{model.__class__.__name__}.pt")

    return model, train_loss_hist, val_loss_hist

# ğŸ” DeÄŸerlendirme
@torch.no_grad()
def evaluate_model(model):
    model.eval()
    all_preds, all_labels, all_probs = [], [], []
    for inputs, labels in dataloaders['val']:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        probs = torch.softmax(outputs, dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())

    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)
    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)
    df_report = pd.DataFrame(report).transpose()

    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    plt.show()

    # ROC-AUC Curve
    try:
        y_true = np.array(pd.get_dummies(all_labels))
        y_score = np.array(all_probs)
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(len(class_names)):
            fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        plt.figure(figsize=(8,6))
        for i in range(len(class_names)):
            plt.plot(fpr[i], tpr[i], label=f"{class_names[i]} (AUC = {roc_auc[i]:.2f})")
        plt.plot([0, 1], [0, 1], 'k--')
        plt.title("ROC-AUC Curve")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.legend()
        plt.grid()
        plt.tight_layout()
        plt.show()
    except:
        print("ROC Curve Ã§izimi baÅŸarÄ±sÄ±z (olasÄ±lÄ±klar eksik olabilir).")

    return df_report

# ğŸ” TÃ¼m modelleri eÄŸit
models_to_train = ['resnet50', 'efficientnet', 'mobilenetv2', 'vgg16']
results = {}

for name in models_to_train:
    print(f"\nğŸ§  Model: {name}")
    model = get_model(name)
    trained_model, train_loss, val_loss = train_model(model, epochs=70, lr=2e-5)
    metrics_df = evaluate_model(trained_model)
    results[name] = metrics_df

# ğŸ“Š KarÅŸÄ±laÅŸtÄ±rmalÄ± grafikler
overall_df = pd.DataFrame({name: df.loc['accuracy']['f1-score'] for name, df in results.items()}, index=["F1 Score"])
overall_df.T.plot(kind='bar', figsize=(10,6), legend=False)
plt.title("ğŸ“Š Model Performans KarÅŸÄ±laÅŸtÄ±rmasÄ± (F1 Score)")
plt.ylabel("F1")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""# TEST"""

# ğŸ” GeliÅŸmiÅŸ Model KarÅŸÄ±laÅŸtÄ±rmalÄ± Test & Analiz Scripti (Grad-CAM++ hariÃ§)

import os
import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, roc_curve,
                             precision_recall_curve, accuracy_score, f1_score, cohen_kappa_score,
                             matthews_corrcoef, log_loss, top_k_accuracy_score, auc)
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision import transforms
from tqdm import tqdm
from torchvision.models import efficientnet_b0, resnet50, mobilenet_v2, vgg16

# âœ… Model listesi
model_names = ["EfficientNetB0", "ResNet50", "MobileNetV2", "VGG16"]
model_paths = {
    "EfficientNetB0": "/content/best_EfficientNet.pt",
    "ResNet50": "/content/best_ResNet.pt",
    "MobileNetV2": "/content/best_MobileNetV2.pt",
    "VGG16": "/content/best_VGG.pt",
}

# âœ… Veriseti Yolu & Transforms
input_size = 224
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
data_transforms = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
test_dataset = ImageFolder(os.path.join(root_dir, 'test'), transform=data_transforms)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)
class_names = test_dataset.classes

# âœ… Model oluÅŸturma fonksiyonlarÄ±
def EfficientNetB0():
    model = efficientnet_b0(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def ResNet50():
    model = resnet50(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))
    return model

def MobileNetV2():
    model = mobilenet_v2(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def VGG16():
    model = vgg16(weights=None)
    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, len(class_names))
    return model

# âœ… Model eÅŸlemesi
model_builders = {
    "EfficientNetB0": EfficientNetB0,
    "ResNet50": ResNet50,
    "MobileNetV2": MobileNetV2,
    "VGG16": VGG16
}

# âœ… Ana deÄŸerlendirme fonksiyonu
def evaluate_all_models():
    results = []
    for model_name in model_names:
        print(f"\nğŸ“Œ Evaluating {model_name}...")

        # âœ… Model oluÅŸtur ve aÄŸÄ±rlÄ±klarÄ± yÃ¼kle
        model = model_builders[model_name]()
        state_dict = torch.load(model_paths[model_name])
        model.load_state_dict(state_dict)
        model.eval()
        model.cuda()

        y_true, y_pred, y_probs = [], [], []
        embeddings, labels = [], []

        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs, targets = inputs.cuda(), targets.cuda()
                outputs = model(inputs)
                probs = torch.softmax(outputs, dim=1)
                _, preds = torch.max(probs, 1)
                y_true.extend(targets.cpu().numpy())
                y_pred.extend(preds.cpu().numpy())
                y_probs.extend(probs.cpu().numpy())
                embeddings.append(outputs.cpu().numpy())
                labels.append(targets.cpu().numpy())

        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_probs = np.array(y_probs)
        embeddings = np.concatenate(embeddings)
        labels = np.concatenate(labels)

        # ğŸ“Š Metrikler
        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average='macro')
        kappa = cohen_kappa_score(y_true, y_pred)
        mcc = matthews_corrcoef(y_true, y_pred)
        logloss = log_loss(y_true, y_probs)
        top3 = top_k_accuracy_score(y_true, y_probs, k=3)
        top5 = top_k_accuracy_score(y_true, y_probs, k=5)

        # ğŸ“Œ Confusion Matrix
        cm = confusion_matrix(y_true, y_pred, normalize='true')
        sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, cmap="Blues")
        plt.title(f"{model_name} - Normalized Confusion Matrix")
        plt.show()

        # ğŸ“Œ ROC-AUC per Class
        y_onehot = np.eye(len(class_names))[y_true]
        for i in range(len(class_names)):
            fpr, tpr, _ = roc_curve(y_onehot[:, i], y_probs[:, i])
            prec, rec, _ = precision_recall_curve(y_onehot[:, i], y_probs[:, i])
            plt.plot(fpr, tpr, label=f"{class_names[i]} AUC={auc(fpr, tpr):.2f}")
        plt.legend()
        plt.title(f"{model_name} - ROC-AUC per Class")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.grid(True)
        plt.show()

        # ğŸ“Œ T-SNE GÃ¶rselleÅŸtirme
        reducer = TSNE(n_components=2, perplexity=30)
        emb_2d = reducer.fit_transform(embeddings)
        plt.figure(figsize=(6, 5))
        sns.scatterplot(x=emb_2d[:, 0], y=emb_2d[:, 1], hue=[class_names[i] for i in labels], palette='deep')
        plt.title(f"{model_name} - t-SNE Embeddings")
        plt.show()

        results.append({
            "Model": model_name,
            "Accuracy": acc,
            "F1": f1,
            "Kappa": kappa,
            "MCC": mcc,
            "LogLoss": logloss,
            "Top-3 Acc": top3,
            "Top-5 Acc": top5
        })

    # ğŸ“‹ Tablolu karÅŸÄ±laÅŸtÄ±rma
    df = pd.DataFrame(results)
    display(df)
    sns.barplot(x="Model", y="Accuracy", data=df)
    plt.title("Model Accuracy KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    plt.show()

    sns.barplot(x="Model", y="F1", data=df)
    plt.title("Model F1 Score KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    plt.show()

# âœ… Fonksiyonu Ã§aÄŸÄ±r
evaluate_all_models()

# ğŸ” GeliÅŸmiÅŸ Model KarÅŸÄ±laÅŸtÄ±rma, Analiz, Validation, ROC-AUC, HatalÄ± GÃ¶sterim, CSV Kaydetme

import os
import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, roc_curve,
                             precision_recall_curve, accuracy_score, f1_score, cohen_kappa_score,
                             matthews_corrcoef, log_loss, top_k_accuracy_score, auc)
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision import transforms
from tqdm import tqdm
from torchvision.models import efficientnet_b0, resnet50, mobilenet_v2, vgg16

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# âœ… Model listesi
model_names = ["EfficientNetB0", "ResNet50", "MobileNetV2", "VGG16"]
model_paths = {
    "EfficientNetB0": "/content/best_EfficientNet.pt",
    "ResNet50": "/content/best_ResNet.pt",
    "MobileNetV2": "/content/best_MobileNetV2.pt",
    "VGG16": "/content/best_VGG.pt",
}

# âœ… Veriseti Yolu & Transforms
input_size = 224
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
data_transforms = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
test_dataset = ImageFolder(os.path.join(root_dir, 'test'), transform=data_transforms)
val_dataset = ImageFolder(os.path.join(root_dir, 'val'), transform=data_transforms)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)
class_names = test_dataset.classes

# âœ… Model oluÅŸturma fonksiyonlarÄ±
def EfficientNetB0():
    model = efficientnet_b0(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def ResNet50():
    model = resnet50(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))
    return model

def MobileNetV2():
    model = mobilenet_v2(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def VGG16():
    model = vgg16(weights=None)
    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, len(class_names))
    return model

model_builders = {
    "EfficientNetB0": EfficientNetB0,
    "ResNet50": ResNet50,
    "MobileNetV2": MobileNetV2,
    "VGG16": VGG16
}

# âœ… HatalÄ± SÄ±nÄ±flandÄ±rÄ±lan GÃ¶sterimi

def show_misclassified_images(model, dataloader, num_images=6):
    model.eval()
    incorrect = []
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            for i in range(len(labels)):
                if preds[i] != labels[i]:
                    incorrect.append((inputs[i].cpu(), preds[i].item(), labels[i].item()))
                if len(incorrect) >= num_images:
                    break
            if len(incorrect) >= num_images:
                break

    fig, axes = plt.subplots(1, len(incorrect), figsize=(15, 5))
    for i, (img, pred, true) in enumerate(incorrect):
        axes[i].imshow(img.permute(1, 2, 0))
        axes[i].set_title(f"P: {class_names[pred]}\nT: {class_names[true]}")
        axes[i].axis('off')
    plt.tight_layout()
    plt.show()

# âœ… ROC-AUC KarÅŸÄ±laÅŸtÄ±rma

def compare_roc_auc(results_list):
    plt.figure(figsize=(8, 6))
    for result in results_list:
        model_name = result["Model"]
        probs = result["Probs"]
        y_true = result["True"]
        y_onehot = np.eye(len(class_names))[y_true]
        auc_sum = 0
        for i in range(len(class_names)):
            fpr, tpr, _ = roc_curve(y_onehot[:, i], probs[:, i])
            auc_score = auc(fpr, tpr)
            auc_sum += auc_score
        avg_auc = auc_sum / len(class_names)
        plt.bar(model_name, avg_auc)
    plt.ylabel("Average ROC-AUC Score")
    plt.title("ROC-AUC KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    plt.grid(True)
    plt.show()

# âœ… Validation iÃ§in ayrÄ± fonksiyon

def evaluate_model_on_loader(model, dataloader, name="Validation"):
    model.eval()
    y_true, y_pred, y_probs = [], [], []
    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            probs = torch.softmax(outputs, dim=1)
            _, preds = torch.max(probs, 1)
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())
            y_probs.extend(probs.cpu().numpy())
    print(f"\n{name} Accuracy:", accuracy_score(y_true, y_pred))
    print(f"{name} F1 Score:", f1_score(y_true, y_pred, average='macro'))

# âœ… Ana fonksiyon

def evaluate_all_models():
    results = []
    for model_name in model_names:
        print(f"\n\U0001f4cc Evaluating {model_name}...")
        model = model_builders[model_name]()
        state_dict = torch.load(model_paths[model_name])
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()

        y_true, y_pred, y_probs = [], [], []
        embeddings, labels = [], []

        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                probs = torch.softmax(outputs, dim=1)
                _, preds = torch.max(probs, 1)
                y_true.extend(targets.cpu().numpy())
                y_pred.extend(preds.cpu().numpy())
                y_probs.extend(probs.cpu().numpy())
                embeddings.append(outputs.cpu().numpy())
                labels.append(targets.cpu().numpy())

        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_probs = np.array(y_probs)
        embeddings = np.concatenate(embeddings)
        labels = np.concatenate(labels)

        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average='macro')
        kappa = cohen_kappa_score(y_true, y_pred)
        mcc = matthews_corrcoef(y_true, y_pred)
        logloss = log_loss(y_true, y_probs)
        top3 = top_k_accuracy_score(y_true, y_probs, k=3)
        top5 = top_k_accuracy_score(y_true, y_probs, k=5)

        cm = confusion_matrix(y_true, y_pred, normalize='true')
        sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, cmap="Blues")
        plt.title(f"{model_name} - Normalized Confusion Matrix")
        plt.show()

        reducer = TSNE(n_components=2, perplexity=30)
        emb_2d = reducer.fit_transform(embeddings)
        plt.figure(figsize=(6, 5))
        sns.scatterplot(x=emb_2d[:, 0], y=emb_2d[:, 1], hue=[class_names[i] for i in labels], palette='deep')
        plt.title(f"{model_name} - t-SNE Embeddings")
        plt.show()

        show_misclassified_images(model, test_loader)

        results.append({
            "Model": model_name,
            "Accuracy": acc,
            "F1": f1,
            "Kappa": kappa,
            "MCC": mcc,
            "LogLoss": logloss,
            "Top-3 Acc": top3,
            "Top-5 Acc": top5,
            "True": y_true,
            "Probs": y_probs
        })

    df = pd.DataFrame(results)
    display(df)
    df.to_csv("model_sonuclari.csv", index=False)

    sns.barplot(x="Model", y="Accuracy", data=df)
    plt.title("Model Accuracy KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    plt.show()

    sns.barplot(x="Model", y="F1", data=df)
    plt.title("Model F1 Score KarÅŸÄ±laÅŸtÄ±rmasÄ±")
    plt.show()

    compare_roc_auc(results)

# âœ… Fonksiyonu Ã§aÄŸÄ±r
evaluate_all_models()

# Ä°steÄŸe baÄŸlÄ±: Validation seti ayrÄ±ca deÄŸerlendirme
model = model_builders["EfficientNetB0"]()
model.load_state_dict(torch.load(model_paths["EfficientNetB0"]))
model.to(device)
evaluate_model_on_loader(model, val_loader, name="Validation")

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from torchvision.datasets import ImageFolder
from torchvision import transforms
from torch.utils.data import DataLoader
from PIL import Image

# ğŸ“‚ Dataset yolu
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
subsets = ['train', 'val', 'test']

# ğŸ“Œ DÃ¶nÃ¼ÅŸtÃ¼rme
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# ğŸ“Š Veri daÄŸÄ±lÄ±mÄ± analizi ve Ã¶rnek gÃ¶sterimi
def analyze_dataset_structure():
    summary = []

    for subset in subsets:
        dataset = ImageFolder(os.path.join(root_dir, subset), transform=data_transforms)
        class_names = dataset.classes
        class_counts = {cls: 0 for cls in class_names}
        file_paths = {cls: [] for cls in class_names}

        for path, label in dataset.samples:
            class_name = class_names[label]
            class_counts[class_name] += 1
            file_paths[class_name].append(path)

        for cls in class_names:
            summary.append({
                "Subset": subset,
                "Class": cls,
                "Count": class_counts[cls],
                "Example Paths": file_paths[cls][:3]  # ilk 3 Ã¶rnek yolu
            })

    df_summary = pd.DataFrame(summary)
    display(df_summary)

    # ğŸ“ˆ GÃ¶rselleÅŸtirme
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_summary, x="Class", y="Count", hue="Subset")
    plt.title("Veri Seti SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (Train/Val/Test)")
    plt.ylabel("Adet")
    plt.xlabel("SÄ±nÄ±f")
    plt.tight_layout()
    plt.show()

    # ğŸ–¼ï¸ Ã–rnek gÃ¶rseller (ilk 3 her sÄ±nÄ±ftan her alt set iÃ§in)
    for subset in subsets:
        dataset = ImageFolder(os.path.join(root_dir, subset))
        class_names = dataset.classes
        print(f"\nğŸ“Œ {subset.upper()} Ã¶rnekleri:\n")

        fig, axes = plt.subplots(nrows=len(class_names), ncols=3, figsize=(9, 3 * len(class_names)))
        for i, cls in enumerate(class_names):
            cls_paths = [p for p, label in dataset.samples if dataset.classes[label] == cls][:3]
            for j, img_path in enumerate(cls_paths):
                img = Image.open(img_path)
                axes[i, j].imshow(img, cmap='gray')
                axes[i, j].set_title(f"{cls}")
                axes[i, j].axis("off")
        plt.tight_layout()
        plt.show()

# âœ… Ã‡aÄŸÄ±r
analyze_dataset_structure()

"""# DenseNet201', 'InceptionV3', 'EfficientNetV2', 'ConvNeXt' EÄÄ°TÄ°MLERÄ°"""

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import densenet201, inception_v3, convnext_base, efficientnet_v2_s
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# --------------------- Tekrarlanabilirlik iÃ§in seed atama ---------------------
def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

# --------------------- Erken durdurma ---------------------
class EarlyStopping:
    def __init__(self, patience=7, delta=1e-4, save_path="best_model.pt"):
        self.patience = patience
        self.delta = delta
        self.save_path = save_path
        self.best_score = None
        self.counter = 0

    def step(self, metric, model):
        score = metric
        if self.best_score is None or score > self.best_score + self.delta:
            self.best_score = score
            self.counter = 0
            torch.save(model.state_dict(), self.save_path)
        else:
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False

# --------------------- KonfigÃ¼rasyon ---------------------
set_seed(2025)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

epochs = 50
batch_size = 32
lr = 1e-4
weight_decay = 1e-5
num_classes = 3
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
models_to_train = ['DenseNet201', 'InceptionV3', 'EfficientNetV2', 'ConvNeXt']

# --------------------- Veri artÄ±rma ---------------------
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# --------------------- Dataset & DataLoader ---------------------
datasets = {phase: ImageFolder(os.path.join(root_dir, phase), transform=data_transforms[phase])
            for phase in ['train', 'val', 'test']}
loaders = {phase: DataLoader(
                datasets[phase],
                batch_size=batch_size,
                shuffle=(phase=='train'),
                num_workers=os.cpu_count(),
                pin_memory=True
            ) for phase in ['train', 'val', 'test']}
class_names = datasets['train'].classes

# --------------------- Model oluÅŸturucu ---------------------
def build_model(name: str):
    if name == 'DenseNet201':
        model = densenet201(pretrained=True)
        model.classifier = nn.Linear(model.classifier.in_features, num_classes)
    elif name == 'InceptionV3':
        model = inception_v3(pretrained=True, aux_logits=True)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)
    elif name == 'EfficientNetV2':
        model = efficientnet_v2_s(pretrained=True)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    elif name == 'ConvNeXt':
        model = convnext_base(pretrained=True)
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
    else:
        raise ValueError(f"Unknown model: {name}")
    return model.to(device)

# --------------------- EÄŸitim ve DeÄŸerlendirme ---------------------
scaler = GradScaler()

for model_name in models_to_train:
    print(f"\n===== Training {model_name} =====")
    model = build_model(model_name)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
    early_stopper = EarlyStopping(patience=7, delta=1e-4, save_path=f'{model_name}_best.pt')
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        # --- Training ---
        model.train()
        train_loss, train_correct = 0.0, 0
        for inputs, targets in tqdm(loaders['train'], desc=f"Epoch {epoch+1}/{epochs}"):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            train_loss += loss.item() * inputs.size(0)
            train_correct += (outputs.argmax(dim=1) == targets).sum().item()

        train_acc = train_correct / len(datasets['train'])

        # --- Validation ---
        model.eval()
        val_loss, val_correct = 0.0, 0
        with torch.no_grad():
            for inputs, targets in loaders['val']:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                val_loss += loss.item() * inputs.size(0)
                val_correct += (outputs.argmax(dim=1) == targets).sum().item()

        val_acc = val_correct / len(datasets['val'])
        scheduler.step(val_acc)
        if early_stopper.step(val_acc, model):
            print("Early stopping triggered.\n")
            break

        print(f"Epoch {epoch+1}/{epochs} | "
              f"Train Loss: {train_loss/len(datasets['train']):.4f} | Train Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss/len(datasets['val']):.4f} | Val Acc: {val_acc:.4f}")

    # --- Test ve Metrik Raporu ---
    print(f"--- Testing {model_name} ---")
    model.load_state_dict(torch.load(f'{model_name}_best.pt'))
    model.eval()

    y_true, y_pred, y_score = [], [], []
    with torch.no_grad():
        for inputs, targets in loaders['test']:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            probs = nn.functional.softmax(outputs, dim=1)
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(probs.argmax(dim=1).cpu().numpy())
            y_score.extend(probs.cpu().numpy())

    # Temel Metrikler
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    print(f"Test Accuracy: {acc:.4f}")
    print(f"Test F1 (macro): {f1:.4f}")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, normalize='true')
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)
    plt.title(f"{model_name} - Confusion Matrix")
    plt.show()

    # ROC-AUC EÄŸrileri
    y_true_oh = np.eye(num_classes)[y_true]
    y_score = np.array(y_score)
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        fpr, tpr, _ = roc_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(fpr, tpr, label=f"{class_names[i]} (AUC={auc(fpr, tpr):.2f})")
    plt.legend()
    plt.title(f"{model_name} - ROC-AUC")
    plt.show()

    # Precision-Recall EÄŸrileri
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        precision, recall, _ = precision_recall_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(recall, precision, label=f"{class_names[i]}")
    plt.legend()
    plt.title(f"{model_name} - Precision-Recall")
    plt.show()

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import densenet201, inception_v3, convnext_base, efficientnet_v2_s
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# --------------------- Tekrarlanabilirlik iÃ§in seed atama ---------------------
def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

# --------------------- Erken durdurma ---------------------
class EarlyStopping:
    def __init__(self, patience=7, delta=1e-4, save_path="best_model.pt"):
        self.patience = patience
        self.delta = delta
        self.save_path = save_path
        self.best_score = None
        self.counter = 0

    def step(self, metric, model):
        score = metric
        if self.best_score is None or score > self.best_score + self.delta:
            self.best_score = score
            self.counter = 0
            torch.save(model.state_dict(), self.save_path)
        else:
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False

# --------------------- KonfigÃ¼rasyon ---------------------
set_seed(2025)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

epochs = 50
batch_size = 32
lr = 1e-4
weight_decay = 1e-5
num_classes = 3
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
models_to_train = ['InceptionV3', 'EfficientNetV2', 'ConvNeXt']

# --------------------- Veri artÄ±rma ---------------------
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# --------------------- Dataset & DataLoader ---------------------
datasets = {phase: ImageFolder(os.path.join(root_dir, phase), transform=data_transforms[phase])
            for phase in ['train', 'val', 'test']}
loaders = {phase: DataLoader(
                datasets[phase],
                batch_size=batch_size,
                shuffle=(phase=='train'),
                num_workers=os.cpu_count(),
                pin_memory=True
            ) for phase in ['train', 'val', 'test']}
class_names = datasets['train'].classes

# --------------------- Model oluÅŸturucu ---------------------
def build_model(name: str):

    if name == 'InceptionV3':
        model = inception_v3(pretrained=True, aux_logits=True)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)
    elif name == 'EfficientNetV2':
        model = efficientnet_v2_s(pretrained=True)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    elif name == 'ConvNeXt':
        model = convnext_base(pretrained=True)
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
    else:
        raise ValueError(f"Unknown model: {name}")
    return model.to(device)

# --------------------- EÄŸitim ve DeÄŸerlendirme ---------------------
scaler = GradScaler()

for model_name in models_to_train:
    print(f"\n===== Training {model_name} =====")
    model = build_model(model_name)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
    early_stopper = EarlyStopping(patience=7, delta=1e-4, save_path=f'{model_name}_best.pt')
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        # --- Training ---
        model.train()
        train_loss, train_correct = 0.0, 0
        for inputs, targets in tqdm(loaders['train'], desc=f"Epoch {epoch+1}/{epochs}"):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            with autocast():
                outputs = model(inputs)
                logits = outputs.logits if hasattr(outputs, 'logits') else outputs
                loss = criterion(logits, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            train_loss += loss.item() * inputs.size(0)
            train_correct += (logits.argmax(dim=1) == targets).sum().item()

        train_acc = train_correct / len(datasets['train'])

        # --- Validation ---
        model.eval()
        val_loss, val_correct = 0.0, 0
        with torch.no_grad():
            for inputs, targets in loaders['val']:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                logits = outputs.logits if hasattr(outputs, 'logits') else outputs
                loss = criterion(logits, targets)
                val_loss += loss.item() * inputs.size(0)
                val_correct += (logits.argmax(dim=1) == targets).sum().item()

        val_acc = val_correct / len(datasets['val'])
        scheduler.step(val_acc)
        if early_stopper.step(val_acc, model):
            print("Early stopping triggered.\n")
            break

        print(f"Epoch {epoch+1}/{epochs} | "
              f"Train Loss: {train_loss/len(datasets['train']):.4f} | Train Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss/len(datasets['val']):.4f} | Val Acc: {val_acc:.4f}")

    # --- Test ve Metrik Raporu ---
    print(f"--- Testing {model_name} ---")
    model.load_state_dict(torch.load(f'{model_name}_best.pt'))
    model.eval()

    y_true, y_pred, y_score = [], [], []
    with torch.no_grad():
        for inputs, targets in loaders['test']:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            logits = outputs.logits if hasattr(outputs, 'logits') else outputs
            probs = nn.functional.softmax(logits, dim=1)
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(probs.argmax(dim=1).cpu().numpy())
            y_score.extend(probs.cpu().numpy())

    # Temel Metrikler
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    print(f"Test Accuracy: {acc:.4f}")
    print(f"Test F1 (macro): {f1:.4f}")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, normalize='true')
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)
    plt.title(f"{model_name} - Confusion Matrix")
    plt.show()

    # ROC-AUC EÄŸrileri
    y_true_oh = np.eye(num_classes)[y_true]
    y_score = np.array(y_score)
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        fpr, tpr, _ = roc_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(fpr, tpr, label=f"{class_names[i]} (AUC={auc(fpr, tpr):.2f})")
    plt.legend()
    plt.title(f"{model_name} - ROC-AUC")
    plt.show()

    # Precision-Recall EÄŸrileri
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        precision, recall, _ = precision_recall_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(recall, precision, label=f"{class_names[i]}")
    plt.legend()
    plt.title(f"{model_name} - Precision-Recall")
    plt.show()