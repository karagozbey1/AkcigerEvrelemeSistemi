# -*- coding: utf-8 -*-
"""Lung Cancer

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u9pB3fT3ytI9Vfc7m1CxZq1YbhFXvuSP

# Görüntü İşleme
"""

from google.colab import drive
drive.mount('/content/drive')



from google.colab import drive
drive.mount('/content/drive')

import os

root_path = '/content/drive/MyDrive'
dataset_path = os.path.join(root_path, 'dataset_lung')

# dataset_lung içeriğini yazdır
print("dataset_lung içeriği:")
print(os.listdir(dataset_path))

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from collections import defaultdict

dataset_path = '/content/drive/MyDrive/dataset_lung'

# Otomatik sınıf isimleri
class_names = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]
image_counts = defaultdict(int)
sample_images = {}

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    image_counts[class_name] = len(image_files)
    if image_files:
        sample_images[class_name] = os.path.join(class_dir, image_files[0])

print("📦 Sınıf başına görüntü sayısı:")
for class_name, count in image_counts.items():
    print(f"• {class_name}: {count} görüntü")

print("\n🎨 Örnek görüntüler:")
plt.figure(figsize=(12, 4))
for i, (class_name, image_path) in enumerate(sample_images.items()):
    img = mpimg.imread(image_path)
    plt.subplot(1, len(sample_images), i + 1)
    plt.imshow(img, cmap='gray')
    plt.title(class_name)
    plt.axis('off')
plt.tight_layout()
plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""*** 🧩 I. VERİ ÖNİZLEME & KEŞİF (EXPLORATORY DATA ANALYSIS) ***

1	Klasör Yapısı, Görsel Sayısı, Format Kontrolü
"""

import os
import matplotlib.pyplot as plt
from collections import defaultdict

# Dataset path
dataset_path = "/content/drive/MyDrive/dataset_lung"
valid_extensions = ('.jpg', '.jpeg', '.png', '.bmp')

# Klasörleri al
class_names = sorted(os.listdir(dataset_path))
image_counts = defaultdict(int)
invalid_files = []

# Görsel format kontrolü ve sayımı
for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    if not os.path.isdir(class_dir):
        continue
    for f in os.listdir(class_dir):
        file_path = os.path.join(class_dir, f)
        if f.lower().endswith(valid_extensions):
            image_counts[class_name] += 1
        else:
            invalid_files.append(file_path)

# 1️⃣ Görsel Sayısı Grafiği
plt.figure(figsize=(8, 5))
plt.bar(image_counts.keys(), image_counts.values(), color='skyblue')
plt.title("Sınıf Bazında Görsel Sayısı")
plt.ylabel("Görsel Sayısı")
plt.xlabel("Sınıf")
for i, count in enumerate(image_counts.values()):
    plt.text(i, count + 5, str(count), ha='center')
plt.tight_layout()
plt.savefig("image_counts_by_class.png")
plt.show()

# 2️⃣ Geçersiz Dosyaları Listele
print("\n❌ Geçersiz Formatlı Dosyalar:")
if invalid_files:
    for path in invalid_files:
        print("-", path)
else:
    print("Tüm dosyalar geçerli formatta.")

# 3️⃣ Özet
print("\n📦 Sınıf Başına Görsel Sayısı:")
for class_name, count in image_counts.items():
    print(f"• {class_name.capitalize()}: {count} görüntü")

# 4️⃣ Toplam görsel sayısı
print(f"\n📊 Toplam geçerli görsel sayısı: {sum(image_counts.values())}")
print(f"🔎 Geçersiz dosya sayısı: {len(invalid_files)}")

"""#	2	Her Sınıftan Örnek Görsel Panoları (3x3 Grid)

Bu adımda, her sınıftan (benign, normal, malignant) rastgele 9 görsel seçerek birer 3x3 grid oluşturuldu . Böylece sınıflar arası görsel farkları ilk aşamada sezgisel olarak gözlemleyebiliriz.

Amaç:
Görsellerdeki yapısal ve doku farklılıklarını ilk aşamada gözlemleme

Verinin niteliği hakkında sezgisel içgörü elde etme

"""

import matplotlib.pyplot as plt
import os
import random
import cv2

# Klasör yolu
dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

def plot_sample_images(class_name, img_size=(100, 100)):
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
    selected_images = random.sample(image_files, 9)

    plt.figure(figsize=(8, 8))
    plt.suptitle(f"{class_name.capitalize()} Sınıfından 9 Örnek Görsel", fontsize=16)

    for idx, image_name in enumerate(selected_images):
        image_path = os.path.join(class_dir, image_name)
        img = cv2.imread(image_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, img_size)

        plt.subplot(3, 3, idx + 1)
        plt.imshow(img)
        plt.axis('off')

    plt.tight_layout()
    plt.subplots_adjust(top=0.9)
    plt.savefig(f"{class_name}_samples_grid.png")
    plt.show()

# Her sınıf için ayrı grid
for cls in class_names:
    plot_sample_images(cls)

"""#	3	Görsel Boyut & Kanal İncelemesi (RGB vs. Grayscale)
Bu adımda amacımız, tüm veri setindeki görüntülerin:

📐 Boyut (yükseklik x genişlik) dağılımını

🎨 Kanal sayısını (Grayscale mi, RGB mi?)

🔎 Anormal çözünürlükleri ve standart dışı formatları

tespit etmektir.

📊 1. Görsel Boyut Dağılımı (Histogram)
Grafikte çoğu görselin boyutu yaklaşık 224x224 ve 512x512 gibi görünüyor.

Ufak sayıda 600+ ve 800+ piksel genişliğe sahip outlier görseller mevcut.

Standardizasyon için tüm görselleri ortak bir boyuta getirmek mantıklı (örn: 224x224 veya 256x256).

🎨 2. Kanal Sayısı Dağılımı
Tüm görüntüler 3-kanallı (RGB) çıktı.

Bu durum harika: Model eğitimine doğrudan uygun.

Grayscale → RGB dönüşümüne gerek kalmadı.

✅ Teknik Sonuç:
Gözlem	Sonuç
Kanal türü	Hepsi RGB (3-kanallı)
Boyutlar	2 farklı boyut kümesi hâkim
Tavsiye	Eğitim öncesi tüm görseller cv2.resize(..., (224,224)) gibi normalize edilmeli

"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from tqdm import tqdm

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

image_shapes = []
channel_counts = []

print("🔍 Görseller analiz ediliyor...\n")

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

    for image_name in tqdm(image_files, desc=class_name):
        img_path = os.path.join(class_dir, image_name)
        img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)

        if img is None:
            continue  # bozuk görsel

        h, w = img.shape[:2]
        c = 1 if len(img.shape) == 2 else img.shape[2]
        image_shapes.append((w, h))
        channel_counts.append(c)

# 🎯 Boyut Dağılımı
shape_counts = Counter(image_shapes)
most_common_shape, most_common_count = shape_counts.most_common(1)[0]

# 📊 Kanal Dağılımı
channel_counts_freq = Counter(channel_counts)

# 📈 Boyut Histogramı
widths = [s[0] for s in image_shapes]
heights = [s[1] for s in image_shapes]

plt.figure(figsize=(10, 4))
plt.hist(widths, bins=30, alpha=0.7, label='Genişlik', color='skyblue')
plt.hist(heights, bins=30, alpha=0.7, label='Yükseklik', color='salmon')
plt.title("📐 Görsel Boyut Dağılımı (Genişlik & Yükseklik)")
plt.xlabel("Piksel Sayısı")
plt.ylabel("Frekans")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.savefig("image_size_distribution.png")
plt.show()

# 🎨 Kanal Dağılımı Grafiği
plt.figure(figsize=(5, 4))
plt.bar(channel_counts_freq.keys(), channel_counts_freq.values(), color='orchid')
plt.title("🎨 Kanal Sayısı Dağılımı")
plt.xticks([1, 3], ["Grayscale", "RGB"])
plt.xlabel("Kanal Sayısı")
plt.ylabel("Görüntü Sayısı")
plt.tight_layout()
plt.savefig("channel_count_distribution.png")
plt.show()

# 🧾 Metinsel Özet
print("\n📋 Görsel Kanal Dağılımı:")
for ch, count in channel_counts_freq.items():
    print(f"• {ch} kanal ({'Grayscale' if ch == 1 else 'RGB'}): {count} görüntü")

print(f"\n📋 En yaygın boyut: {most_common_shape[0]}x{most_common_shape[1]} ({most_common_count} görsel)")
print(f"🔎 Farklı boyut sayısı: {len(shape_counts)}")

"""#	4	Bozuk, Eksik, Açılmayan Görsellerin Loglanması



"""

import os
import cv2
from tqdm import tqdm

# Klasör yolu
dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

# Bozuk dosya listesi
corrupted_images = []

print("🔎 Görseller taranıyor...\n")

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

    for img_file in tqdm(image_files, desc=f"Taranıyor: {class_name}"):
        img_path = os.path.join(class_dir, img_file)

        # Boş dosya veya okunamayan görsel
        if os.path.getsize(img_path) == 0:
            corrupted_images.append((class_name, img_file, "Dosya boyutu 0"))
            continue

        img = cv2.imread(img_path)
        if img is None:
            corrupted_images.append((class_name, img_file, "cv2.imread başarısız"))

# 🧾 Sonuçları kaydet
log_path = "/content/corrupted_image_log.txt"
with open(log_path, "w") as f:
    for item in corrupted_images:
        f.write(f"{item[0]}/{item[1]} => {item[2]}\n")

# 🧮 Özet
print("\n🧾 Taranan toplam bozuk/eksik görsel sayısı:", len(corrupted_images))
if corrupted_images:
    print(f"📁 Log dosyası: {log_path}")
    print("🔍 İlk 5 bozuk dosya:")
    for item in corrupted_images[:5]:
        print(f" - {item[0]}/{item[1]} → {item[2]}")
else:
    print("🎉 Tüm görseller okunabilir ve sağlam!")

"""#	5	Her sınıfa ait Ortalama Görsel (Mean Image Map)


Her sınıf için tüm görüntülerin piksel bazında ortalamasını alarak:

Görsel örüntü farklarını daha net görmek

Eğitim setindeki baskın yapıları sezgisel olarak görmek

Noise var mı, veri standardı ne durumda anlayabilmek

📐 Hazırlık:
Tüm görseller aynı boyutta (örn: 224×224) olmalı

Tüm görseller RGB (3-kanal) olmalı

Ortalama, float32 türünde hesaplanmalı

📊 Ne Elde Ediyoruz?
Sınıf	Görsel
benign	mean_image_benign.png
normal	mean_image_normal.png
malignant	mean_image_malignant.png

Bu görseller, o sınıftaki tüm verilerin “ortalama yapısını” temsil eder. Genellikle daha soluk ve yayvan dokular çıkar.

💬 Yorumlama Önerisi:
Gözlem	Yorum
Daha parlak ortalamalar	Genel yoğunluk fazla
Belirgin yapılar	Sınıf içi benzerlik yüksek
Belirsiz / dağınık	Veri gürültülü olabilir
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]
img_size = (224, 224)  # Ortak boyut

def compute_class_mean_image(class_name):
    class_dir = os.path.join(dataset_path, class_name)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]

    mean_image = np.zeros((img_size[1], img_size[0], 3), dtype=np.float32)
    count = 0

    for img_file in image_files:
        img_path = os.path.join(class_dir, img_file)
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, img_size)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        mean_image += img.astype(np.float32)
        count += 1

    if count > 0:
        mean_image /= count
        mean_image = mean_image.astype(np.uint8)

    return mean_image, count

# 🔍 Her sınıf için ortalama hesapla ve göster
for class_name in class_names:
    mean_img, total = compute_class_mean_image(class_name)

    plt.figure(figsize=(4, 4))
    plt.imshow(mean_img)
    plt.title(f"🧠 Ortalama Görsel: {class_name.capitalize()} ({total} adet)")
    plt.axis("off")
    plt.tight_layout()
    save_path = f"mean_image_{class_name}.png"
    plt.savefig(save_path)
    plt.show()

"""#	6	Görüntü Entropisi ile Bilgi Yoğunluğu Ölçümü

Amaç:
Her bir sınıftaki görüntülerin bilgi miktarını (entropi) ölçerek:

Görsel içerik ne kadar karmaşık?

Detay/farklılık ne düzeyde?

Veri kalitesi & ayırt edicilik potansiyeli nedir?

bunu sayısal ve grafiksel olarak değerlendirmek.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from scipy.stats import entropy

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ["benign", "normal", "malignant"]

def calculate_entropy(image):
    """Tek kanallı (grayscale) görüntünün entropisini hesaplar"""
    histogram, _ = np.histogram(image.flatten(), bins=256, range=[0, 256], density=True)
    return entropy(histogram, base=2)

entropies = {}

for class_name in class_names:
    class_dir = os.path.join(dataset_path, class_name)
    files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    entropy_list = []
    for file in tqdm(files, desc=f"{class_name} sınıfı entropi hesaplanıyor"):
        img_path = os.path.join(class_dir, file)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        img = cv2.resize(img, (224, 224))
        e = calculate_entropy(img)
        entropy_list.append(e)

    entropies[class_name] = entropy_list

# 📊 Boxplot ile Görsel Entropi Dağılımı
plt.figure(figsize=(10, 6))
plt.boxplot([entropies[c] for c in class_names], labels=class_names)
plt.title("📉 Görüntü Entropisi Dağılımı (Bilgi Yoğunluğu)")
plt.ylabel("Entropi (bit)")
plt.grid(True)
plt.tight_layout()
plt.savefig("entropi_dagilimi.png")
plt.show()

# 🧾 Ortalama entropiler
print("📘 Ortalama Entropi Değerleri:")
for c in class_names:
    avg_entropy = np.mean(entropies[c])
    std_entropy = np.std(entropies[c])
    print(f"• {c.capitalize()}: {avg_entropy:.3f} ± {std_entropy:.3f} bit")

"""#	7	Dosya Boyutu Dağılımı – İmaj Kalitesi Kontrolü

**Amaç:**

 Görsel boyutlarını normalize ederek (örneğin 224×224):

Model mimarileriyle (CNN tabanlı ResNet, VGG vs.) uyum sağlanır.

Aykırı çözünürlük farkları ve öğrenme bozuklukları ortadan kaldırılır.

Eğitim süresi kısalır, GPU belleği dengelenir.

**Ne Gözlemlemeliyiz?** :
------------------------
Outlier dosyalar var mı? Çok küçük veya çok büyük dosyalar tespit edilirse loglayabiliriz.

Sınıflar arası kalite farkı var mı? Örneğin, malignant dosyaları belirgin şekilde büyükse veri dengesizliği olabilir.

Dilersen:

df_sizes[df_sizes['size_kb'] < 5] gibi filtreyle çok küçük dosyaları listeleyebilirim.

Aykırı değerleri .boxplot(showfliers=True) ile gösterebiliriz.
"""

import os
import matplotlib.pyplot as plt
import seaborn as sns

dataset_path = "/content/drive/MyDrive/dataset_lung"
class_names = ['benign', 'normal', 'malignant']
file_sizes = []

# Her sınıftan dosya boyutlarını topla
for cls in class_names:
    class_dir = os.path.join(dataset_path, cls)
    for file_name in os.listdir(class_dir):
        if file_name.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            file_path = os.path.join(class_dir, file_name)
            size_kb = os.path.getsize(file_path) / 1024  # KB
            file_sizes.append({'class': cls, 'size_kb': size_kb})

# Görsel olarak analiz et
df_sizes = pd.DataFrame(file_sizes)

plt.figure(figsize=(12, 6))
sns.boxplot(data=df_sizes, x='class', y='size_kb')
plt.title('📦 Dosya Boyutu Dağılımı (KB)')
plt.ylabel('Dosya Boyutu (KB)')
plt.xlabel('Sınıf')
plt.grid(True)
plt.show()

# İstatistikleri yazdır
print("📊 Dosya Boyutu İstatistikleri (KB):")
print(df_sizes.groupby("class")["size_kb"].describe().round(2))

"""# 8 Görsel Boyutlarını Dengeleme

Görsel boyutlarını normalize ederek (örneğin 224×224):

Model mimarileriyle (CNN tabanlı ResNet, VGG vs.) uyum sağlanır.

Aykırı çözünürlük farkları ve öğrenme bozuklukları ortadan kaldırılır.

Eğitim süresi kısalır, GPU belleği dengelenir.
"""

import os
from PIL import Image
from tqdm import tqdm

# Kaynak ve hedef klasör
input_root = '/content/drive/MyDrive/dataset_lung'
output_root = '/content/drive/MyDrive/dataset_lung_resized'
target_size = (224, 224)

os.makedirs(output_root, exist_ok=True)

# Sınıf klasörleri üzerinden dön
for class_name in os.listdir(input_root):
    input_class_dir = os.path.join(input_root, class_name)
    output_class_dir = os.path.join(output_root, class_name)
    os.makedirs(output_class_dir, exist_ok=True)

    for filename in tqdm(os.listdir(input_class_dir), desc=f"Resizing {class_name}"):
        if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
            img_path = os.path.join(input_class_dir, filename)
            save_path = os.path.join(output_class_dir, filename)

            try:
                img = Image.open(img_path)
                img = img.convert('RGB')  # RGB'ye dönüştür (uyumluluk için)
                img = img.resize(target_size, Image.BILINEAR)
                img.save(save_path)
            except Exception as e:
                print(f"HATA: {img_path} - {e}")



import os
from PIL import Image
import matplotlib.pyplot as plt
from collections import Counter

resized_path = "/content/drive/MyDrive/dataset_lung_resized"
class_names = os.listdir(resized_path)

widths, heights, sizes = [], [], []

# Boyut bilgilerini topla
for cls in class_names:
    cls_dir = os.path.join(resized_path, cls)
    for fname in os.listdir(cls_dir):
        if fname.lower().endswith(('.jpg', '.png', '.jpeg')):
            try:
                img = Image.open(os.path.join(cls_dir, fname))
                w, h = img.size
                widths.append(w)
                heights.append(h)
                sizes.append((w, h))
            except:
                print(f"⚠️ Hatalı görsel: {cls}/{fname}")

# Histogram çizimi
plt.figure(figsize=(10,4))
plt.hist(widths, bins=10, alpha=0.6, label="Genişlik", color="skyblue", edgecolor='black')
plt.hist(heights, bins=10, alpha=0.6, label="Yükseklik", color="salmon", edgecolor='black')
plt.title("🎯 Resize Sonrası Görsel Boyut Dağılımı")
plt.xlabel("Piksel Sayısı")
plt.ylabel("Frekans")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# Boyut frekans analizi
size_counter = Counter(sizes)
print("\n🧾 Görsel Boyutu Frekansı:")
for size, count in size_counter.most_common():
    print(f"🔹 {size}: {count} adet")

# Yorum
total = sum(size_counter.values())
correct = size_counter.get((224, 224), 0)
if correct == total:
    print(f"\n✅ Tüm {total} görsel başarıyla 224x224 olarak resize edildi.")
else:
    print(f"\n⚠️ Toplam {total} görselden yalnızca {correct} tanesi 224x224. Diğerlerinde farklılık var!")

"""#	9	Histogram Karşılaştırmaları (Her sınıfa özel)

Her sınıftaki örnek görsellerin piksel yoğunluğu dağılımını histogramlarla görselleştirildi . Bu, sınıflar arasındaki görsel parlaklık, kontrast ve bilgi yoğunluğu farklarını gözlemlemek için önemli bir adımdır.

**Amaç:**

Her sınıf için birkaç rastgele görselin grayscale histogramını çizmek

Görsel içerikler hakkında bilgi edinmek (aşırı karanlık, kontrast eksikliği vs.)

Eğitim öncesi normalize ihtiyacını daha iyi anlamak

**sonuç:**

 cv2.IMREAD_GRAYSCALE ile grayscale dönüşümü yapılıyor (Renk kanallarını karşılaştırmak istiyorsan RGB histogramları da çizilebilir).

Histogram Eğrisi → Piksel değerine göre görselin ne kadar karanlık/açık yoğunlukta olduğunu gösterir.

Bu çıktılar, görsellerin normalize edilmesi gerektiğini daha iyi anlamanı sağlar.

"""

import os
import cv2
import matplotlib.pyplot as plt
import random

def plot_class_histograms(dataset_path, class_names, img_size=(224, 224), samples_per_class=3):
    for cls in class_names:
        cls_path = os.path.join(dataset_path, cls)
        all_images = [img for img in os.listdir(cls_path) if img.lower().endswith(('.jpg', '.png', '.jpeg'))]
        selected_imgs = random.sample(all_images, samples_per_class)

        plt.figure(figsize=(15, 3))
        for i, img_name in enumerate(selected_imgs):
            img_path = os.path.join(cls_path, img_name)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            img = cv2.resize(img, img_size)
            hist = cv2.calcHist([img], [0], None, [256], [0, 256])

            plt.subplot(1, samples_per_class, i + 1)
            plt.plot(hist, color='black')
            plt.title(f"{cls} - {img_name}")
            plt.xlabel("Piksel Değeri")
            plt.ylabel("Frekans")
            plt.tight_layout()
            plt.suptitle(f"📊 {cls} Sınıfı Histogramları", fontsize=16)
        plt.subplots_adjust(top=0.75)
        plt.show()


# Kullanım
dataset_path = "/content/drive/MyDrive/dataset_lung_resized"
class_names = ["benign", "malignant", "normal"]
plot_class_histograms(dataset_path, class_names)

"""#	10	Renk Kanalı Dönüşümü (Grayscale → RGB)

Her resmi RGB’ye çevirir

Bu adım, özellikle bazı modeller (örneğin: pretrained CNN modelleri – ResNet, VGG, EfficientNet vs.) RGB giriş beklediği için zorunlu hale gelir.

Grayscale (tek kanal) olan görselleri 3 kanallı RGB (aynı görüntüyü 3 kez kopyalayarak) haline getirmek.


CNN tabanlı birçok model input_shape=(224, 224, 3) ister.

Görsellerimiz şu anda 224x224x1 şeklinde olabilir.

Grayscale → RGB dönüşüm: cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)

Bu işlem bilgiyi değiştirmez, yalnızca kanalları genişletir.



"""

import os
import cv2
from tqdm import tqdm

# Giriş (grayscale) klasörü ve çıkış (RGB) klasörü
input_dir = "/content/drive/MyDrive/dataset_lung_resized"
output_dir = "/content/drive/MyDrive/dataset_lung_rgb"
os.makedirs(output_dir, exist_ok=True)

# Her sınıfı gez
for class_name in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, class_name)
    class_output_path = os.path.join(output_dir, class_name)
    os.makedirs(class_output_path, exist_ok=True)

    for file_name in tqdm(os.listdir(class_input_path), desc=f"{class_name} dönüştürülüyor"):
        input_path = os.path.join(class_input_path, file_name)
        output_path = os.path.join(class_output_path, file_name)

        try:
            img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                continue

            rgb_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            cv2.imwrite(output_path, rgb_img)
        except Exception as e:
            print(f"Hata: {file_name} - {e}")

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict

# Sen klasör yolunu buraya yaz
dataset_path = "/content/drive/MyDrive/dataset_lung_rgb"
class_names = os.listdir(dataset_path)

channel_counts = defaultdict(list)

for cls in class_names:
    class_dir = os.path.join(dataset_path, cls)
    for img_name in os.listdir(class_dir):
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path)
        if img is None:
            continue
        channels = img.shape[-1]
        channel_counts[cls].append(channels)

# Grafik: Sınıflara göre kanal sayısı dağılımı
plt.figure(figsize=(8, 5))
for cls in class_names:
    plt.hist(channel_counts[cls], bins=np.arange(1, 5)-0.5, alpha=0.6, label=cls)
plt.xticks([1, 2, 3])
plt.xlabel("Kanal Sayısı (1=Grayscale, 3=RGB)")
plt.ylabel("Görüntü Sayısı")
plt.title("🔍 Sınıflara Göre Görsel Renk Kanal Dağılımı")
plt.legend()
plt.grid(True)
plt.show()

# Metinsel analiz (ZeroDivisionError kontrolü ile)
for cls in class_names:
    total = len(channel_counts[cls])
    rgb = sum(1 for c in channel_counts[cls] if c == 3)
    gray = sum(1 for c in channel_counts[cls] if c == 1)

    if total > 0:
        print(f"📁 {cls}: {rgb}/{total} (%{round(100 * rgb / total, 2)}) RGB, {gray}/{total} (%{round(100 * gray / total, 2)}) Grayscale")
    else:
        print(f"📁 {cls}: ⚠️ Uyarı: Bu sınıfta analiz edilecek görüntü bulunamadı.")

"""#	11	Piksel Değer Normalizasyonu (0–1 veya -1–1)

Bu adım, görsellerin her piksel değerini aynı ölçeğe indirerek modelin daha hızlı ve kararlı öğrenmesini sağlar.

Amaç:

Piksel değerlerini 0–255 aralığından 0–1 aralığına dönüştürmek

Görselleri normalize ederek model eğitimine uygun hale getirmek

"""

import os
import cv2
import numpy as np
from tqdm import tqdm
from matplotlib import pyplot as plt

input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_rgb"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_normalized"
os.makedirs(output_dir, exist_ok=True)

class_names = [cls for cls in os.listdir(input_dir) if not cls.startswith(".")]
summary = {}

for cls in class_names:
    class_input_path = os.path.join(input_dir, cls)
    class_output_path = os.path.join(output_dir, cls)
    os.makedirs(class_output_path, exist_ok=True)

    pixel_means = []
    for fname in tqdm(os.listdir(class_input_path), desc=f"{cls}"):
        img_path = os.path.join(class_input_path, fname)
        try:
            img = cv2.imread(img_path)
            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
            img = img.astype(np.float32) / 255.0  # 🔽 Normalization

            pixel_means.append(np.mean(img))

            save_path = os.path.join(class_output_path, fname)
            img_uint8 = (img * 255).astype(np.uint8)  # Kaydetmek için tekrar uint8'e çevir
            cv2.imwrite(save_path, cv2.cvtColor(img_uint8, cv2.COLOR_RGB2BGR))
        except Exception as e:
            print(f"⚠️ Hata: {img_path} – {e}")

    summary[cls] = {
        "count": len(pixel_means),
        "mean": round(np.mean(pixel_means), 4),
        "std": round(np.std(pixel_means), 4)
    }

# 🎯 Özet Tablosu
print("\n📘 Piksel Ortalama Değerleri (0–1 aralığında):")
for cls, stat in summary.items():
    print(f"• {cls}: {stat['mean']} ± {stat['std']} (n={stat['count']})")

# 📊 Dağılım Grafiği
plt.figure(figsize=(8, 4))
for cls, stat in summary.items():
    plt.bar(cls, stat['mean'], yerr=stat['std'], capsize=6)
plt.title("📊 Sınıf Bazında Ortalama Piksel Değerleri (Normalize Edilmiş)")
plt.ylabel("Ortalama Piksel Değeri (0–1)")
plt.tight_layout()
plt.show()

"""# 12 Histogram Eşitleme + Kontrast Dağılım Analizi

Her görseli griye çevirip histogram eşitleme uygular.

Geri RGB formatında 3 kanallı olarak kaydeder.

Görsellerin kontrastını (piksel std. sapması) ölçer.

Her sınıf için kontrast istatistiklerini ve histogram grafiğini üretir.




"""

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image

# Giriş ve çıkış klasörleri
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_normalized"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_hist_equalized"
os.makedirs(output_dir, exist_ok=True)

# Kontrast ölçüm fonksiyonu (standard deviation)
def calculate_contrast(image):
    return np.std(image)

# Her sınıf için işlemleri yapalım
contrast_stats = {}

for cls in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, cls)
    class_output_path = os.path.join(output_dir, cls)
    os.makedirs(class_output_path, exist_ok=True)

    contrast_values = []

    for filename in tqdm(os.listdir(class_input_path), desc=f"İşleniyor: {cls}"):
        img_path = os.path.join(class_input_path, filename)
        try:
            # RGB görseli yükle ve Grayscale'e çevir
            img_rgb = cv2.imread(img_path)
            gray = cv2.cvtColor(img_rgb, cv2.COLOR_BGR2GRAY)

            # Histogram eşitleme
            equalized = cv2.equalizeHist(gray)

            # Tekrar RGB'ye çevirerek kaydet (3 kanal)
            equalized_rgb = cv2.cvtColor(equalized, cv2.COLOR_GRAY2BGR)
            save_path = os.path.join(class_output_path, filename)
            cv2.imwrite(save_path, equalized_rgb)

            # Kontrast ölç
            contrast = calculate_contrast(equalized)
            contrast_values.append(contrast)

        except Exception as e:
            print(f"HATA: {filename} dosyasında sorun var → {e}")

    # İstatistikleri kaydet
    contrast_stats[cls] = {
        'mean': np.mean(contrast_values),
        'std': np.std(contrast_values),
        'min': np.min(contrast_values),
        'max': np.max(contrast_values),
        'n': len(contrast_values),
        'values': contrast_values
    }

# 🔍 Kontrast istatistiklerini yazdır
for cls, stats in contrast_stats.items():
    print(f"\n📊 {cls} Sınıfı Kontrast Dağılımı:")
    print(f"• Ortalama: {stats['mean']:.2f}")
    print(f"• Standart Sapma: {stats['std']:.2f}")
    print(f"• Min: {stats['min']:.2f}")
    print(f"• Max: {stats['max']:.2f}")
    print(f"• Görsel Sayısı: {stats['n']}")

# 🎨 Kontrast Histogramlarını çiz
plt.figure(figsize=(12, 6))
for cls, stats in contrast_stats.items():
    plt.hist(stats['values'], bins=50, alpha=0.6, label=cls)
plt.title("📈 Histogram Eşitleme Sonrası Görsel Kontrast Dağılımı")
plt.xlabel("Kontrast (Std. Dev.)")
plt.ylabel("Görüntü Sayısı")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""# 13 Gaussian Blur


Tüm sınıflar için kontrastın normalize edilmesi ve dar bir aralığa oturması, modelin kontrasta bağlı aşırı öğrenme yapmasını engeller.

Sonuç:
Kontrast aralıkları dengelendi ve Gaussian Blur ile gürültüler azaltıldı.

Kontrast uçları yok, bu da modelin aşırıya kaçmasını engelleyecek.

Tüm sınıflar için ortalamalar birbirine yakın (±1.75 aralığında), bu çok iyi bir ön işleme sonucu!


"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from torchvision import transforms
from PIL import Image

# Giriş ve çıkış yolları
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_hist_equalized"
blurred_augmented_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_blur_augmented"
os.makedirs(blurred_augmented_dir, exist_ok=True)

# Veri artırma transformları
augmentations = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(degrees=15),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
])

# Gaussian blur parametresi
kernel_size = (3, 3)

# İşlenmiş örneklerden kontrast ölçmek için
contrast_map = {'malignant': [], 'benign': [], 'normal': []}

# İşleme
for cls in os.listdir(input_dir):
    class_path = os.path.join(input_dir, cls)
    out_path = os.path.join(blurred_augmented_dir, cls)
    os.makedirs(out_path, exist_ok=True)

    for img_file in tqdm(os.listdir(class_path), desc=f"{cls} işleniyor"):
        img_path = os.path.join(class_path, img_file)

        # OpenCV ile oku ve Gaussian Blur uygula
        image = cv2.imread(img_path)
        blurred = cv2.GaussianBlur(image, kernel_size, 0)

        # RGB için yeniden PIL'e çevirip augment et
        pil_img = Image.fromarray(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))
        augmented_img = augmentations(pil_img)

        # Sonucu kaydet
        save_path = os.path.join(out_path, img_file)
        augmented_img.save(save_path)

        # Kontrast analizi için: std (grayscale)
        gray = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)
        contrast_map[cls].append(np.std(gray))

# 🎨 Kontrast Dağılım Grafiği
plt.figure(figsize=(12, 6))
for cls in contrast_map:
    sns.histplot(contrast_map[cls], label=cls, kde=True, bins=30, alpha=0.5)
plt.title("🎯 Gaussian Blur + Augmentasyon Sonrası Görsel Kontrast Dağılımı")
plt.xlabel("Kontrast (Std. Dev.)")
plt.ylabel("Görüntü Sayısı")
plt.legend()
plt.tight_layout()
plt.savefig("blur_augmented_contrast.png")
plt.show()

# 🔢 İstatistiksel Özet
for cls, values in contrast_map.items():
    print(f"📊 {cls.capitalize()} sınıfı (Gaussian Blur + Augmentation):")
    print(f"• Ortalama: {np.mean(values):.2f}")
    print(f"• Std. Sapma: {np.std(values):.2f}")
    print(f"• Min: {np.min(values):.2f}")
    print(f"• Max: {np.max(values):.2f}")
    print(f"• Görsel Sayısı: {len(values)}\n")

"""Tüm sınıflar için ortalamalar birbirine yakın (±1.75 aralığında), bu çok iyi bir ön işleme sonucu!

# 14 Gaussian Blur + Augmentation

Yani görsellerin etrafındaki boşlukları temizleme veya görseli orantılı bir şekilde genişleterek kare hale getirme işlemini gerçekleştireceğiz.

 Bu Adımda Amaç:
Görseller farklı oranlarda (en-boy oranı ≠ 1) olabilir.

Model için giriş boyutlarını eşitlemek gerekir.

Padding işlemiyle resimler kare formatta ve ortalanmış olur.
"""

import os
from PIL import Image, ImageOps
import matplotlib.pyplot as plt

input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_blur_augmented"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_padded"
os.makedirs(output_dir, exist_ok=True)

# Her sınıfı işle
for class_name in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, class_name)
    class_output_path = os.path.join(output_dir, class_name)
    os.makedirs(class_output_path, exist_ok=True)

    for file_name in os.listdir(class_input_path):
        if not file_name.lower().endswith(('.png', '.jpg', '.jpeg')): continue

        img_path = os.path.join(class_input_path, file_name)
        img = Image.open(img_path)

        # Otomatik padding için kareye merkezle
        padded_img = ImageOps.pad(img, size=(224, 224), color=(0, 0, 0))  # Siyah boşluk eklenir

        padded_img.save(os.path.join(class_output_path, file_name))

"""Doğrulama: Örnek Görsellerden Önce/Sonra Gösterimi"""

import random

def show_before_after(sample_class):
    input_folder = os.path.join(input_dir, sample_class)
    output_folder = os.path.join(output_dir, sample_class)

    img_name = random.choice(os.listdir(input_folder))
    orig = Image.open(os.path.join(input_folder, img_name))
    padded = Image.open(os.path.join(output_folder, img_name))

    fig, axs = plt.subplots(1, 2, figsize=(8, 4))
    axs[0].imshow(orig)
    axs[0].set_title("🔹 Orijinal")
    axs[1].imshow(padded)
    axs[1].set_title("📐 Padded (224x224)")
    for ax in axs: ax.axis("off")
    plt.suptitle(f"{sample_class} sınıfından: {img_name}")
    plt.tight_layout()
    plt.show()

# Örnek olarak bir sınıf göster
show_before_after("malignant")

"""# 15 Görüntü Şiddet Normalizasyonu / Sharpening (Keskinleştirme)

CT görüntülerindeki kenarları ve detayları daha belirgin hale getirerek modelin odaklanmasını kolaylaştırmak.

Kullanılan Yöntem:

OpenCV cv2.filter2D() ile klasik sharpening filtresi

Her görüntüye keskinleştirme.


Ortalama kontrast ve keskinlik histogramı .
"""

import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from PIL import Image

# Giriş ve çıkış yolları
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_padded"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_sharpened"
os.makedirs(output_dir, exist_ok=True)

# Keskinleştirme filtresi
sharpen_kernel = np.array([[0, -1, 0],
                           [-1, 5, -1],
                           [0, -1, 0]])

# Kontrast değerlerini tut
contrast_dict = {}

# Görselleştirme için örnek seçelim
example_images = {}

# Her sınıf için işle
for cls in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, cls)
    class_output_path = os.path.join(output_dir, cls)
    os.makedirs(class_output_path, exist_ok=True)

    contrasts = []
    image_list = sorted(os.listdir(class_input_path))[:3]  # İlk 3 görsel örnek
    example_images[cls] = []

    for img_name in os.listdir(class_input_path):
        img_path = os.path.join(class_input_path, img_name)
        img = cv2.imread(img_path)

        # Apply sharpening
        sharpened = cv2.filter2D(img, -1, sharpen_kernel)

        # Save sharpened image
        cv2.imwrite(os.path.join(class_output_path, img_name), sharpened)

        # Kontrast (std dev)
        gray = cv2.cvtColor(sharpened, cv2.COLOR_BGR2GRAY)
        contrast = np.std(gray)
        contrasts.append(contrast)

        # Örnek görsel topla
        if img_name in image_list:
            example_images[cls].append((img, sharpened, img_name))

    contrast_dict[cls] = contrasts

# 🎨 Örnek önce-sonra karşılaştırması
fig, axs = plt.subplots(len(example_images), 3, figsize=(12, 4*len(example_images)))
for i, cls in enumerate(example_images):
    for j, (original, sharpened, name) in enumerate(example_images[cls]):
        axs[i, j].imshow(np.hstack((original, sharpened)))
        axs[i, j].axis("off")
        axs[i, j].set_title(f"{cls}: {name}")
plt.suptitle("🔍 Keskinleştirme Uygulaması (Önce - Sonra)", fontsize=16)
plt.tight_layout()
plt.show()

# 📊 Kontrast histogramı
plt.figure(figsize=(10, 5))
for cls, values in contrast_dict.items():
    plt.hist(values, bins=50, alpha=0.5, label=cls)
plt.xlabel("Kontrast (Std. Dev.)")
plt.ylabel("Görüntü Sayısı")
plt.title("📊 Keskinleştirme Sonrası Kontrast Dağılımı")
plt.legend()
plt.grid(True)
plt.show()

# 📘 Ortalama kontrastlar
for cls in contrast_dict:
    print(f"{cls} sınıfı kontrast ortalaması: {np.mean(contrast_dict[cls]):.2f} ± {np.std(contrast_dict[cls]):.2f}")

"""# 16 Augmentasyon

Veri artırımı, elimizdeki verileri çeşitlendirmek için görseller üzerinde yapay çeşitlilik oluşturur.
"""

import os
from PIL import Image, ImageOps
import random
from tqdm import tqdm
import matplotlib.pyplot as plt

input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_sharpened"
output_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_augmented"
os.makedirs(output_dir, exist_ok=True)

def augment_image(image):
    transforms = [
        lambda x: x.transpose(Image.FLIP_LEFT_RIGHT),
        lambda x: x.transpose(Image.FLIP_TOP_BOTTOM),
        lambda x: x.rotate(15),
        lambda x: x.rotate(-15)
    ]
    return [t(image) for t in transforms]

# Görselleri çoğalt ve kaydet
for class_name in os.listdir(input_dir):
    class_input_path = os.path.join(input_dir, class_name)
    class_output_path = os.path.join(output_dir, class_name)
    os.makedirs(class_output_path, exist_ok=True)

    for img_name in tqdm(os.listdir(class_input_path), desc=f"{class_name}"):
        if not img_name.endswith(".jpg"):
            continue
        img_path = os.path.join(class_input_path, img_name)
        image = Image.open(img_path).convert("RGB")
        image.save(os.path.join(class_output_path, img_name))  # Orijinali

        for i, aug in enumerate(augment_image(image)):
            aug_name = f"{os.path.splitext(img_name)[0]}_aug{i}.jpg"
            aug.save(os.path.join(class_output_path, aug_name))

# Görsel örnekleri göster
def show_augmented_examples(class_name, n=3):
    path = os.path.join(output_dir, class_name)
    sample_files = sorted([f for f in os.listdir(path) if f.endswith(".jpg")])[:n * 4]

    fig, axes = plt.subplots(n, 4, figsize=(12, 3 * n))
    for i in range(n):
        for j in range(4):
            idx = i * 4 + j
            img = Image.open(os.path.join(path, sample_files[idx]))
            axes[i, j].imshow(img)
            axes[i, j].axis("off")
            axes[i, j].set_title(sample_files[idx])
    plt.tight_layout()
    plt.suptitle(f"📈 Augmentasyon Sonrası Örnek Görseller ({class_name})", fontsize=16, y=1.02)
    plt.show()

show_augmented_examples("malignant")

"""Orijinal görselin çeşitli varyasyonları (çevirme, döndürme) oluşturuldu.

Görüntü kalitesi ve medikal içerik korunarak veri çeşitliliği sağlandı.

Bu, overfitting riskini azaltır, modelin genel performansını artırır.
"""

import os
import matplotlib.pyplot as plt

# Augment edilmiş veri seti yolu
augmented_dataset_path = "/content/drive/MyDrive/processed_dataset/dataset_lung_augmented"

# Her sınıftaki görsel sayısını say
class_counts = {}
for cls in os.listdir(augmented_dataset_path):
    cls_path = os.path.join(augmented_dataset_path, cls)
    if os.path.isdir(cls_path):
        image_count = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        class_counts[cls] = image_count

# Görselleştirme
plt.figure(figsize=(6, 4))
plt.bar(class_counts.keys(), class_counts.values(), color=["#FF9999", "#99CCFF", "#99FF99"])
plt.title("📊 Augmentasyon Sonrası Sınıf Dağılımı")
plt.xlabel("Sınıflar")
plt.ylabel("Görsel Sayısı")
plt.grid(axis='y')
plt.show()

# Yazılı çıktı
print("📦 Sınıf Dağılımları:")
for cls, count in class_counts.items():
    print(f"• {cls}: {count} görüntü")

# Dengesizlik değerlendirmesi
min_class = min(class_counts, key=class_counts.get)
max_class = max(class_counts, key=class_counts.get)
imbalance_ratio = class_counts[max_class] / class_counts[min_class]

print(f"\n🔎 Dengesizlik Oranı: {imbalance_ratio:.2f}")
if imbalance_ratio > 1.2:
    print("⚠️ Sınıflar arasında belirgin bir dengesizlik var. Oversampling önerilir.")
else:
    print("✅ Sınıf dağılımı dengeli. Ek dengeleme gerekmez.")

"""#	**17	Sınıf Dağılımı (Train/Val/Test için ayrı)**

"""

import os
import shutil
from sklearn.model_selection import train_test_split
from collections import defaultdict

# 🔧 Giriş ve çıkış klasör yolları
input_dir = "/content/drive/MyDrive/processed_dataset/dataset_lung_augmented"
output_base = "/content/drive/MyDrive/processed_dataset/split_dataset"
os.makedirs(output_base, exist_ok=True)

# 📁 Train, Val, Test oranları
train_ratio = 0.7
val_ratio = 0.15
test_ratio = 0.15

# 📦 Görselleri sınıfa göre ayır
class_files = defaultdict(list)
for class_name in os.listdir(input_dir):
    class_path = os.path.join(input_dir, class_name)
    if not os.path.isdir(class_path):
        continue
    for file in os.listdir(class_path):
        if file.lower().endswith((".jpg", ".png", ".jpeg")):
            class_files[class_name].append(os.path.join(class_path, file))

# ✂️ Train/Val/Test ayrımı ve kopyalama
for class_name, file_list in class_files.items():
    train_files, temp_files = train_test_split(file_list, train_size=train_ratio, random_state=42)
    val_files, test_files = train_test_split(temp_files, test_size=test_ratio / (val_ratio + test_ratio), random_state=42)

    for split, files in zip(["train", "val", "test"], [train_files, val_files, test_files]):
        split_dir = os.path.join(output_base, split, class_name)
        os.makedirs(split_dir, exist_ok=True)
        for f in files:
            shutil.copy(f, os.path.join(split_dir, os.path.basename(f)))

print("✅ Veriler Train/Val/Test olarak ayrıldı ve kopyalandı.")

# 🔢 Sınıf dağılımı raporu
import pandas as pd

distribution = {}
for split in ["train", "val", "test"]:
    for class_name in class_files.keys():
        path = os.path.join(output_base, split, class_name)
        count = len(os.listdir(path)) if os.path.exists(path) else 0
        distribution[(split, class_name)] = count

df = pd.DataFrame(distribution.items(), columns=["Split/Class", "Count"])
df = df.pivot(index="Split/Class", columns=None, values="Count")
print("\n📊 Sınıf Dağılımı (Train/Val/Test):")
print(df)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 🔧 Sınıf dağılımını tabloya dönüştür
distribution_df = pd.DataFrame([
    {"split": split, "class": class_name, "count": count}
    for (split, class_name), count in distribution.items()
])

# 📊 Tablo olarak yazdır
pivot_df = distribution_df.pivot(index="class", columns="split", values="count")
print("📊 Sınıf Dağılımı Tablosu (Train / Val / Test):")
print(pivot_df)

# 📈 Grafikle göster
plt.figure(figsize=(8, 5))
sns.barplot(data=distribution_df, x="class", y="count", hue="split")
plt.title("📊 Train / Val / Test Sınıf Dağılımı")
plt.xlabel("Sınıf")
plt.ylabel("Görsel Sayısı")
plt.tight_layout()
plt.show()

"""# **18 Entropi Hesabı**

Bu adımda, her bir sınıfın entropi değerlerinin dağılımını histogram üzerinde göstereceğiz. Bu, bilgi yoğunluğunun sınıflar arasında nasıl değiştiğini görsel olarak analiz etmemizi sağlar.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# Eğitim setinde entropi analizi
data_dir = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
class_names = sorted(os.listdir(data_dir))

# Entropi hesaplama fonksiyonu
def calculate_entropy(img):
    hist = cv2.calcHist([img], [0], None, [256], [0, 256])
    hist_norm = hist.ravel() / hist.sum()
    entropy = -np.sum([p * np.log2(p) for p in hist_norm if p != 0])
    return entropy

# Tüm sınıflar için entropileri topla
entropy_dict = {}

for cls in class_names:
    entropies = []
    class_dir = os.path.join(data_dir, cls)
    for fname in tqdm(os.listdir(class_dir), desc=f"{cls}"):
        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):
            img_path = os.path.join(class_dir, fname)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                entropies.append(calculate_entropy(img))
    entropy_dict[cls] = entropies

# 📊 Histogramları çiz
plt.figure(figsize=(12, 6))
for cls, values in entropy_dict.items():
    plt.hist(values, bins=50, alpha=0.6, label=f"{cls} (mean={np.mean(values):.2f})")

plt.title("📊 Entropi Dağılımı Histogramı (Tüm Sınıflar)")
plt.xlabel("Entropi (bit)")
plt.ylabel("Görüntü Sayısı")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

"""# **19**

# **Ortalama Görüntü Yoğunluğu Karşılaştırması**

# **Görsel Frekans Spektrumu Analizi (FFT)**

# **Görüntü Zıtlık (Seviye Farkı) Analizi**

-

Kod, her sınıf için:

Görüntü ortalamasını,

Frekans spektrum enerjisini (log-FFT),

Piksel seviyesinde kontrastı (max-min farkı) çıkarır.

KDE eğrileri ile karşılaştırmalı analiz sağlar.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import seaborn as sns

# 🔧 Giriş dizini (gerekirse değiştir)
input_dir = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
classes = ["malignant", "benign", "normal"]

# 📊 Verileri saklayacak sözlük
mean_intensities = {}
fft_energies = {}
contrast_levels = {}

# 🧪 Her sınıf için hesapla
for cls in classes:
    mean_vals, fft_vals, contrast_vals = [], [], []
    class_dir = os.path.join(input_dir, cls)
    image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    for img_name in tqdm(image_files, desc=f"{cls}"):
        img_path = os.path.join(class_dir, img_name)
        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

        # Ortalama yoğunluk
        mean_vals.append(np.mean(img))

        # FFT spektrumu
        f = np.fft.fft2(img)
        fshift = np.fft.fftshift(f)
        magnitude_spectrum = np.abs(fshift)
        energy = np.mean(np.log1p(magnitude_spectrum))  # log(1 + x) for stability
        fft_vals.append(energy)

        # Kontrast (Seviye farkı)
        contrast = img.max() - img.min()
        contrast_vals.append(contrast)

    mean_intensities[cls] = mean_vals
    fft_energies[cls] = fft_vals
    contrast_levels[cls] = contrast_vals

# 📊 Ortalama Yoğunluk
plt.figure(figsize=(10, 5))
for cls in classes:
    sns.kdeplot(mean_intensities[cls], label=f"{cls} (mean={np.mean(mean_intensities[cls]):.2f})")
plt.title("📌 Ortalama Görüntü Yoğunluğu Dağılımı")
plt.xlabel("Yoğunluk (0–255)")
plt.ylabel("Yoğunluk")
plt.legend()
plt.grid(True)
plt.show()

# ⚡ FFT Frekans Enerjisi
plt.figure(figsize=(10, 5))
for cls in classes:
    sns.kdeplot(fft_energies[cls], label=f"{cls} (mean={np.mean(fft_energies[cls]):.2f})")
plt.title("📊 FFT Tabanlı Frekans Spektrumu Enerji Dağılımı")
plt.xlabel("Log-Frekans Enerjisi")
plt.ylabel("Yoğunluk")
plt.legend()
plt.grid(True)
plt.show()

# 🎯 Kontrast (Seviye Farkı)
plt.figure(figsize=(10, 5))
for cls in classes:
    sns.kdeplot(contrast_levels[cls], label=f"{cls} (mean={np.mean(contrast_levels[cls]):.2f})")
plt.title("🌓 Görüntü Zıtlığı Dağılımı (Seviye Farkı)")
plt.xlabel("Kontrast (max - min)")
plt.ylabel("Yoğunluk")
plt.legend()
plt.grid(True)
plt.show()

"""#*** 20 PCA + t-SNE ***
 Bu adımda görsellerin yüksek boyutlu temsilini 2 boyuta indirerek sınıflar arası ayrılabilirliği görselleştiriyoruz. Bu işlem, veri setindeki örneklerin benzerliklerini sezgisel olarak gözlemlememizi sağlar.

 sonuç: PCA (Principal Component Analysis):
Avantaj: Hızlıdır ve büyük veri setleri için uygundur.

Sonuç: PCA grafiğinde sınıflar (malignant, benign, normal) büyük ölçüde üst üste binmiş. Bu durum, sınıfların doğrudan PCA düzleminde çok ayrışmadığını gösteriyor.

Yorum: Görsellerin temel bileşenleri (renk tonu, doku vb.) sınıflar arasında çok belirgin farklar üretmemiş olabilir.

 t-SNE (t-Distributed Stochastic Neighbor Embedding):
Avantaj: Daha karmaşık, non-lineer ilişkileri açığa çıkarabilir.

Sonuç: t-SNE sonucunda kısmi kümelenmeler görülebiliyor ama yine çok belirgin bir ayrım gözlenmiyor.

Yorum: Görsel temsiller daha fazla iyileştirme veya farklı özellik mühendisliği gerektirebilir. CNN tabanlı feature extractor’lar (örneğin VGG veya ResNet) ile öznitelik çıkarımı yapılırsa ayrım daha net olabilir.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from PIL import Image

# 📂 Yol
data_dir = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
classes = ["malignant", "benign", "normal"]

# 🔄 Görselleri yükle ve flatten et
image_vectors = []
labels = []

for cls in classes:
    class_dir = os.path.join(data_dir, cls)
    for fname in os.listdir(class_dir):
        if fname.lower().endswith(('.jpg', '.png', '.jpeg')):
            img_path = os.path.join(class_dir, fname)
            img = Image.open(img_path).convert("L").resize((64, 64))  # Daha küçük boyut hız için
            img_array = np.array(img).flatten()
            image_vectors.append(img_array)
            labels.append(cls)

X = np.array(image_vectors)
y = np.array(labels)

# 🔄 Standartlaştırma
X_scaled = StandardScaler().fit_transform(X)

# 🔬 PCA (önce kaba ayrım)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# 🌀 t-SNE (daha detaylı görsel ayrım)
tsne = TSNE(n_components=2, perplexity=30, random_state=42)
X_tsne = tsne.fit_transform(X_scaled)

# 🎨 Görselleştir (PCA)
plt.figure(figsize=(10, 5))
for cls in classes:
    plt.scatter(X_pca[y == cls, 0], X_pca[y == cls, 1], label=cls, alpha=0.5)
plt.title("🧬 PCA ile Görsel Temsil")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.legend()
plt.grid(True)
plt.show()

# 🎨 Görselleştir (t-SNE)
plt.figure(figsize=(10, 5))
for cls in classes:
    plt.scatter(X_tsne[y == cls, 0], X_tsne[y == cls, 1], label=cls, alpha=0.5)
plt.title("🌀 t-SNE ile Görsel Temsil")
plt.xlabel("t-SNE 1")
plt.ylabel("t-SNE 2")
plt.legend()
plt.grid(True)
plt.show()

"""# 21 Veri Seti İstatistikleri (Ortalama, Std, Min, Max)

sonuç:

✅ Tüm sınıfların ortalama parlaklığı oldukça yakın ve dengeli.
✅ Tüm sınıflarda min/max değerleri 0–255 aralığında. Bu, görsellerin tüm ton aralığını kapsadığını gösteriyor.
✅ Standart sapma değerleri de benzer seviyelerde, bu da kontrast çeşitliliğinin dengeli olduğunu gösteriyor.
"""

import os
import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt

# 📁 Klasör yolu
dataset_path = "/content/drive/MyDrive/processed_dataset/split_dataset/train"

# 🔍 Sınıflar
class_names = ["malignant", "benign", "normal"]

# 📊 İstatistikleri tutmak için liste
statistics = []

# 🔁 Her sınıf için tüm görsellerin istatistiklerini hesapla
for cls in class_names:
    cls_dir = os.path.join(dataset_path, cls)
    pixel_values = []

    for img_name in tqdm(os.listdir(cls_dir), desc=f"{cls}"):
        img_path = os.path.join(cls_dir, img_name)
        try:
            img = cv2.imread(img_path)
            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            pixel_values.extend(img_gray.flatten())
        except:
            continue

    pixel_values = np.array(pixel_values)
    stats = {
        "Sınıf": cls,
        "Görüntü Sayısı": len(os.listdir(cls_dir)),
        "Ortalama Piksel": np.mean(pixel_values).round(2),
        "Std Sapma": np.std(pixel_values).round(2),
        "Min": np.min(pixel_values),
        "Max": np.max(pixel_values)
    }
    statistics.append(stats)

# 📋 Tabloyu oluştur
df_stats = pd.DataFrame(statistics)
print(df_stats)

# 📈 Görselleştirme (Opsiyonel)
df_stats_plot = df_stats.set_index("Sınıf")[["Ortalama Piksel", "Std Sapma"]]
df_stats_plot.plot(kind='bar', figsize=(10, 5), title="📊 Ortalama ve Std Piksel Değerleri", colormap='viridis')
plt.ylabel("Değer (0-255)")
plt.xticks(rotation=0)
plt.grid(axis="y")
plt.tight_layout()
plt.show()

"""# 22 Boş Görsel Tespiti ve Temizlenmesi ve Görüntüdeki Açık-Karanlık Oranı Ölçümü (Mean Brightness)


Train/Val/Test için ayrık şekilde parlaklık ortalamaları oldukça tutarlı:

malignant: 122.68–122.80

benign: 121.21–121.42

normal: 122.12–122.60

Dağılımlar dengeli ve sınıflar arası büyük uçurumlar yok → Bu, modelin aydınlık/karanlık farklarından etkilenme riskini azaltır.

✅ Hiçbir sınıfta ciddi bir outlier parlaklık sapması yok.
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from collections import defaultdict

# 📁 Ana veri dizini
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
brightness_data = defaultdict(list)
empty_images = []

# 🔍 Train/Val/Test her biri için gez
for split in ['train', 'val', 'test']:
    split_path = os.path.join(root_dir, split)
    for cls in os.listdir(split_path):
        class_dir = os.path.join(split_path, cls)
        if not os.path.isdir(class_dir):
            continue
        for fname in tqdm(os.listdir(class_dir), desc=f"📂 {split}/{cls}"):
            fpath = os.path.join(class_dir, fname)
            try:
                img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)
                if img is None or np.all(img == 0):
                    empty_images.append(fpath)
                    continue
                mean_brightness = np.mean(img)
                brightness_data[f"{split}/{cls}"].append(mean_brightness)
            except Exception:
                empty_images.append(fpath)

# 🧹 Boş/bozuk görsellerin silinmesi
for fpath in empty_images:
    if os.path.exists(fpath):
        os.remove(fpath)

# 📊 Ortalama parlaklık analizi
plt.figure(figsize=(12, 6))
for key, values in brightness_data.items():
    plt.hist(values, bins=40, alpha=0.6, label=f"{key} (mean={np.mean(values):.2f})")
plt.title("💡 Train/Val/Test Ayrık Ortalama Parlaklık Dağılımı")
plt.xlabel("Parlaklık (0–255)")
plt.ylabel("Görüntü Sayısı")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 📝 Log
print("🧹 Silinen boş/bozuk görsel sayısı:", len(empty_images))

"""# 23 Görüntülerde Kenar (Edge) Bilgisi Yoğunluğu (Canny Edge)

sonuç:

Malignant (kötü huylu) sınıfındaki edge yoğunluğu daha düşük. Bu, kenarların daha az belirgin veya daha yumuşak yapıda olduğunu gösterebilir.

Benign ve normal sınıflar daha yüksek edge oranına sahip, bu da daha fazla yapısal detay veya kenar geçişi barındırdıklarını gösteriyor.

Bu fark, sınıflandırma modelleri açısından ayırt edici bir sinyal olabilir.
"""

import cv2
import os
import numpy as np
import matplotlib.pyplot as plt
from collections import defaultdict
from tqdm import tqdm

# Dataset yolu
base_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]
classes = ["malignant", "benign", "normal"]

edge_densities = defaultdict(list)

# Her klasör için gezip Canny edge analizi yapalım
for split in splits:
    for cls in classes:
        class_path = os.path.join(base_dir, split, cls)
        for fname in tqdm(os.listdir(class_path), desc=f"{split}/{cls}"):
            fpath = os.path.join(class_path, fname)
            try:
                img = cv2.imread(fpath, cv2.IMREAD_GRAYSCALE)
                if img is None: continue

                edges = cv2.Canny(img, 100, 200)
                edge_density = np.sum(edges > 0) / edges.size
                edge_densities[f"{split}/{cls}"].append(edge_density)
            except:
                continue

# 🔍 Histogram grafiği
plt.figure(figsize=(12, 6))
for key, values in edge_densities.items():
    plt.hist(values, bins=50, alpha=0.5, label=f"{key} (mean={np.mean(values):.3f})")
plt.title("🧠 Canny Edge Yoğunluğu Dağılımı (Train/Val/Test + Sınıf Bazlı)")
plt.xlabel("Kenar Yoğunluğu (Oran)")
plt.ylabel("Görüntü Sayısı")
plt.legend()
plt.grid(True)
plt.show()

"""# 24 Etiketli CSV Oluşturma (filename, label, path, size, set) , Etiket Uyumu Kontrolü – Sınıf İsmi ve Path Uyuşmazlıkları , Çoklu Etiket veya Evre Bilgisi Varsa Ayrıştırma (Multi-Label) , Etiket Tutarlılık Testi – Aynı Görselin İki Farklı Etiketi Var mı? ,Class Weights Hesaplama – Model Eğitimi İçin.


**Özellikler:**

Her sınıf ve split için görsel sayısı çubuğu çizilir.

Label uyuşmazlıkları varsa tablo olarak gösterilir.

Çoklu etiket durumu tespit edilir.

Aynı dosya adına sahip ancak farklı etiket almış görseller varsa listelenir.

Class weights tablo formatında sunulur.
"""

import os
import pandas as pd
from PIL import Image
from collections import Counter
import matplotlib.pyplot as plt
import seaborn as sns

# Ana dizin
base_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]
classes = ["malignant", "benign", "normal"]

# 1. Etiketli CSV oluşturma
data = []
for split in splits:
    for cls in classes:
        class_dir = os.path.join(base_dir, split, cls)
        if not os.path.exists(class_dir):
            continue
        for fname in os.listdir(class_dir):
            fpath = os.path.join(class_dir, fname)
            try:
                with Image.open(fpath) as img:
                    width, height = img.size
            except:
                width, height = None, None
            data.append({
                "filename": fname,
                "label": cls,
                "full_path": fpath,
                "size": f"{width}x{height}",
                "set": split
            })

df = pd.DataFrame(data)

# 2. Etiket Uyumu Kontrolü
df["path_match_label"] = df.apply(lambda row: row["label"] in row["full_path"], axis=1)
label_mismatches = df[~df["path_match_label"]]

# 3. Çoklu Etiket Kontrolü
df["multi_label"] = df["label"].apply(lambda x: "," in x)

# 4. Aynı görsele farklı etiket atanmış mı?
conflicts_df = df.groupby("filename")["label"].nunique().reset_index()
conflicts_df = conflicts_df[conflicts_df["label"] > 1]

# 5. Class weights
label_counts = df["label"].value_counts().to_dict()
total = sum(label_counts.values())
class_weights = {cls: round(total / (len(label_counts) * count), 3) for cls, count in label_counts.items()}

# 🔍 Görselleştirme ve çıktı
print("✅ Etiketli CSV oluşturuldu. Görsel tutarsızlıklar ve istatistiksel analiz aşağıdadır:")

# 🎯 1. Sınıf dağılımı görselleştirme
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x="label", hue="set", palette="viridis")
plt.title("📊 Görsel Sayısı - Sınıf ve Set Dağılımı")
plt.xlabel("Sınıf")
plt.ylabel("Adet")
plt.tight_layout()
plt.show()

# 🎯 2. Label uyumsuzlukları
if not label_mismatches.empty:
    print(f"⚠️ Etiket uyuşmazlığı bulunan {len(label_mismatches)} görsel tespit edildi.")
    display(label_mismatches.head())
else:
    print("✅ Etiket ve path uyumu tam.")

# 🎯 3. Multi-label kontrol
multi_count = df["multi_label"].sum()
print(f"🧩 Multi-label etiketli görsel sayısı: {multi_count}")

# 🎯 4. Etiket çakışması kontrolü
if not conflicts_df.empty:
    print(f"⚠️ Farklı etiket atanmış {len(conflicts_df)} görsel bulundu.")
    display(conflicts_df.head())
else:
    print("✅ Aynı görsele birden fazla etiket atanması durumu yok.")

# 🎯 5. Class weights
cw_df = pd.DataFrame.from_dict(class_weights, orient="index", columns=["Class Weight"]).reset_index()
cw_df.rename(columns={"index": "Class"}, inplace=True)
print("\n🎯 Class Weights (Model için önerilen):")
display(cw_df)

# 🔚 Özet
print("🔍 Analiz tamamlandı. Eğitimde bu veriler ışığında dengeleme uygulanabilir.")

import os
import pandas as pd

# Split klasör yolu
split_root = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]

# Hatalı etiketlenenleri tutmak için liste
mismatch_entries = []

# Her split için kontrol et
for split in splits:
    split_path = os.path.join(split_root, split)
    for class_name in os.listdir(split_path):
        class_dir = os.path.join(split_path, class_name)
        if not os.path.isdir(class_dir):
            continue
        for file in os.listdir(class_dir):
            if file.lower().endswith((".jpg", ".jpeg", ".png")):
                actual_path = os.path.join(class_dir, file)
                expected_label = class_name.lower()

                # Dosya adından label çıkarmaya çalış
                # Örn: "malignant - XYZ.jpg" → "malignant"
                try:
                    file_label = file.split()[0].lower()
                except:
                    file_label = "unknown"

                if expected_label != file_label:
                    mismatch_entries.append({
                        "split": split,
                        "expected_label": expected_label,
                        "inferred_from_filename": file_label,
                        "file": file,
                        "path": actual_path
                    })

# Sonuçları DataFrame'e aktar
mismatch_df = pd.DataFrame(mismatch_entries)

# Durumu bildir
if mismatch_df.empty:
    print("✅ Tüm train/val/test dosyalarının etiketleri dosya isimleriyle uyumlu.")
else:
    print(f"❌ {len(mismatch_df)} etiket uyuşmazlığı bulundu:")
    display(mismatch_df.head())

"""# 25
# Kenar Algılama (Edge Detection) – Sobel, Prewitt, Canny gibi yöntemlerle yapı farklarını görselleştirme

🔍 Amaç: Görsellerdeki kenar bilgisi oranlarını ölçmek
📊 Gözlem:

malignant sınıfında kenar yoğunluğu genellikle daha az (%40–50 civarı).

benign ve normal sınıflarda daha yüksek, geniş bir dağılıma sahip.

➡ Bu farklılık, kenar netliği üzerinden ayrım yapacak bir modelde kullanılabilir.

# HOG (Histogram of Oriented Gradients) Görselleştirme – Sınıflar arası yapısal yön bilgisini karşılaştırma

Amaç: Kenar yönelimlerini (gradient) görselleştirmek
📷 Gözlem: FFT görselleri:

Malignant görüntülerde daha yoğun merkez bölgesi (daha fazla düşük frekanslı detay).

Normal ve benign sınıflarda daha homojen yapılar görülüyor.

➡ Yapısal yoğunluk farkları tespit edilmiş, bu HOG gibi kenara duyarlı CNN tabanlı modeller için önemlidir.

# Fourier Transform Görsel Analizi – Frekans spektrumu ile doku ve düzen tespiti

🔍 Amaç: Görsellerdeki frekans bileşenlerinin enerji dağılımını görmek
📷 Gözlem:

FFT çıktıları tüm sınıflarda benzer görünüyor ama malignant daha belirgin düşey frekans çizgileri taşıyor.

Bu, bazı radyolojik paternlerin frekans uzayında daha belirgin olduğunu gösteriyor olabilir.

➡ Frekans domain'i kullanılarak özellik çıkarımı yapılabilir.

# Gabor Filter ile Tekstür Özellikleri – Doku analizi için Gabor filtre haritaları

🔍 Amaç: Görüntüdeki yüzey ve doku farklılıklarını (tekstür) yakalamak
📷 Gözlem:

malignant doku haritaları daha yoğun ve ayrık.

normal daha düzgün ve tekstürel detayları daha az.

➡ Gabor filtreleri, CNN öncesi özellik çıkarımı için etkili olabilir.

# VGG/ResNet ile Feature Embedding Çıkarımı – Modelden vektör temsili alıp PCA/t-SNE ile görselleştirme

🔍 Amaç: Derin bir modelden görüntü temsillerini alarak sınıflar arası ayrımı test etmek
📊 Gözlem:

VGG16’dan alınan özelliklerin dağılımı normal sınıfta daha düşük yoğunluklu.

malignant ve benign daha zengin ve farklı bir dağılım sergiliyor.

➡ Bu adım modelin sınıfları ayırt edebilirliğini gösteren güçlü bir adımdı.


"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage.filters import gabor
from tensorflow.keras.applications import VGG16
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.models import Model
from tqdm import tqdm
from scipy.fft import fft2, fftshift
import seaborn as sns
import pandas as pd

base_path = "/content/drive/MyDrive/processed_dataset/split_dataset"
splits = ["train", "val", "test"]
classes = ["malignant", "benign", "normal"]

edge_means = []

for split in splits:
    for cls in classes:
        folder = os.path.join(base_path, split, cls)
        for img_file in tqdm(sorted(os.listdir(folder))[:50], desc=f"Canny: {split}/{cls}"):
            img_path = os.path.join(folder, img_file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            edges = cv2.Canny(img, 100, 200)
            edge_mean = np.mean(edges)
            edge_means.append({"split": split, "class": cls, "mean_edge": edge_mean})

df_edge = pd.DataFrame(edge_means)
plt.figure(figsize=(8, 4))
sns.boxplot(data=df_edge, x="class", y="mean_edge", hue="split")
plt.title("🔍 Canny Edge Yoğunluğu")
plt.show()

plt.figure(figsize=(12, 6))
i = 1
for cls in classes:
    path = os.path.join(base_path, "train", cls)
    img_path = os.path.join(path, sorted(os.listdir(path))[0])
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    f = fftshift(fft2(img))
    magnitude_spectrum = 20 * np.log(np.abs(f) + 1)
    plt.subplot(1, 3, i)
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.title(f"FFT - {cls}")
    plt.axis('off')
    i += 1
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
i = 1
for cls in classes:
    path = os.path.join(base_path, "train", cls)
    img_path = os.path.join(path, sorted(os.listdir(path))[0])
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    filt_real, _ = gabor(img, frequency=0.6)
    plt.subplot(1, 3, i)
    plt.imshow(filt_real, cmap='gray')
    plt.title(f"Gabor - {cls}")
    plt.axis('off')
    i += 1
plt.tight_layout()
plt.show()

model = VGG16(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
feat_model = Model(inputs=model.input, outputs=model.output)

features = []
for cls in classes:
    folder = os.path.join(base_path, "train", cls)
    for img_file in tqdm(sorted(os.listdir(folder))[:5], desc=f"VGG16 Features - {cls}"):
        img_path = os.path.join(folder, img_file)
        img = load_img(img_path, target_size=(224, 224))
        x = img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        feat = feat_model.predict(x)
        features.append({"class": cls, "flatten_feat": feat.flatten()[:50].mean()})  # örnek

df_feat = pd.DataFrame(features)
sns.boxplot(data=df_feat, x="class", y="flatten_feat")
plt.title("🔍 VGG16 Özellik Dağılımı (Ortalama İlk 50 Değer)")
plt.show()

import os
import time
import cv2
import torch
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
import matplotlib.pyplot as plt

# Dataset sınıfı
class SimpleImageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.image_paths = []
        self.labels = []
        self.transform = transform

        for cls in os.listdir(root_dir):
            cls_path = os.path.join(root_dir, cls)
            if not os.path.isdir(cls_path): continue
            for fname in os.listdir(cls_path):
                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):
                    self.image_paths.append(os.path.join(cls_path, fname))
                    self.labels.append(cls)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = cv2.imread(self.image_paths[idx])
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx]

# 1️⃣ Transform ve dataset
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
dataset_path = "/content/drive/MyDrive/processed_dataset/split_dataset/train"
dataset = SimpleImageDataset(dataset_path, transform=transform)

# 2️⃣ DataLoader test
loader = DataLoader(dataset, batch_size=32, shuffle=True)
start = time.time()
for batch in loader:
    images, labels = batch
    break
end = time.time()
print(f"⏱️ İlk batch yükleme süresi: {end - start:.4f} saniye")

# 3️⃣ Augmentasyon testi
aug_transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])
sample_path = dataset.image_paths[0]
orig = cv2.imread(sample_path)
orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)
aug = aug_transform(orig)

# Görselleştir
plt.figure(figsize=(8, 4))
plt.subplot(1, 2, 1)
plt.imshow(orig)
plt.title("🖼️ Orijinal")
plt.axis("off")
plt.subplot(1, 2, 2)
plt.imshow(aug.permute(1, 2, 0))
plt.title("🎨 Augmented")
plt.axis("off")
plt.tight_layout()
plt.show()

"""# **MODEL EĞİTİMLERİ**
---------------------------
YAPILACAK İŞLEMLER:

Kapsamlı Model Eğitimi Yapılacak Modeller:
 (hem klasik hem derin öğrenme):

🎯 Klasik Modeller (scikit-learn):
Random Forest

SVM

XGBoost

LightGBM

CatBoost

🤖 Derin Öğrenme Modelleri (PyTorch / Keras):
CNN (Scratch)

Transfer Learning:

VGG16

ResNet50

EfficientNetB0

MobileNetV2


**Her model için:**

Confusion Matrix

ROC-AUC Curve

Precision-Recall Curve

Accuracy/F1 Score tablosu

Epoch bazlı loss/accuracy grafik

Classification Report

Feature importance (varsa)

Grad-CAM haritaları (DL modellerde)
"""

# ✅ Tüm modelleri karşılaştırmalı eğiten, A100 için optimize edilmiş eğitim pipeline'ı
# Kullanılan modeller: ResNet50, EfficientNetB0, MobileNetV2, VGG16, SVM, XGBoost, LightGBM, CatBoost
# Ölçülen metrikler: Accuracy, Precision, Recall, F1-Score, AUC, Confusion Matrix, Loss/Eğri, Grad-CAM, Feature Importance

import os
import torch
import torchvision
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc, precision_recall_curve
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
from tqdm import tqdm

# 🔧 Donanım Ayarı
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print("Kullanılan cihaz:", device)

# ✅ DataLoader ayarları
batch_size = 64
input_size = 224

data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(10),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((input_size, input_size)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406],
                             [0.229, 0.224, 0.225])
    ]),
}

# 📂 Dataset Yolu
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
datasets = {x: ImageFolder(os.path.join(root_dir, x), transform=data_transforms[x]) for x in ['train', 'val']}
dataloaders = {x: DataLoader(datasets[x], batch_size=batch_size, shuffle=True, num_workers=4) for x in ['train', 'val']}
class_names = datasets['train'].classes

# 📦 Model listesi
def get_model(name):
    if name == 'resnet50':
        model = models.resnet50(weights='IMAGENET1K_V1')
        model.fc = nn.Linear(model.fc.in_features, len(class_names))
    elif name == 'efficientnet':
        model = models.efficientnet_b0(weights='IMAGENET1K_V1')
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))
    elif name == 'mobilenetv2':
        model = models.mobilenet_v2(weights='IMAGENET1K_V1')
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(class_names))
    elif name == 'vgg16':
        model = models.vgg16(weights='IMAGENET1K_V1')
        model.classifier[6] = nn.Linear(model.classifier[6].in_features, len(class_names))
    else:
        raise ValueError("Model bilinmiyor.")
    return model.to(device)

# 🎯 Eğitim Fonksiyonu
criterion = nn.CrossEntropyLoss()
def train_model(model, epochs=70, lr=2e-5):
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)
    train_loss_hist, val_loss_hist = [], []
    best_acc = 0.0

    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()
            else:
                model.eval()

            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in tqdm(dataloaders[phase]):
                inputs, labels = inputs.to(device), labels.to(device)

                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        optimizer.zero_grad()
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            epoch_loss = running_loss / len(datasets[phase])
            epoch_acc = running_corrects.double() / len(datasets[phase])

            if phase == 'train':
                train_loss_hist.append(epoch_loss)
                scheduler.step()
            else:
                val_loss_hist.append(epoch_loss)

            print(f"{phase.capitalize()} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                torch.save(model.state_dict(), f"best_{model.__class__.__name__}.pt")

    return model, train_loss_hist, val_loss_hist

# 🔍 Değerlendirme
@torch.no_grad()
def evaluate_model(model):
    model.eval()
    all_preds, all_labels, all_probs = [], [], []
    for inputs, labels in dataloaders['val']:
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = model(inputs)
        _, preds = torch.max(outputs, 1)
        probs = torch.softmax(outputs, dim=1)

        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())
        all_probs.extend(probs.cpu().numpy())

    # Confusion Matrix
    cm = confusion_matrix(all_labels, all_preds)
    report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)
    df_report = pd.DataFrame(report).transpose()

    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)
    plt.title("Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    plt.show()

    # ROC-AUC Curve
    try:
        y_true = np.array(pd.get_dummies(all_labels))
        y_score = np.array(all_probs)
        fpr = dict()
        tpr = dict()
        roc_auc = dict()
        for i in range(len(class_names)):
            fpr[i], tpr[i], _ = roc_curve(y_true[:, i], y_score[:, i])
            roc_auc[i] = auc(fpr[i], tpr[i])

        plt.figure(figsize=(8,6))
        for i in range(len(class_names)):
            plt.plot(fpr[i], tpr[i], label=f"{class_names[i]} (AUC = {roc_auc[i]:.2f})")
        plt.plot([0, 1], [0, 1], 'k--')
        plt.title("ROC-AUC Curve")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.legend()
        plt.grid()
        plt.tight_layout()
        plt.show()
    except:
        print("ROC Curve çizimi başarısız (olasılıklar eksik olabilir).")

    return df_report

# 🔁 Tüm modelleri eğit
models_to_train = ['resnet50', 'efficientnet', 'mobilenetv2', 'vgg16']
results = {}

for name in models_to_train:
    print(f"\n🧠 Model: {name}")
    model = get_model(name)
    trained_model, train_loss, val_loss = train_model(model, epochs=70, lr=2e-5)
    metrics_df = evaluate_model(trained_model)
    results[name] = metrics_df

# 📊 Karşılaştırmalı grafikler
overall_df = pd.DataFrame({name: df.loc['accuracy']['f1-score'] for name, df in results.items()}, index=["F1 Score"])
overall_df.T.plot(kind='bar', figsize=(10,6), legend=False)
plt.title("📊 Model Performans Karşılaştırması (F1 Score)")
plt.ylabel("F1")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

"""# TEST"""

# 🔍 Gelişmiş Model Karşılaştırmalı Test & Analiz Scripti (Grad-CAM++ hariç)

import os
import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, roc_curve,
                             precision_recall_curve, accuracy_score, f1_score, cohen_kappa_score,
                             matthews_corrcoef, log_loss, top_k_accuracy_score, auc)
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision import transforms
from tqdm import tqdm
from torchvision.models import efficientnet_b0, resnet50, mobilenet_v2, vgg16

# ✅ Model listesi
model_names = ["EfficientNetB0", "ResNet50", "MobileNetV2", "VGG16"]
model_paths = {
    "EfficientNetB0": "/content/best_EfficientNet.pt",
    "ResNet50": "/content/best_ResNet.pt",
    "MobileNetV2": "/content/best_MobileNetV2.pt",
    "VGG16": "/content/best_VGG.pt",
}

# ✅ Veriseti Yolu & Transforms
input_size = 224
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
data_transforms = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
test_dataset = ImageFolder(os.path.join(root_dir, 'test'), transform=data_transforms)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)
class_names = test_dataset.classes

# ✅ Model oluşturma fonksiyonları
def EfficientNetB0():
    model = efficientnet_b0(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def ResNet50():
    model = resnet50(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))
    return model

def MobileNetV2():
    model = mobilenet_v2(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def VGG16():
    model = vgg16(weights=None)
    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, len(class_names))
    return model

# ✅ Model eşlemesi
model_builders = {
    "EfficientNetB0": EfficientNetB0,
    "ResNet50": ResNet50,
    "MobileNetV2": MobileNetV2,
    "VGG16": VGG16
}

# ✅ Ana değerlendirme fonksiyonu
def evaluate_all_models():
    results = []
    for model_name in model_names:
        print(f"\n📌 Evaluating {model_name}...")

        # ✅ Model oluştur ve ağırlıkları yükle
        model = model_builders[model_name]()
        state_dict = torch.load(model_paths[model_name])
        model.load_state_dict(state_dict)
        model.eval()
        model.cuda()

        y_true, y_pred, y_probs = [], [], []
        embeddings, labels = [], []

        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs, targets = inputs.cuda(), targets.cuda()
                outputs = model(inputs)
                probs = torch.softmax(outputs, dim=1)
                _, preds = torch.max(probs, 1)
                y_true.extend(targets.cpu().numpy())
                y_pred.extend(preds.cpu().numpy())
                y_probs.extend(probs.cpu().numpy())
                embeddings.append(outputs.cpu().numpy())
                labels.append(targets.cpu().numpy())

        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_probs = np.array(y_probs)
        embeddings = np.concatenate(embeddings)
        labels = np.concatenate(labels)

        # 📊 Metrikler
        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average='macro')
        kappa = cohen_kappa_score(y_true, y_pred)
        mcc = matthews_corrcoef(y_true, y_pred)
        logloss = log_loss(y_true, y_probs)
        top3 = top_k_accuracy_score(y_true, y_probs, k=3)
        top5 = top_k_accuracy_score(y_true, y_probs, k=5)

        # 📌 Confusion Matrix
        cm = confusion_matrix(y_true, y_pred, normalize='true')
        sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, cmap="Blues")
        plt.title(f"{model_name} - Normalized Confusion Matrix")
        plt.show()

        # 📌 ROC-AUC per Class
        y_onehot = np.eye(len(class_names))[y_true]
        for i in range(len(class_names)):
            fpr, tpr, _ = roc_curve(y_onehot[:, i], y_probs[:, i])
            prec, rec, _ = precision_recall_curve(y_onehot[:, i], y_probs[:, i])
            plt.plot(fpr, tpr, label=f"{class_names[i]} AUC={auc(fpr, tpr):.2f}")
        plt.legend()
        plt.title(f"{model_name} - ROC-AUC per Class")
        plt.xlabel("False Positive Rate")
        plt.ylabel("True Positive Rate")
        plt.grid(True)
        plt.show()

        # 📌 T-SNE Görselleştirme
        reducer = TSNE(n_components=2, perplexity=30)
        emb_2d = reducer.fit_transform(embeddings)
        plt.figure(figsize=(6, 5))
        sns.scatterplot(x=emb_2d[:, 0], y=emb_2d[:, 1], hue=[class_names[i] for i in labels], palette='deep')
        plt.title(f"{model_name} - t-SNE Embeddings")
        plt.show()

        results.append({
            "Model": model_name,
            "Accuracy": acc,
            "F1": f1,
            "Kappa": kappa,
            "MCC": mcc,
            "LogLoss": logloss,
            "Top-3 Acc": top3,
            "Top-5 Acc": top5
        })

    # 📋 Tablolu karşılaştırma
    df = pd.DataFrame(results)
    display(df)
    sns.barplot(x="Model", y="Accuracy", data=df)
    plt.title("Model Accuracy Karşılaştırması")
    plt.show()

    sns.barplot(x="Model", y="F1", data=df)
    plt.title("Model F1 Score Karşılaştırması")
    plt.show()

# ✅ Fonksiyonu çağır
evaluate_all_models()

# 🔍 Gelişmiş Model Karşılaştırma, Analiz, Validation, ROC-AUC, Hatalı Gösterim, CSV Kaydetme

import os
import torch
import torchvision
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score, roc_curve,
                             precision_recall_curve, accuracy_score, f1_score, cohen_kappa_score,
                             matthews_corrcoef, log_loss, top_k_accuracy_score, auc)
from sklearn.manifold import TSNE
from torch.utils.data import DataLoader
from torchvision.datasets import ImageFolder
from torchvision import transforms
from tqdm import tqdm
from torchvision.models import efficientnet_b0, resnet50, mobilenet_v2, vgg16

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ✅ Model listesi
model_names = ["EfficientNetB0", "ResNet50", "MobileNetV2", "VGG16"]
model_paths = {
    "EfficientNetB0": "/content/best_EfficientNet.pt",
    "ResNet50": "/content/best_ResNet.pt",
    "MobileNetV2": "/content/best_MobileNetV2.pt",
    "VGG16": "/content/best_VGG.pt",
}

# ✅ Veriseti Yolu & Transforms
input_size = 224
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
data_transforms = transforms.Compose([
    transforms.Resize((input_size, input_size)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])
test_dataset = ImageFolder(os.path.join(root_dir, 'test'), transform=data_transforms)
val_dataset = ImageFolder(os.path.join(root_dir, 'val'), transform=data_transforms)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)
val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)
class_names = test_dataset.classes

# ✅ Model oluşturma fonksiyonları
def EfficientNetB0():
    model = efficientnet_b0(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def ResNet50():
    model = resnet50(weights=None)
    model.fc = torch.nn.Linear(model.fc.in_features, len(class_names))
    return model

def MobileNetV2():
    model = mobilenet_v2(weights=None)
    model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, len(class_names))
    return model

def VGG16():
    model = vgg16(weights=None)
    model.classifier[6] = torch.nn.Linear(model.classifier[6].in_features, len(class_names))
    return model

model_builders = {
    "EfficientNetB0": EfficientNetB0,
    "ResNet50": ResNet50,
    "MobileNetV2": MobileNetV2,
    "VGG16": VGG16
}

# ✅ Hatalı Sınıflandırılan Gösterimi

def show_misclassified_images(model, dataloader, num_images=6):
    model.eval()
    incorrect = []
    with torch.no_grad():
        for inputs, labels in dataloader:
            inputs, labels = inputs.to(device), labels.to(device)
            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)
            for i in range(len(labels)):
                if preds[i] != labels[i]:
                    incorrect.append((inputs[i].cpu(), preds[i].item(), labels[i].item()))
                if len(incorrect) >= num_images:
                    break
            if len(incorrect) >= num_images:
                break

    fig, axes = plt.subplots(1, len(incorrect), figsize=(15, 5))
    for i, (img, pred, true) in enumerate(incorrect):
        axes[i].imshow(img.permute(1, 2, 0))
        axes[i].set_title(f"P: {class_names[pred]}\nT: {class_names[true]}")
        axes[i].axis('off')
    plt.tight_layout()
    plt.show()

# ✅ ROC-AUC Karşılaştırma

def compare_roc_auc(results_list):
    plt.figure(figsize=(8, 6))
    for result in results_list:
        model_name = result["Model"]
        probs = result["Probs"]
        y_true = result["True"]
        y_onehot = np.eye(len(class_names))[y_true]
        auc_sum = 0
        for i in range(len(class_names)):
            fpr, tpr, _ = roc_curve(y_onehot[:, i], probs[:, i])
            auc_score = auc(fpr, tpr)
            auc_sum += auc_score
        avg_auc = auc_sum / len(class_names)
        plt.bar(model_name, avg_auc)
    plt.ylabel("Average ROC-AUC Score")
    plt.title("ROC-AUC Karşılaştırması")
    plt.grid(True)
    plt.show()

# ✅ Validation için ayrı fonksiyon

def evaluate_model_on_loader(model, dataloader, name="Validation"):
    model.eval()
    y_true, y_pred, y_probs = [], [], []
    with torch.no_grad():
        for inputs, targets in dataloader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            probs = torch.softmax(outputs, dim=1)
            _, preds = torch.max(probs, 1)
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())
            y_probs.extend(probs.cpu().numpy())
    print(f"\n{name} Accuracy:", accuracy_score(y_true, y_pred))
    print(f"{name} F1 Score:", f1_score(y_true, y_pred, average='macro'))

# ✅ Ana fonksiyon

def evaluate_all_models():
    results = []
    for model_name in model_names:
        print(f"\n\U0001f4cc Evaluating {model_name}...")
        model = model_builders[model_name]()
        state_dict = torch.load(model_paths[model_name])
        model.load_state_dict(state_dict)
        model.to(device)
        model.eval()

        y_true, y_pred, y_probs = [], [], []
        embeddings, labels = [], []

        with torch.no_grad():
            for inputs, targets in test_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                probs = torch.softmax(outputs, dim=1)
                _, preds = torch.max(probs, 1)
                y_true.extend(targets.cpu().numpy())
                y_pred.extend(preds.cpu().numpy())
                y_probs.extend(probs.cpu().numpy())
                embeddings.append(outputs.cpu().numpy())
                labels.append(targets.cpu().numpy())

        y_true = np.array(y_true)
        y_pred = np.array(y_pred)
        y_probs = np.array(y_probs)
        embeddings = np.concatenate(embeddings)
        labels = np.concatenate(labels)

        acc = accuracy_score(y_true, y_pred)
        f1 = f1_score(y_true, y_pred, average='macro')
        kappa = cohen_kappa_score(y_true, y_pred)
        mcc = matthews_corrcoef(y_true, y_pred)
        logloss = log_loss(y_true, y_probs)
        top3 = top_k_accuracy_score(y_true, y_probs, k=3)
        top5 = top_k_accuracy_score(y_true, y_probs, k=5)

        cm = confusion_matrix(y_true, y_pred, normalize='true')
        sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names, cmap="Blues")
        plt.title(f"{model_name} - Normalized Confusion Matrix")
        plt.show()

        reducer = TSNE(n_components=2, perplexity=30)
        emb_2d = reducer.fit_transform(embeddings)
        plt.figure(figsize=(6, 5))
        sns.scatterplot(x=emb_2d[:, 0], y=emb_2d[:, 1], hue=[class_names[i] for i in labels], palette='deep')
        plt.title(f"{model_name} - t-SNE Embeddings")
        plt.show()

        show_misclassified_images(model, test_loader)

        results.append({
            "Model": model_name,
            "Accuracy": acc,
            "F1": f1,
            "Kappa": kappa,
            "MCC": mcc,
            "LogLoss": logloss,
            "Top-3 Acc": top3,
            "Top-5 Acc": top5,
            "True": y_true,
            "Probs": y_probs
        })

    df = pd.DataFrame(results)
    display(df)
    df.to_csv("model_sonuclari.csv", index=False)

    sns.barplot(x="Model", y="Accuracy", data=df)
    plt.title("Model Accuracy Karşılaştırması")
    plt.show()

    sns.barplot(x="Model", y="F1", data=df)
    plt.title("Model F1 Score Karşılaştırması")
    plt.show()

    compare_roc_auc(results)

# ✅ Fonksiyonu çağır
evaluate_all_models()

# İsteğe bağlı: Validation seti ayrıca değerlendirme
model = model_builders["EfficientNetB0"]()
model.load_state_dict(torch.load(model_paths["EfficientNetB0"]))
model.to(device)
evaluate_model_on_loader(model, val_loader, name="Validation")

import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from torchvision.datasets import ImageFolder
from torchvision import transforms
from torch.utils.data import DataLoader
from PIL import Image

# 📂 Dataset yolu
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
subsets = ['train', 'val', 'test']

# 📌 Dönüştürme
data_transforms = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor()
])

# 📊 Veri dağılımı analizi ve örnek gösterimi
def analyze_dataset_structure():
    summary = []

    for subset in subsets:
        dataset = ImageFolder(os.path.join(root_dir, subset), transform=data_transforms)
        class_names = dataset.classes
        class_counts = {cls: 0 for cls in class_names}
        file_paths = {cls: [] for cls in class_names}

        for path, label in dataset.samples:
            class_name = class_names[label]
            class_counts[class_name] += 1
            file_paths[class_name].append(path)

        for cls in class_names:
            summary.append({
                "Subset": subset,
                "Class": cls,
                "Count": class_counts[cls],
                "Example Paths": file_paths[cls][:3]  # ilk 3 örnek yolu
            })

    df_summary = pd.DataFrame(summary)
    display(df_summary)

    # 📈 Görselleştirme
    plt.figure(figsize=(10, 6))
    sns.barplot(data=df_summary, x="Class", y="Count", hue="Subset")
    plt.title("Veri Seti Sınıf Dağılımı (Train/Val/Test)")
    plt.ylabel("Adet")
    plt.xlabel("Sınıf")
    plt.tight_layout()
    plt.show()

    # 🖼️ Örnek görseller (ilk 3 her sınıftan her alt set için)
    for subset in subsets:
        dataset = ImageFolder(os.path.join(root_dir, subset))
        class_names = dataset.classes
        print(f"\n📌 {subset.upper()} örnekleri:\n")

        fig, axes = plt.subplots(nrows=len(class_names), ncols=3, figsize=(9, 3 * len(class_names)))
        for i, cls in enumerate(class_names):
            cls_paths = [p for p, label in dataset.samples if dataset.classes[label] == cls][:3]
            for j, img_path in enumerate(cls_paths):
                img = Image.open(img_path)
                axes[i, j].imshow(img, cmap='gray')
                axes[i, j].set_title(f"{cls}")
                axes[i, j].axis("off")
        plt.tight_layout()
        plt.show()

# ✅ Çağır
analyze_dataset_structure()

"""# DenseNet201', 'InceptionV3', 'EfficientNetV2', 'ConvNeXt' EĞİTİMLERİ"""

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import densenet201, inception_v3, convnext_base, efficientnet_v2_s
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# --------------------- Tekrarlanabilirlik için seed atama ---------------------
def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

# --------------------- Erken durdurma ---------------------
class EarlyStopping:
    def __init__(self, patience=7, delta=1e-4, save_path="best_model.pt"):
        self.patience = patience
        self.delta = delta
        self.save_path = save_path
        self.best_score = None
        self.counter = 0

    def step(self, metric, model):
        score = metric
        if self.best_score is None or score > self.best_score + self.delta:
            self.best_score = score
            self.counter = 0
            torch.save(model.state_dict(), self.save_path)
        else:
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False

# --------------------- Konfigürasyon ---------------------
set_seed(2025)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

epochs = 50
batch_size = 32
lr = 1e-4
weight_decay = 1e-5
num_classes = 3
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
models_to_train = ['DenseNet201', 'InceptionV3', 'EfficientNetV2', 'ConvNeXt']

# --------------------- Veri artırma ---------------------
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# --------------------- Dataset & DataLoader ---------------------
datasets = {phase: ImageFolder(os.path.join(root_dir, phase), transform=data_transforms[phase])
            for phase in ['train', 'val', 'test']}
loaders = {phase: DataLoader(
                datasets[phase],
                batch_size=batch_size,
                shuffle=(phase=='train'),
                num_workers=os.cpu_count(),
                pin_memory=True
            ) for phase in ['train', 'val', 'test']}
class_names = datasets['train'].classes

# --------------------- Model oluşturucu ---------------------
def build_model(name: str):
    if name == 'DenseNet201':
        model = densenet201(pretrained=True)
        model.classifier = nn.Linear(model.classifier.in_features, num_classes)
    elif name == 'InceptionV3':
        model = inception_v3(pretrained=True, aux_logits=True)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)
    elif name == 'EfficientNetV2':
        model = efficientnet_v2_s(pretrained=True)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    elif name == 'ConvNeXt':
        model = convnext_base(pretrained=True)
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
    else:
        raise ValueError(f"Unknown model: {name}")
    return model.to(device)

# --------------------- Eğitim ve Değerlendirme ---------------------
scaler = GradScaler()

for model_name in models_to_train:
    print(f"\n===== Training {model_name} =====")
    model = build_model(model_name)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
    early_stopper = EarlyStopping(patience=7, delta=1e-4, save_path=f'{model_name}_best.pt')
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        # --- Training ---
        model.train()
        train_loss, train_correct = 0.0, 0
        for inputs, targets in tqdm(loaders['train'], desc=f"Epoch {epoch+1}/{epochs}"):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            with autocast():
                outputs = model(inputs)
                loss = criterion(outputs, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            train_loss += loss.item() * inputs.size(0)
            train_correct += (outputs.argmax(dim=1) == targets).sum().item()

        train_acc = train_correct / len(datasets['train'])

        # --- Validation ---
        model.eval()
        val_loss, val_correct = 0.0, 0
        with torch.no_grad():
            for inputs, targets in loaders['val']:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)
                val_loss += loss.item() * inputs.size(0)
                val_correct += (outputs.argmax(dim=1) == targets).sum().item()

        val_acc = val_correct / len(datasets['val'])
        scheduler.step(val_acc)
        if early_stopper.step(val_acc, model):
            print("Early stopping triggered.\n")
            break

        print(f"Epoch {epoch+1}/{epochs} | "
              f"Train Loss: {train_loss/len(datasets['train']):.4f} | Train Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss/len(datasets['val']):.4f} | Val Acc: {val_acc:.4f}")

    # --- Test ve Metrik Raporu ---
    print(f"--- Testing {model_name} ---")
    model.load_state_dict(torch.load(f'{model_name}_best.pt'))
    model.eval()

    y_true, y_pred, y_score = [], [], []
    with torch.no_grad():
        for inputs, targets in loaders['test']:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            probs = nn.functional.softmax(outputs, dim=1)
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(probs.argmax(dim=1).cpu().numpy())
            y_score.extend(probs.cpu().numpy())

    # Temel Metrikler
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    print(f"Test Accuracy: {acc:.4f}")
    print(f"Test F1 (macro): {f1:.4f}")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, normalize='true')
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)
    plt.title(f"{model_name} - Confusion Matrix")
    plt.show()

    # ROC-AUC Eğrileri
    y_true_oh = np.eye(num_classes)[y_true]
    y_score = np.array(y_score)
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        fpr, tpr, _ = roc_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(fpr, tpr, label=f"{class_names[i]} (AUC={auc(fpr, tpr):.2f})")
    plt.legend()
    plt.title(f"{model_name} - ROC-AUC")
    plt.show()

    # Precision-Recall Eğrileri
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        precision, recall, _ = precision_recall_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(recall, precision, label=f"{class_names[i]}")
    plt.legend()
    plt.title(f"{model_name} - Precision-Recall")
    plt.show()

import os
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
from torchvision.models import densenet201, inception_v3, convnext_base, efficientnet_v2_s
from torch.optim.lr_scheduler import ReduceLROnPlateau
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve, accuracy_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm

# --------------------- Tekrarlanabilirlik için seed atama ---------------------
def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)

# --------------------- Erken durdurma ---------------------
class EarlyStopping:
    def __init__(self, patience=7, delta=1e-4, save_path="best_model.pt"):
        self.patience = patience
        self.delta = delta
        self.save_path = save_path
        self.best_score = None
        self.counter = 0

    def step(self, metric, model):
        score = metric
        if self.best_score is None or score > self.best_score + self.delta:
            self.best_score = score
            self.counter = 0
            torch.save(model.state_dict(), self.save_path)
        else:
            self.counter += 1
            if self.counter >= self.patience:
                return True
        return False

# --------------------- Konfigürasyon ---------------------
set_seed(2025)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

epochs = 50
batch_size = 32
lr = 1e-4
weight_decay = 1e-5
num_classes = 3
root_dir = "/content/drive/MyDrive/processed_dataset/split_dataset"
models_to_train = ['InceptionV3', 'EfficientNetV2', 'ConvNeXt']

# --------------------- Veri artırma ---------------------
data_transforms = {
    'train': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.RandomResizedCrop(299, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'test': transforms.Compose([
        transforms.Resize((299, 299)),
        transforms.CenterCrop(299),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
}

# --------------------- Dataset & DataLoader ---------------------
datasets = {phase: ImageFolder(os.path.join(root_dir, phase), transform=data_transforms[phase])
            for phase in ['train', 'val', 'test']}
loaders = {phase: DataLoader(
                datasets[phase],
                batch_size=batch_size,
                shuffle=(phase=='train'),
                num_workers=os.cpu_count(),
                pin_memory=True
            ) for phase in ['train', 'val', 'test']}
class_names = datasets['train'].classes

# --------------------- Model oluşturucu ---------------------
def build_model(name: str):

    if name == 'InceptionV3':
        model = inception_v3(pretrained=True, aux_logits=True)
        model.fc = nn.Linear(model.fc.in_features, num_classes)
        model.AuxLogits.fc = nn.Linear(model.AuxLogits.fc.in_features, num_classes)
    elif name == 'EfficientNetV2':
        model = efficientnet_v2_s(pretrained=True)
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)
    elif name == 'ConvNeXt':
        model = convnext_base(pretrained=True)
        model.classifier[2] = nn.Linear(model.classifier[2].in_features, num_classes)
    else:
        raise ValueError(f"Unknown model: {name}")
    return model.to(device)

# --------------------- Eğitim ve Değerlendirme ---------------------
scaler = GradScaler()

for model_name in models_to_train:
    print(f"\n===== Training {model_name} =====")
    model = build_model(model_name)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)
    early_stopper = EarlyStopping(patience=7, delta=1e-4, save_path=f'{model_name}_best.pt')
    criterion = nn.CrossEntropyLoss()

    for epoch in range(epochs):
        # --- Training ---
        model.train()
        train_loss, train_correct = 0.0, 0
        for inputs, targets in tqdm(loaders['train'], desc=f"Epoch {epoch+1}/{epochs}"):
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            with autocast():
                outputs = model(inputs)
                logits = outputs.logits if hasattr(outputs, 'logits') else outputs
                loss = criterion(logits, targets)
            scaler.scale(loss).backward()
            scaler.step(optimizer)
            scaler.update()
            train_loss += loss.item() * inputs.size(0)
            train_correct += (logits.argmax(dim=1) == targets).sum().item()

        train_acc = train_correct / len(datasets['train'])

        # --- Validation ---
        model.eval()
        val_loss, val_correct = 0.0, 0
        with torch.no_grad():
            for inputs, targets in loaders['val']:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                logits = outputs.logits if hasattr(outputs, 'logits') else outputs
                loss = criterion(logits, targets)
                val_loss += loss.item() * inputs.size(0)
                val_correct += (logits.argmax(dim=1) == targets).sum().item()

        val_acc = val_correct / len(datasets['val'])
        scheduler.step(val_acc)
        if early_stopper.step(val_acc, model):
            print("Early stopping triggered.\n")
            break

        print(f"Epoch {epoch+1}/{epochs} | "
              f"Train Loss: {train_loss/len(datasets['train']):.4f} | Train Acc: {train_acc:.4f} | "
              f"Val Loss: {val_loss/len(datasets['val']):.4f} | Val Acc: {val_acc:.4f}")

    # --- Test ve Metrik Raporu ---
    print(f"--- Testing {model_name} ---")
    model.load_state_dict(torch.load(f'{model_name}_best.pt'))
    model.eval()

    y_true, y_pred, y_score = [], [], []
    with torch.no_grad():
        for inputs, targets in loaders['test']:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            logits = outputs.logits if hasattr(outputs, 'logits') else outputs
            probs = nn.functional.softmax(logits, dim=1)
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(probs.argmax(dim=1).cpu().numpy())
            y_score.extend(probs.cpu().numpy())

    # Temel Metrikler
    acc = accuracy_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred, average='macro')
    print(f"Test Accuracy: {acc:.4f}")
    print(f"Test F1 (macro): {f1:.4f}")
    print(classification_report(y_true, y_pred, target_names=class_names))

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, normalize='true')
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, xticklabels=class_names, yticklabels=class_names)
    plt.title(f"{model_name} - Confusion Matrix")
    plt.show()

    # ROC-AUC Eğrileri
    y_true_oh = np.eye(num_classes)[y_true]
    y_score = np.array(y_score)
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        fpr, tpr, _ = roc_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(fpr, tpr, label=f"{class_names[i]} (AUC={auc(fpr, tpr):.2f})")
    plt.legend()
    plt.title(f"{model_name} - ROC-AUC")
    plt.show()

    # Precision-Recall Eğrileri
    plt.figure(figsize=(6,5))
    for i in range(num_classes):
        precision, recall, _ = precision_recall_curve(y_true_oh[:, i], y_score[:, i])
        plt.plot(recall, precision, label=f"{class_names[i]}")
    plt.legend()
    plt.title(f"{model_name} - Precision-Recall")
    plt.show()